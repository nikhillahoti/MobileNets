{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import Model\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import Conv3D\n",
    "\n",
    "fileName = \"Trump.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "# Global MobileNets model\n",
    "mobile = keras.applications.mobilenet.MobileNet(weights=\"imagenet\")\n",
    "model = Model(mobile.input, mobile.layers[43].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f02202226a0>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f01923060f0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f01922ce3c8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f019214ef28>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f019214edd8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f01919139b0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0190086f60>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f01887b94a8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f01887d62e8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f018874b278>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f01887b4860>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f0188733ac8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f01886ea208>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0188625518>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0188625748>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f01885c4828>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f01885820b8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0188582a20>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f0188500da0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f01884e0940>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0188450cf8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f0188402ac8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0188204f60>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f018822bdd8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f01881e7b70>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f01881a4be0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0188123dd8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0188123e80>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f01880c56a0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0188085908>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f018805ba90>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f01687bf8d0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f01687cdeb8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0168773668>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f016871f5f8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0168691438>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f01686f7a20>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f01685fdc88>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f016861cf60>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f019233f978>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f019233f940>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f01685107f0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f01684cd9e8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f016844ce48>\n",
      "\n",
      "\n",
      " Weight Size\n",
      "(1, 1, 1, 256, 512)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer41 = model.layers[41]\n",
    "W = np.array(layer41.get_weights())\n",
    "\n",
    "print(\"\\n\\n Weight Size\")\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_Thirteen(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(1):\n",
    "            for k in range(512):\n",
    "                for l in range(256):\n",
    "                    fTemp.write(str(W[i][j][l][k]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f02202226a0>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f01923060f0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f01922ce3c8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f019214ef28>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f019214edd8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f01919139b0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0190086f60>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f01887b94a8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f01887d62e8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f018874b278>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f01887b4860>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f0188733ac8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f01886ea208>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0188625518>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0188625748>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f01885c4828>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f01885820b8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0188582a20>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f0188500da0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f01884e0940>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0188450cf8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f0188402ac8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0188204f60>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f018822bdd8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f01881e7b70>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f01881a4be0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0188123dd8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0188123e80>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f01880c56a0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0188085908>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f018805ba90>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f01687bf8d0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f01687cdeb8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0168773668>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f016871f5f8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0168691438>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f01686f7a20>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f01685fdc88>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f016861cf60>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f019233f978>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f019233f940>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f01685107f0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f01684cd9e8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f016844ce48>\n",
      "(1, 1, 1, 256, 512)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer41 = model.layers[41]\n",
    "W = np.array(layer41.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer41.get_weights()[0]\n",
    "write_to_file_weights_layer_Thirteen(\"data/ThirteenthLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_Thirteen(\"data/ThirteenthLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 512)\n",
      "[1.2941556  1.6203151  0.5696549  0.9311667  0.6474082  1.1922176\n",
      " 1.2866814  1.0885127  1.2523308  0.8299578  1.0637304  0.9347129\n",
      " 1.4609058  1.281396   0.8552405  1.6895874  1.1628817  0.43024826\n",
      " 0.95699304 0.62227815 1.0826663  0.8209004  0.8019412  1.2522207\n",
      " 0.6045446  0.8062246  1.155899   1.3945308  1.174245   0.43836126\n",
      " 1.2868369  1.0689931  1.3352126  0.65847    0.744378   1.7432104\n",
      " 1.1108321  0.45976037 1.1769902  0.99231166 1.2362936  0.71464455\n",
      " 0.72609496 1.0042778  1.5001314  1.146608   0.9987836  0.94819003\n",
      " 1.698161   1.042011   1.0687627  1.1909738  0.89143527 0.97145927\n",
      " 0.94598746 0.58027196 1.2796587  0.95663065 1.3575435  1.3471178\n",
      " 1.3356056  0.7777277  2.1685565  1.5516374  0.8304897  0.89272827\n",
      " 0.51475316 0.82308817 1.0894883  0.8273627  0.88041323 0.88121694\n",
      " 0.6241419  1.112578   0.93103075 1.271727   0.70799994 1.001308\n",
      " 0.58845264 0.97563475 1.1940554  1.650416   0.8070227  1.0554483\n",
      " 0.8933694  0.84010816 1.5692711  1.9494748  1.2482287  1.6174532\n",
      " 1.9848889  1.1080751  0.9435969  1.347038   1.2434491  0.8892527\n",
      " 1.1936082  0.9685876  0.8338081  0.6587802  0.92776215 1.0355752\n",
      " 1.8223205  0.9701034  1.1980462  1.3983629  1.0865756  1.297456\n",
      " 1.2513239  0.67929244 1.007219   0.9726355  1.1233846  0.9099259\n",
      " 0.85401744 0.8321921  0.83811927 0.53358847 1.3433965  1.1470432\n",
      " 1.4600676  1.0360746  1.0228868  1.0049794  0.9847222  1.0727913\n",
      " 0.6026622  0.40769246 1.3485299  1.0181847  0.91582084 1.1652367\n",
      " 1.4572123  1.116975   0.9395301  1.1721966  1.3563477  0.9704003\n",
      " 0.97135407 1.8968456  0.6788441  1.5932031  1.1185622  1.0036497\n",
      " 1.154305   1.2346593  1.3156612  1.5142094  2.147691   0.90980643\n",
      " 1.287833   0.80027723 0.5383283  0.7544571  1.4282959  0.61938\n",
      " 0.65227157 1.5036756  0.6195288  1.6054329  0.80389065 0.88874775\n",
      " 1.2376746  1.4653378  0.7622792  0.96326435 0.7111826  1.9405204\n",
      " 1.0400404  0.72257555 1.1064259  0.81906825 2.1564102  0.9986614\n",
      " 1.1127765  0.8951182  0.85300344 2.092944   0.73636603 0.9148987\n",
      " 1.0061812  1.5350505  0.85743976 0.67051953 2.0297205  0.42575094\n",
      " 1.1212873  0.9961695  0.83904403 0.65465856 0.94789475 0.95492244\n",
      " 1.163523   0.81740934 2.356367   0.7292693  0.68028593 1.0329964\n",
      " 0.8617862  1.2993233  0.627949   0.75718874 1.1743178  0.984254\n",
      " 1.1141115  0.8653388  0.9090359  1.3806895  1.0402852  1.1184989\n",
      " 0.8121576  0.8618439  1.8292714  0.962995   1.3001105  1.0884783\n",
      " 0.96841204 0.5760025  1.0308888  0.97447395 1.2671432  1.2511019\n",
      " 1.0845523  0.4134626  0.8894276  0.9746704  0.7092747  1.4752481\n",
      " 1.2298295  0.9117646  0.535967   0.90779406 0.74457556 1.47586\n",
      " 1.2910858  1.0532216  0.885842   0.7199006  0.9567987  0.963389\n",
      " 0.7720089  1.1154869  1.1811248  1.162425   1.9301162  0.80315065\n",
      " 0.9572927  1.4887549  1.0423429  0.62649786 0.7281652  0.6080119\n",
      " 0.9868259  1.0084596  1.7089207  0.9581674  1.2273682  1.0489005\n",
      " 0.88351566 1.1025211  1.1778474  1.2495736  1.2873067  0.62803686\n",
      " 0.74451244 1.5312862  1.0387112  1.1750473  1.1407412  0.98922896\n",
      " 0.892439   0.48931932 0.7085422  0.9086681  1.5315118  1.011938\n",
      " 1.4721427  1.1577673  1.77643    1.0563142  0.8855045  1.1393484\n",
      " 1.095886   0.81079423 0.83847976 0.5023894  0.78051883 1.2887257\n",
      " 1.0002452  0.56321913 0.8168442  0.32832512 1.1091886  0.8871887\n",
      " 1.2508163  1.1579151  1.5023255  1.0973015  1.2549648  0.97273743\n",
      " 0.7807669  0.53686523 0.65902984 0.6445895  1.200097   0.9663846\n",
      " 0.5649045  1.0029212  0.8959514  0.7683831  0.7816279  0.31185028\n",
      " 1.0028942  1.2714512  0.5562779  0.6564003  0.6209103  0.70232046\n",
      " 1.3873956  1.5607202  0.73680234 1.3830209  1.2489101  1.3597753\n",
      " 0.6990501  1.4462646  1.2733786  1.8170929  0.9405268  1.1067135\n",
      " 1.2239016  0.7698717  0.7819745  1.0059383  1.0372863  1.1080605\n",
      " 0.61285335 1.8737373  1.0545473  1.2894166  1.288347   2.0068853\n",
      " 0.9540796  1.0012538  0.9472854  1.0129992  0.7160412  0.77564126\n",
      " 0.91287535 1.1444886  1.229016   0.90084136 1.0238138  1.5099702\n",
      " 1.3293072  0.7264801  1.3636795  1.0238642  0.7853783  0.9205571\n",
      " 1.305471   1.1984618  1.2114098  1.5321596  1.7711722  0.76919085\n",
      " 0.97760123 1.080821   0.7948953  1.5196893  2.0659168  0.93226933\n",
      " 0.686809   0.554941   0.8549265  0.94637126 1.786314   0.7859041\n",
      " 0.7514788  0.8734702  1.2614701  1.0177597  0.93008405 0.8045322\n",
      " 1.5875832  1.1512896  0.88122594 0.7610787  0.95226246 0.9665016\n",
      " 1.3691193  1.1654035  1.3455065  1.0615001  1.1337415  1.1567141\n",
      " 0.79291505 0.9808087  0.79531544 0.53420454 1.0611067  1.206443\n",
      " 0.9729232  0.9271882  1.0082444  0.8612038  1.2358992  1.1191659\n",
      " 1.3502389  0.8720357  1.3349068  0.9411877  0.781287   1.591539\n",
      " 1.2076054  1.1580478  0.7125646  0.9425555  1.406812   0.7128681\n",
      " 1.6141204  0.6590685  2.0114522  1.1629308  1.5139726  1.0105646\n",
      " 1.1048826  1.3508397  0.1362364  1.1877335  1.9838406  1.0484705\n",
      " 1.2179981  1.192097   1.0455717  0.8435964  0.605523   1.2071631\n",
      " 0.5444958  1.7201008  1.5555134  1.2891164  0.8853644  0.9609817\n",
      " 1.1187106  0.81773776 0.62922406 1.3658336  0.6443844  0.8853406\n",
      " 1.0276171  0.4515472  0.9144348  1.6324956  1.1487402  0.9644117\n",
      " 1.2866924  1.01872    1.2146019  1.4424528  0.6209308  1.3585001\n",
      " 1.0513786  0.9261659  1.2950987  1.1447906  0.62224287 1.1107202\n",
      " 0.60321087 1.1213385  0.94179916 0.71548134 2.0488622  0.9420201\n",
      " 0.72208923 0.97629726 0.9460183  0.953005   0.8950105  1.0391656\n",
      " 0.78605783 0.9997791  0.9632811  1.0546972  0.6540085  1.3750107\n",
      " 0.9812816  1.069973   1.2595669  1.1488777  1.1589503  0.861738\n",
      " 1.3868086  0.9067024  0.55660754 0.9628426  1.1289893  1.0294906\n",
      " 0.54664826 1.2789066  1.4701647  1.1472642  0.9173831  0.96712965\n",
      " 0.8783845  0.7850254  0.1569274  0.99409366 0.85735404 1.1458752\n",
      " 1.4197849  0.6470866 ]\n",
      "[ 1.6122186  -0.2467916   1.5003417   1.9165599   1.4060643   1.0012629\n",
      " -0.2798753   1.5686669   0.78138936  1.9895343   1.2670612   1.1456326\n",
      "  0.02689581  0.03515068  1.8913429   0.56209606  0.9319734   1.7265141\n",
      "  1.8097931   1.7248673   1.1120431   2.1775162   1.4816135   1.8401979\n",
      "  1.3564336   1.8237073   1.5130264   0.30702776  0.99111766  1.7155769\n",
      "  0.6343746   1.3530251   0.07082722  1.2584596   1.3113691   1.2323223\n",
      "  0.44697368  1.4772967   0.56071526  1.2708517   0.96240586  1.4379895\n",
      "  1.692069    1.2770938   1.6199338  -0.3495256   1.2215697   1.235161\n",
      "  1.0458381   0.8477635   1.1394244   1.7028427   1.4966199   0.9960677\n",
      "  1.5504717   2.0626233   0.5381426   1.2175766   1.525711    0.7254115\n",
      "  1.9277403   1.2831086  -0.01531219 -0.19627324  0.29211834  1.9629242\n",
      "  1.6738108   1.3188105   1.2664927   1.3493614   1.6040561   1.4136124\n",
      "  1.5087173   0.47695023  1.6808032   0.5677731   1.2713681   1.7361208\n",
      "  2.0622602   1.1872026   2.1963265   1.3904346   1.0802755   0.46259308\n",
      "  1.0967968   2.2920597   1.9556655  -0.08429294  1.0025938   0.51061386\n",
      " -0.5251674   1.1702833   1.5519155   0.30977982  0.371563    1.834018\n",
      "  0.9125433   1.156456    1.0635376   1.3484237   0.12808044  1.8129742\n",
      "  0.13369255  1.1877338   0.6884446   0.02506452  0.99340826  0.83446395\n",
      "  2.232219    1.127491    1.3449987   0.98537016  1.4353315   1.5762382\n",
      "  1.6032519   1.816163    1.9337591   1.5443497  -0.06631795  0.4028299\n",
      "  0.813687    0.22990434  1.5993295   1.9581666   1.2015293   1.6057245\n",
      "  1.1316882   1.4917886   0.8453593   1.7499795   1.4613271   0.45683727\n",
      " -0.34842876  0.3946967   1.6730226   0.63790625  0.15957837  1.4636353\n",
      "  1.9982051   0.5075388   1.6203542   0.28535485  0.95756847  2.1843207\n",
      "  1.2118003   1.2322153   0.5453332  -0.33181065  0.41174817  1.6567981\n",
      "  0.06009495  1.022196    1.1423146   0.9071632   0.25267118  1.310401\n",
      "  1.0736159   1.1007094   1.438087    0.4883003   1.5307457   1.4339162\n",
      "  1.8734878   0.98607624  1.4302254   1.308613    1.4082465  -0.45734742\n",
      "  1.0903746   1.5946333   1.0385324   1.1659122   0.8150652  -0.07994358\n",
      "  0.77053523  0.9973828   1.4920278   0.02129052  1.5716964   2.1150913\n",
      "  1.3336165  -0.6411574   1.3026147   1.612708    1.2282132   1.5681094\n",
      "  1.4351081   1.5001898   1.2681471   1.7142315   1.2510995   1.241993\n",
      "  1.245821    1.5715376   1.05022     1.50362     1.3525562   1.6122981\n",
      "  1.6428227   0.40159315  1.3649509   1.1431391   0.63906646  1.1273576\n",
      "  1.9624522   1.4914508   1.8140161   0.43795976  1.0220156   2.0449812\n",
      "  1.4153126   1.5387353  -0.27991176  0.861232    0.21498704  0.5278636\n",
      "  1.4869524   2.353784    1.9771134   1.0006744   1.9071939   1.4218086\n",
      "  1.9569101   1.6128663   1.0391047   1.115147    1.6119976   1.6938074\n",
      " -0.32457447  1.7622325   1.716476    2.0449016   1.0957366   0.7443988\n",
      "  0.18335868  0.7728297   1.182021    1.3233124   1.8618065   1.2222775\n",
      "  1.0499067  -0.8323983   0.867012    0.65474963  0.56320894  1.6435901\n",
      "  1.1847405   1.1363189   0.6351754   1.5834428   1.5613805   1.5805762\n",
      "  1.6262213   1.1890814   0.92012984  2.3002074   1.6829051   1.5174357\n",
      "  1.6047498   1.7197949   0.96405035  0.33794802  1.3815128   1.4578563\n",
      "  1.5755812   0.06418502  1.3371186   1.4339044   0.6597829   1.9869326\n",
      "  1.464527    1.5319254   1.0783155   1.343725    0.1577434   0.9117282\n",
      "  1.1262403   0.41262108 -0.40176082  0.6929162   1.060227    1.9423857\n",
      "  1.2701569   2.1409833   2.1773205   1.4077346   1.3449676   0.531339\n",
      "  0.31302112  1.3702223   1.123974    1.7764343   0.09950906  1.2315882\n",
      "  2.0035534   0.5860929   0.22236462  0.4847883   1.80029     1.4896619\n",
      "  1.1323069   1.6203445   1.4339384   1.5332468   1.7312506   1.6371864\n",
      "  1.5045357   1.3534881   1.7349299   1.5375868   1.4433489   1.9184595\n",
      "  0.86917615  0.30339047  1.6318833   1.480416    1.6634132   1.8024552\n",
      "  0.43038547  0.40251136  1.9797568   1.0393908   0.64736843  1.2191023\n",
      "  2.1157157   0.03031918 -0.33031046 -0.31959113  1.5367856   1.9628565\n",
      "  1.1586814   1.4288706   1.9002843   1.7360612   1.5520158   0.8957458\n",
      "  1.6400899   0.18835512  1.4146951  -0.36231565  0.49919492 -0.5635867\n",
      "  1.5726633   1.3254902   0.8602587   1.3582424   1.3818958   1.247351\n",
      "  1.130019    0.22513181  1.1713879   1.3779492   1.1876907   1.2048668\n",
      "  0.8106033   1.2448637   0.74698913  2.1792185   1.0802798   1.3012508\n",
      "  0.25378686  0.8291518   1.0694675   1.2335593   0.3379886   1.4754938\n",
      "  1.314534    1.6287569   2.0374572  -0.07405298  1.1802728   1.8535072\n",
      "  1.3132957   1.5951034   1.8977349   1.7922715   1.2422771   1.452545\n",
      "  1.6517885   1.5905893   0.93189746  0.8024255   1.3662986   1.7200062\n",
      "  1.6078805   0.5459677   1.8331869   1.371175    2.0991948   0.8461031\n",
      " -0.537071    1.525059   -0.13757299  0.59482956  1.080439    0.74793935\n",
      "  1.4043487   1.7661604   1.0626844   1.3822173  -0.4997765   2.373249\n",
      "  0.54335093  1.9479886   1.9664928   1.4908018   1.9598467   1.1223869\n",
      "  0.7357213   0.7760303   0.70707047  1.4287753   1.6983525   0.05643079\n",
      "  1.0747896   0.75868887  0.88570094  1.8762949  -0.02171894  1.2154099\n",
      "  2.178849    1.5496783  -0.7965084   0.31837696 -0.9089138   1.0554045\n",
      "  1.5018326   2.3043296   1.6923809   0.50790733 -0.51259255  1.6685569\n",
      "  0.6395041   1.1336231   1.2530127   1.9077791   1.4157351   0.5753604\n",
      "  1.5274497   0.2248936  -0.46915966  1.9643737   1.6086814   0.21810171\n",
      "  1.3284196   1.1341321   1.7159953   1.5597678   1.744184    1.2473388\n",
      "  1.6209378   1.5981619   1.2984523  -0.1517127  -0.67367357  1.4018438\n",
      "  0.73488605  1.2254387   0.6779096   0.08091987  1.3243744   0.02445128\n",
      "  0.8041628   1.6491967   0.7933638   1.1190865   1.585358    0.4456405\n",
      "  1.9218127   1.4965796   1.2205538   1.7785342  -0.22408505  1.7960824\n",
      "  1.655377    1.1935875   1.8991861   0.34621957  1.5132532   1.5562246\n",
      "  1.0980513   1.8396244   1.8829683   1.5234792   1.3167645   0.6934288\n",
      "  0.17198846  0.8149964   1.6986055   1.7362796   1.4621954   1.124013\n",
      "  0.6923408   2.25088     1.7182934   0.02928101  0.5532897   1.7125074\n",
      "  1.8238257   1.6623533   0.2339667   0.5214959   1.8290046   1.4789233\n",
      "  1.8521488   1.5854301   1.7513572   1.3953363   1.5755287  -0.631994\n",
      "  1.3236384   1.2105744 ]\n",
      "[ 1.87408045e-01  1.93783030e-01 -3.04888815e-01 -4.28681910e-01\n",
      " -8.89758289e-01  2.53818011e+00  1.84245372e+00  1.95446432e-01\n",
      " -1.16462326e+00 -1.30026734e+00  3.29686761e-01 -1.15002656e+00\n",
      "  7.58503199e-01 -5.55404484e-01 -1.31284192e-01 -1.98697424e+00\n",
      " -1.52085304e+00 -7.36282408e-01 -3.44638079e-01  1.14247613e-01\n",
      "  5.51977418e-02  5.17503135e-02 -6.70727491e-01 -1.80045772e+00\n",
      " -2.03538701e-01 -2.20866275e+00  9.33753371e-01 -1.68451309e-01\n",
      " -1.34207651e-01 -1.54052794e+00  2.85064466e-02 -1.89342439e+00\n",
      " -1.81133479e-01  4.55205381e-01 -1.32552660e+00 -2.10278606e+00\n",
      "  2.04387951e+00  1.26353249e-01 -1.18129444e+00  4.61253673e-02\n",
      " -4.53257710e-02 -7.73015097e-02 -4.99792933e-01  4.76269215e-01\n",
      "  6.19692206e-01  1.32884014e+00  1.09734107e-02 -7.30557084e-01\n",
      "  2.58232832e+00 -1.08645701e+00 -3.72181445e-01 -1.05514264e+00\n",
      " -1.42082798e+00 -9.14033830e-01  9.59483027e-01  9.26068425e-01\n",
      " -1.82412386e-01  1.45311546e+00  1.32280231e+00  5.70940375e-01\n",
      " -1.81623483e+00  2.13636860e-01 -1.62209761e+00 -4.86774325e-01\n",
      "  5.94647169e-01 -6.61601901e-01 -9.46438372e-01 -1.23459387e+00\n",
      "  9.25179541e-01 -1.59054697e+00  7.42787123e-02 -6.48343980e-01\n",
      "  7.54679918e-01  1.07259774e+00  2.89246082e+00  1.80926049e+00\n",
      " -4.01425928e-01 -7.80813336e-01  1.40771151e+00 -1.20139802e+00\n",
      " -1.93504429e+00 -4.21446562e-01  1.44927049e+00 -6.56899139e-02\n",
      "  1.58644128e+00  3.87513965e-01  2.08339095e+00  1.53677434e-01\n",
      "  2.10091448e+00  5.57885915e-02  3.39656144e-01 -1.24816775e+00\n",
      " -8.16538095e-01 -1.34294355e+00 -1.05581558e+00 -3.04854155e-01\n",
      " -1.64951253e+00  5.44690847e-01 -6.03389442e-01 -1.07067287e+00\n",
      "  2.17059344e-01  5.35986483e-01  1.73255634e+00  8.94628882e-01\n",
      " -1.49258447e+00 -5.12296438e-01 -1.00464022e+00  1.99437439e+00\n",
      " -5.26526451e-01  4.48604405e-01  1.10029191e-01 -1.08206892e+00\n",
      " -5.46499372e-01 -7.14130938e-01 -2.05196285e+00  1.65722072e+00\n",
      " -3.24704081e-01 -1.88028619e-01 -8.07847559e-01 -4.93024625e-02\n",
      "  1.27070796e+00  1.50716138e+00 -2.58309007e+00  9.61104780e-02\n",
      "  1.58188605e+00  1.90752804e+00 -7.71354914e-01  4.85750526e-01\n",
      " -7.88635015e-02 -6.53200269e-01 -1.67809927e+00  8.48788977e-01\n",
      " -8.95294607e-01 -1.20332646e+00  8.96479130e-01  1.19035363e+00\n",
      " -1.61297274e+00 -8.42331529e-01  1.64000368e+00 -1.26859888e-01\n",
      " -1.86711335e+00 -7.02034354e-01 -1.54911399e+00  2.18299556e+00\n",
      "  4.80193272e-02  1.95970261e+00 -1.49863160e+00 -8.74775589e-01\n",
      "  2.68102109e-01  1.46338427e+00  6.47608280e-01  3.54497820e-01\n",
      "  4.77575302e-01  8.09589326e-02  6.10503376e-01 -1.22000296e-02\n",
      " -2.19488859e+00  8.27188253e-01  9.14248168e-01 -1.57662794e-01\n",
      " -9.93650198e-01 -5.57158828e-01 -4.08541918e-01 -8.36138308e-01\n",
      " -3.66106153e-01  6.59654010e-03  4.31155026e-01 -4.68805343e-01\n",
      "  1.24006629e+00  2.48953030e-01 -4.29075569e-01 -7.33681798e-01\n",
      "  1.05159569e+00  1.25525761e+00  8.66790712e-01 -1.18876803e+00\n",
      "  9.23403800e-01  4.13883418e-01  7.40387321e-01  1.92086667e-01\n",
      " -1.05182445e+00  7.54307568e-01 -8.96081209e-01 -1.63397038e+00\n",
      " -1.18152030e-01  5.26866257e-01  2.67680362e-02  8.99130821e-01\n",
      " -4.58153218e-01  5.71541965e-01  2.26988387e+00  5.83241224e-01\n",
      " -3.44674438e-01 -2.94671893e-01  2.07315230e+00 -4.06090081e-01\n",
      "  1.19317122e-01  2.87041903e-01 -2.25766253e+00 -7.00918287e-02\n",
      "  1.64006308e-01  1.42440665e+00 -2.58796185e-01 -4.81902063e-01\n",
      "  3.11326712e-01 -6.54646456e-01 -9.02652383e-01 -1.09993887e+00\n",
      " -1.65524423e+00 -3.89282882e-01  1.34367153e-01  1.41877866e+00\n",
      " -3.85493964e-01 -4.87042570e+00 -2.04757285e+00 -4.49187569e-02\n",
      " -4.66490448e-01  1.10476568e-01  1.27787024e-01  1.82792664e+00\n",
      "  9.95891929e-01  9.19151962e-01 -1.13219976e+00 -1.93746835e-02\n",
      "  2.45655358e-01 -3.28448319e+00  2.94275939e-01 -6.18266046e-01\n",
      " -2.74246716e+00 -1.81948972e+00  1.36814928e+00 -1.29082882e+00\n",
      "  9.41701829e-01  3.71059561e+00  3.28793287e-01 -1.17292571e+00\n",
      "  1.17559627e-01 -2.08332086e+00 -7.65096247e-01  1.19450676e+00\n",
      " -1.22635460e+00 -1.30133069e+00 -1.04017818e+00 -4.38558310e-01\n",
      "  5.72342813e-01 -5.34591675e-01 -2.51329541e-01  1.39786804e+00\n",
      "  2.60798669e+00 -1.21453655e+00  4.19410914e-01 -8.38756263e-01\n",
      " -2.53475928e+00  7.21427202e-01 -3.06464696e+00 -3.39216255e-02\n",
      "  1.76474369e+00 -6.53309882e-01  2.05898023e+00 -7.62747347e-01\n",
      "  1.49996233e+00 -7.51134276e-01 -9.13352609e-01 -1.23641574e+00\n",
      " -6.16014779e-01  3.51504803e-01  1.88877225e-01 -1.27203572e+00\n",
      " -1.03961670e+00  2.32240200e+00  3.27269554e-01  1.50283590e-01\n",
      " -9.88116682e-01  1.17300844e+00  1.35909629e+00 -7.54496634e-01\n",
      " -1.79999486e-01  6.87945127e-01  8.45699534e-02  9.76919942e-03\n",
      "  2.05774665e+00 -4.69991475e-01 -8.89930665e-01 -4.98088211e-01\n",
      "  1.91328466e+00 -4.03901339e+00 -1.81554943e-01 -6.11749351e-01\n",
      " -5.29259622e-01  1.41266942e+00  8.24434876e-01  2.31413886e-01\n",
      "  2.17276287e+00  1.58423638e+00  1.82641530e+00  1.42429268e+00\n",
      " -1.01047075e+00  1.77271438e+00 -1.80845141e+00  2.50101984e-01\n",
      " -1.30005825e+00  7.04529047e-01  7.42530704e-01  1.03331316e+00\n",
      "  2.61978656e-01 -7.73024261e-01  3.70568246e-01  6.57593906e-01\n",
      "  1.07779443e+00 -9.06722724e-01  6.59657180e-01 -1.56131709e+00\n",
      " -1.93758619e+00  3.78784895e-01 -1.43185484e+00 -3.39464933e-01\n",
      "  3.87908906e-01 -8.36645305e-01 -4.41864312e-01 -1.39326787e+00\n",
      " -6.34611726e-01  9.49837446e-01 -1.28063846e+00 -4.69488680e-01\n",
      " -1.95103967e+00 -3.21913838e-01  3.96829605e-01  1.17262256e+00\n",
      "  2.64087033e+00 -1.54439056e+00  1.04241394e-01  7.55151510e-01\n",
      "  3.79146308e-01  1.48300922e+00  1.07817888e+00  3.94679487e-01\n",
      "  6.53725088e-01  1.69720948e+00 -9.20517087e-01 -3.11581837e-03\n",
      "  2.12996054e+00  2.47446179e-01  2.31672812e+00  7.35952616e-01\n",
      "  1.09304857e+00 -4.79795605e-01 -6.74501956e-01  2.99440694e+00\n",
      "  5.15301600e-02 -1.79804575e+00  1.08208370e+00  1.30313134e+00\n",
      "  3.67158115e-01 -1.02604604e+00  9.79299605e-01  1.37126184e+00\n",
      " -1.91298747e+00  1.48201132e+00 -1.13670397e+00  5.69424868e-01\n",
      "  3.45600456e-01 -1.96361840e+00 -1.04491353e+00 -3.08140427e-01\n",
      " -9.03258473e-02 -4.25907403e-01 -1.91026822e-01 -2.10771099e-01\n",
      "  2.18062133e-01 -2.12250948e-02 -2.27479315e+00 -2.31363252e-01\n",
      "  8.68288696e-01 -1.78084886e+00  1.56456554e+00 -9.15543139e-01\n",
      "  9.93267417e-01 -7.83904731e-01 -8.16677630e-01  1.47516930e+00\n",
      " -7.78365791e-01 -1.03630638e+00  1.53139257e+00 -1.40700722e+00\n",
      "  2.99815267e-01  1.05889849e-01  6.35305047e-01 -1.57772267e+00\n",
      "  3.08161688e+00 -4.60459590e-01  2.54424930e-01  6.46299481e-01\n",
      " -2.19260788e+00  1.39858258e+00  3.11363470e-02 -1.07304358e+00\n",
      " -1.21859527e+00  2.72123337e+00 -4.84400481e-01 -1.30505598e+00\n",
      " -1.62547588e-01  4.20791626e-01  2.55833626e-01  5.20053506e-01\n",
      " -1.32503903e+00 -1.12589073e+00 -1.18300714e-01 -1.28820646e+00\n",
      "  1.67902440e-01 -3.52822617e-02  1.14417148e+00 -2.03164244e+00\n",
      "  1.86014521e+00  8.35412979e-01 -8.04118335e-01 -2.67687607e+00\n",
      " -5.83714843e-01  2.25626683e+00  1.12533891e+00 -3.16953421e+00\n",
      " -1.03781730e-01  1.04688212e-01  2.50196338e-01  1.90800083e+00\n",
      "  6.22030795e-01 -2.12139368e+00 -6.59646869e-01 -3.36699635e-01\n",
      "  2.44673386e-01 -2.21483064e+00 -5.15917659e-01 -8.60291421e-01\n",
      "  5.11357725e-01 -9.28200245e-01 -2.97368377e-01  2.43987131e+00\n",
      " -1.30632555e+00 -5.61369002e-01  8.76376748e-01  8.71825576e-01\n",
      " -1.42876816e+00  2.75808334e-01  1.27113283e+00  2.71628559e-01\n",
      " -1.50006509e+00  1.27023792e+00 -2.44821072e+00 -1.10526752e+00\n",
      "  7.37839997e-01 -1.36480856e+00  1.84612536e+00 -1.18547313e-01\n",
      " -1.26238108e+00  5.81614554e-01 -9.90620613e-01  9.91465058e-03\n",
      " -9.24524724e-01  7.68863380e-01 -2.47863278e-01  7.33914554e-01\n",
      " -4.15319264e-01 -1.25888872e+00 -1.72475600e+00  9.04729843e-01\n",
      "  5.83219767e-01 -1.31444478e+00  1.97032783e-02  6.88730419e-01\n",
      " -2.17980576e+00 -7.13450074e-01 -1.32471418e+00  1.91179013e+00\n",
      "  1.99038267e-01  7.93340445e-01 -2.31709644e-01 -3.69853526e-02\n",
      " -1.64850664e+00  2.76309609e-01  7.21243978e-01  2.03477049e+00\n",
      " -1.54133976e+00  8.36427331e-01  1.62972823e-01 -2.80669242e-01\n",
      " -1.31322658e+00 -1.65065274e-01  1.26081896e+00 -4.77948099e-01\n",
      "  1.82398760e+00  7.94149160e-01 -1.54036558e+00  9.65361178e-01\n",
      "  2.96127987e+00  3.63823920e-01  2.46423513e-01  1.53103769e+00\n",
      "  1.19943433e-01  5.96316397e-01  3.92851502e-01  1.13400352e+00\n",
      "  1.37149000e+00 -1.60719585e+00 -2.87735581e+00 -1.22882694e-01\n",
      " -9.76942003e-01 -1.88396347e+00  2.49044155e-03  3.62812161e-01\n",
      " -1.10971737e+00  1.64863276e+00 -1.26777244e+00 -5.35632193e-01]\n",
      "[0.6661935  0.76724124 0.44926316 0.86205626 0.774597   0.88086003\n",
      " 0.47661924 0.7691022  0.41126823 2.2304442  0.37280813 0.8052378\n",
      " 0.98258513 0.51125884 1.4263896  0.4937638  0.5343906  0.5011482\n",
      " 0.4741635  0.951781   0.47306055 2.0430586  0.84932595 0.84421825\n",
      " 1.3545758  0.8541305  1.4184784  0.6035682  0.6436265  0.5238359\n",
      " 0.576994   0.7520263  0.49980888 0.44560954 1.190857   0.6342985\n",
      " 0.4389236  0.40970814 1.2453985  0.33927637 0.46600804 0.58779687\n",
      " 0.5148744  0.7207446  0.5704188  0.45779255 0.90762115 0.52788055\n",
      " 0.8103011  1.0783156  0.5479386  0.72372425 0.6772966  1.6297957\n",
      " 1.0365953  1.0732114  0.6384746  0.7002119  0.589441   0.62218446\n",
      " 0.9065715  0.42844427 0.65759504 0.9150109  0.3076807  0.6794757\n",
      " 0.86187375 0.5308645  1.1821738  0.8047972  1.027307   0.5426692\n",
      " 0.9647739  0.4037306  0.99316204 0.67896867 0.5676245  0.6463913\n",
      " 0.6801881  0.49796382 1.6007926  0.33540335 1.1877404  0.44602135\n",
      " 0.5471205  0.49190488 0.58498776 0.65269864 0.69318116 0.5943211\n",
      " 0.66030294 0.48540285 0.6427831  0.54555285 0.51229185 1.6174291\n",
      " 0.66767937 0.3132585  0.66007876 0.6143734  0.56487244 0.5978164\n",
      " 0.7643252  0.49621654 0.748752   1.3611592  0.7053405  0.5054414\n",
      " 0.60417515 0.2671131  0.7223904  0.61230993 2.0867007  0.50977874\n",
      " 0.56072205 2.132394   0.9894344  0.64361763 0.49067798 0.34268904\n",
      " 0.5171894  0.34895894 0.7624087  0.53318226 0.87782985 1.3001056\n",
      " 0.7980248  0.93160975 1.2482275  1.3323513  0.62245595 0.7460457\n",
      " 0.44748545 0.39714077 1.1866909  0.46089092 0.7842017  1.0382932\n",
      " 1.4360635  0.46958068 1.0937482  1.2331847  0.83895093 0.75338745\n",
      " 1.1708592  0.847272   0.5190851  1.074958   0.63148254 1.1066681\n",
      " 0.78343266 0.5654944  0.38772202 0.6903916  1.2466885  0.9153933\n",
      " 0.79268754 1.0048386  1.086143   0.6574788  0.6662859  0.8761873\n",
      " 0.6462916  1.1413891  0.8890511  0.60791713 0.49976534 0.6733919\n",
      " 0.70620793 0.70500886 0.6143294  0.35345995 0.6715331  0.49690452\n",
      " 0.36128977 0.661427   0.63831717 0.50985026 0.6208258  1.3138615\n",
      " 0.6042491  0.62438273 0.9755116  0.32088554 0.426057   0.4549344\n",
      " 0.5696067  0.46018025 0.34617886 1.1823883  0.7434565  0.6819447\n",
      " 0.880769   0.6453801  0.89308894 0.45789936 0.46239635 0.44584382\n",
      " 1.1701838  1.0475026  0.8483665  0.6730409  0.5421425  0.5815532\n",
      " 0.9952094  1.0834613  0.7737434  0.8422465  0.7708027  1.2523211\n",
      " 0.23662086 0.6096249  0.6413514  0.7550822  0.5538009  0.3517507\n",
      " 0.5663143  1.0622278  1.281581   0.85398966 0.7014676  0.6310238\n",
      " 1.5426416  0.5185715  0.4575889  1.1890339  0.86839044 0.7297792\n",
      " 0.39983585 1.1509203  1.0268489  1.2583357  0.59155047 0.9054173\n",
      " 0.6707578  0.65129155 0.440988   0.5676201  0.41377398 0.7894055\n",
      " 0.5409977  0.35138547 0.98584664 0.47480327 0.3831234  0.97805196\n",
      " 0.84511685 0.68926376 0.49447736 0.87632823 0.8911617  1.152185\n",
      " 0.42559183 0.8292734  1.4051586  0.46987748 0.69539064 0.6605475\n",
      " 0.56574786 0.46421716 0.6275325  0.5036284  1.1239649  0.58214086\n",
      " 1.0347372  0.50565654 1.5967218  0.9183598  0.43576226 0.5661092\n",
      " 0.9137409  0.5863295  0.40608266 1.1245272  1.2813987  0.4883852\n",
      " 0.85470086 0.41505015 1.5353501  0.43046573 0.4911751  1.318103\n",
      " 0.7662748  0.8554616  2.3923144  0.7808463  0.34270072 0.68075323\n",
      " 0.4817729  0.58854127 0.41192895 0.534604   0.5092972  0.6004053\n",
      " 1.6414615  0.8253524  0.9439916  1.0935189  0.7349661  0.73019034\n",
      " 0.609966   0.40667328 1.2603241  0.52547556 0.47952646 0.72012454\n",
      " 0.33027488 0.8755989  0.8159126  0.52116996 0.57856095 1.5011076\n",
      " 1.1252404  0.6475984  2.0282454  0.9977843  0.9860198  1.7765218\n",
      " 0.43037933 1.159527   1.5574697  0.56010914 0.6682624  0.35425717\n",
      " 0.5759267  0.65707797 0.43494412 0.58389515 2.1998143  1.4523371\n",
      " 0.49020314 0.5610136  1.1238809  0.46635008 0.49204153 0.5203758\n",
      " 1.6112446  0.8993916  0.48353463 0.44358373 0.9547963  0.48060113\n",
      " 1.6117177  0.8154227  0.3778155  0.76481575 0.50645643 0.49978977\n",
      " 0.53250855 0.6696885  1.2800645  0.64497983 0.30060378 0.72569466\n",
      " 0.42047113 0.64794683 0.80370927 0.8923044  0.9206999  0.7164518\n",
      " 0.78662074 0.826259   0.81230444 0.42415267 1.7603655  0.3814116\n",
      " 0.69082177 0.36558142 1.1469201  0.807166   0.8923151  0.80832946\n",
      " 0.67736906 0.5543961  0.8969912  0.775529   0.46221742 0.98283553\n",
      " 0.8172876  1.3043456  0.7519327  0.5126975  1.0833559  0.8366588\n",
      " 0.4631418  1.1405576  0.5856383  0.99917156 2.813282   0.3172802\n",
      " 0.3746325  0.84674996 0.66631263 0.4487642  1.1309003  0.79686344\n",
      " 0.5825932  1.188662   1.2832625  0.6526686  0.40886265 1.3998545\n",
      " 0.3846985  1.2876347  1.769063   0.88222957 1.4268107  0.61564845\n",
      " 0.70869815 0.42843077 0.35652202 0.6604978  0.6959078  0.6138514\n",
      " 1.1363324  0.49497122 0.4438337  1.2233903  1.1167339  0.9533168\n",
      " 0.83595276 0.5960664  0.6273058  0.61632663 0.47639632 0.68999976\n",
      " 0.61803365 1.6003034  0.81323797 0.6437765  0.76658446 0.91378325\n",
      " 1.5294776  1.1264206  0.9794282  1.3487093  0.64999634 0.6188404\n",
      " 0.7551378  0.62104064 0.57887924 0.7446987  0.7731916  0.57094973\n",
      " 0.6472226  0.66827387 0.74997145 0.8630593  0.6060421  0.5050721\n",
      " 0.5134153  0.44614378 0.4980495  0.5393749  0.27626494 0.6151633\n",
      " 0.8076372  0.65033686 0.722314   1.3820717  0.32201633 0.62277216\n",
      " 0.46667388 0.7433843  0.68391174 0.78343993 0.6411866  0.5450273\n",
      " 0.39613104 0.705406   0.5812178  0.96526223 0.6526351  0.8270359\n",
      " 0.832888   0.5937488  1.1889441  0.5006405  0.7309263  0.7454246\n",
      " 0.5112521  1.0118564  0.86380345 0.758455   0.8883929  0.65058947\n",
      " 0.53816426 1.0343498  0.82138634 0.8499277  0.657736   0.42028406\n",
      " 0.36046246 0.68475026 0.74520075 0.4651368  0.5406886  0.88264143\n",
      " 0.534937   1.0973064  0.6755496  0.75490576 1.2818658  0.74120134\n",
      " 0.8607286  0.7077736  0.9092043  0.8133149  0.82401735 0.64255315\n",
      " 0.69955045 0.4056401 ]\n"
     ]
    }
   ],
   "source": [
    "import math as m\n",
    "layer42 = model.layers[42]\n",
    "W = np.array(layer42.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "batchNorm = model.layers[42].get_weights()\n",
    "\n",
    "fMean = open(\"data/ThirteenthLayer/Thirteenth_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/ThirteenthLayer/Thirteenth_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/ThirteenthLayer/Thirteenth_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/ThirteenthLayer/Thirteenth_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_ThirteenthLayer():\n",
    "    fExp = open('data/ThirteenthLayer/Thirteenth_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/ThirteenthLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "        try:\n",
    "            if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "                counter += 1\n",
    "                if(counter < 30):\n",
    "                    print(str(cAct[i].strip()) + \"--->\" + str(cExp[i].strip()) + \"  ----> \" + str(i))\n",
    "        except:\n",
    "            print(\"Error\" + str(i))\n",
    "            try:\n",
    "                abc = int(round(float(cExp[i].strip())))\n",
    "            except:\n",
    "                print(\"here \")\n",
    "            \n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.499935--->1.5000932  ----> 8753\n",
      "0.500180--->0.49985892  ----> 13145\n",
      "1.499723--->1.5006182  ----> 13952\n",
      "1.499504--->1.5003437  ----> 13996\n",
      "1.499421--->1.5001069  ----> 14051\n",
      "1.499999--->1.5000141  ----> 20721\n",
      "0.499571--->0.5008404  ----> 21192\n",
      "2.500093--->2.4996662  ----> 63779\n",
      "Number of mismatch - 8\n"
     ]
    }
   ],
   "source": [
    "checkFile_ThirteenthLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
