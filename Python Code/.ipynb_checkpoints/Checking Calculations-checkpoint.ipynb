{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import Model\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import Conv3D\n",
    "\n",
    "fileName = \"Trump.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "# Global MobileNets model\n",
    "mobile = keras.applications.mobilenet.MobileNet(weights=\"imagenet\")\n",
    "model = Model(mobile.input, mobile.layers[21].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_input(fileName, X):\n",
    "    fhandler = open(fileName, \"w\")\n",
    "    for i in range(3):\n",
    "        for j in range(224):\n",
    "            for k in range(224):\n",
    "                fhandler.write(str(X[j][k][i]) + \"\\n\")\n",
    "    fhandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_Input_Files():\n",
    "    \n",
    "    img_width = 224\n",
    "    img_height = 224\n",
    "\n",
    "    img = image.load_img(fileName, target_size=(img_width, img_height))\n",
    "    X = image.img_to_array(img)\n",
    "\n",
    "    # Normalizing the Input\n",
    "    X = tf.keras.utils.normalize(X, axis=2)\n",
    "    \n",
    "    # Write Normalized Input to file\n",
    "    write_to_file_input(\"data/FirstLayer/inputNorm.txt\", X)\n",
    "    \n",
    "    \n",
    "    # Write combination input to file\n",
    "    X[:, :, 0] = 1\n",
    "    X[:, :, 1] = 10\n",
    "    X[:, :, 2] = 100\n",
    "    write_to_file_input(\"data/FirstLayer/inputComb.txt\", X)\n",
    "    \n",
    "    # Write all 1's input to file\n",
    "    X[:, :, 0] = 1\n",
    "    X[:, :, 1] = 1\n",
    "    X[:, :, 2] = 1\n",
    "    write_to_file_input(\"data/FirstLayer/inputSet1.txt\", X)\n",
    "\n",
    "    print(\"Creating Input files Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_Input_Files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_one(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(32):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = model.layers[2].get_weights()[0]\n",
    "write_to_file_weights_layer_one(\"data/FirstLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_one(\"data/FirstLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_second(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(32):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = model.layers[5].get_weights()[0]\n",
    "write_to_file_weights_layer_second(\"data/SecondLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_second(\"data/SecondLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkCalculations():\n",
    "\n",
    "    img_width = 224\n",
    "    img_height = 224\n",
    "\n",
    "    img = image.load_img(fileName, target_size=(img_width, img_height))\n",
    "    X = image.img_to_array(img)\n",
    "\n",
    "    # Normalized the Input\n",
    "    X = tf.keras.utils.normalize(X, axis=2)\n",
    "    \n",
    "    # Set as 1\n",
    "    #X[:,:,0] = 1\n",
    "    #X[:,:,1] = 1\n",
    "    #X[:,:,2] = 1\n",
    "\n",
    "    # Set as Combination\n",
    "    #X[:,:,0] = 1\n",
    "    #X[:,:,1] = 10\n",
    "    #X[:,:,2] = 100\n",
    "\n",
    "    print(X[0][0][0])\n",
    "    print(X[0][1][0])\n",
    "    print(X[0][2][0])\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    print(X.shape)\n",
    "\n",
    "    # Weights part\n",
    "    W = model.layers[2].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[2].set_weights(W)\n",
    "    \n",
    "    \n",
    "    W = model.layers[5].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[5].set_weights(W)\n",
    "    \n",
    "    W = model.layers[8].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[8].set_weights(W)\n",
    "    \n",
    "    W = model.layers[12].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[12].set_weights(W)\n",
    "    \n",
    "    W = model.layers[15].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[15].set_weights(W)\n",
    "    \n",
    "    W = model.layers[18].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[18].set_weights(W)\n",
    "    \n",
    "    \n",
    "    output = model.predict(X)\n",
    "    print(\"Output Shape ---> \")\n",
    "    print(output.shape)\n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "    # Save Output to file\n",
    "    fOutput = open(\"data/SixthLayer/Sixth_Layer_Output.txt\", \"w\")\n",
    "    for i in range(len(output)):\n",
    "        for j in range(len(output[0][0][0])):\n",
    "            for k in range(len(output[0])):\n",
    "                for l in range(len(output[0][0])):\n",
    "                    fOutput.write(str(output[i][k][l][j]) + \"\\n\")\n",
    "    fOutput.close()\n",
    "    print(\"Output File Writing Complete!!!\")\n",
    "\n",
    "    print(\"\\n\\n Description of Layers\")\n",
    "    for layer in model.layers:\n",
    "        print(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:2198: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return sqrt(add.reduce(s, axis=axis, keepdims=keepdims))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.145017\n",
      "0.351735\n",
      "0.563547\n",
      "(1, 224, 224, 3)\n",
      "Output Shape ---> \n",
      "(1, 56, 56, 128)\n",
      "--------------------------------\n",
      "Output File Writing Complete!!!\n",
      "\n",
      "\n",
      " Description of Layers\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fda1f1c6a58>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fda1f1c6748>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fda1f1c6cc0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda1f29b278>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda1f31ba58>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fda1f287ac8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda28fe47b8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda17081da0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fda1f14fdd8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda1f165e80>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda1f12c3c8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fda1f084ac8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fda1f084b38>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda1efdb898>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda1efdbd68>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fda1ef8af98>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda1efbdd68>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda1ef082b0>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fda1eedd9b0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda1eea3b00>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda1ee61048>\n",
      "Total Time --> 5.233251094818115\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "checkCalculations()\n",
    "end = time.time()\n",
    "print(\"Total Time -->\", (end - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 6 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_SixthLayer():\n",
    "    fExp = open('data/SixthLayer/Sixth_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/SixthLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    mismatchStart = 0;\n",
    "    boo = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            if(boo < 500):\n",
    "                boo += 1\n",
    "                print(str(cAct[i].strip()) + \"  --->   \" + str(cExp[i].strip()) + \" <---- \" + str(i) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    print(mismatchStart)\n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500014  --->   0.499986 <---- 5299\n",
      "2.500029  --->   2.5 <---- 12677\n",
      "0.499984  --->   0.500016 <---- 30045\n",
      "0.499934  --->   0.500131 <---- 248054\n",
      "0.499856  --->   0.500051 <---- 249042\n",
      "0.500026  --->   0.499958 <---- 341187\n",
      "Number of mismatch - 6\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "checkFile_SixthLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 5 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_FifthLayer():\n",
    "    fExp = open('data/FifthLayer/Fifth_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/FifthLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            print(str(cAct[i].strip()) + \"  --->   \" + str(cExp[i].strip()) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkFile_FifthLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 1 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_FirstLayer():\n",
    "    fExp = open('data/FirstLayer/First_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/FirstLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mismatch - 388864\n"
     ]
    }
   ],
   "source": [
    "checkFile_FirstLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 4 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_FourthLayer():\n",
    "    fExp = open('data/FourthLayer/Fourth_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/FourthLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            print(str(cAct[i].strip()) + \"--->\" + str(cExp[i].strip()) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkFile_FourthLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 2 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checkFile_SecondLayer():\n",
    "    fExp = open('data/SecondLayer/Second_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/SecondLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            print(str(cAct[i].strip()) + \"--->\" + str(cExp[i].strip()) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkFile_SecondLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_ThirdLayer():\n",
    "    fExp = open('data/ThirdLayer/Third_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/ThirdLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 6 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.17376578  0.92570347  1.33578944  0.76546639  0.88438272  1.28590727\n",
      "  0.64942753  1.40510738  1.05130637  1.72453225  0.9786219   1.67618835\n",
      "  0.58891213  1.50489914  1.79923272  2.04591084  1.34045398  0.81471074\n",
      "  0.99819231  0.89749551  1.47205436  1.69671047  1.45804167  0.6779514\n",
      "  0.94730163  1.63231707  2.26928258  1.84552538  1.11021316  1.17338729\n",
      "  1.29545557  2.00494432  2.32145643  1.48001683  1.37820995  1.05569613\n",
      "  1.46535122  0.66719675  0.95240086  7.10886765  1.99117792  0.85256547\n",
      "  2.21908903  1.20690072  1.69672048  0.94427353  3.62987256  0.92673427\n",
      "  1.22302294  1.07908344  1.08553994  1.00814819  1.09811568  1.27662528\n",
      "  1.04946864  1.33240819  1.17767119  1.200719    1.43957746  0.66142839\n",
      "  1.62856257  1.56319773  1.19957316  1.26731813  1.12130773  1.65475392\n",
      "  1.28627729  2.31529236  4.39884281  1.97971916  1.06841552  0.95823908\n",
      "  1.17420721  1.62769365  1.38963318  1.01462626  0.86462164  1.54941881\n",
      "  1.35129344  1.17098308  0.76067418  0.94015956  0.72020191  1.56491935\n",
      "  2.03240156  1.3279444   1.13324714  1.38579226  1.5140686   1.45908129\n",
      "  1.27209127  0.83640563  1.67506766  1.13486207  1.04992676  1.06743562\n",
      "  0.72675216  1.77436161  0.75012028  0.86915714  1.18154442  0.50819468\n",
      "  1.73744273  1.22357368  0.76849401  0.89601618  1.07886708  1.37949109\n",
      "  1.12686002  1.53349817  0.70203727  1.60559881  0.77601296  1.62249327\n",
      "  3.12489629  1.22871459  1.65109372  1.04824734  0.58185148  0.95162141\n",
      "  0.69721955  3.97329402  0.85076779  1.47501397  0.69098943  1.29685533\n",
      "  1.29523468  2.28140354]\n",
      "[ 0.72143465  0.01363674  0.05389157  5.05492496  2.49030423 -1.059587\n",
      " -0.40610358 -0.26670736 -0.23595124 -0.43631679  3.56390285  0.15713345\n",
      "  0.04360056 -0.015995   -0.07100134  2.56553316 -0.35836366 -1.17873263\n",
      "  0.15068009  2.44716811 -0.05382602  0.00852313 -0.15267693  2.2692802\n",
      "  0.98935497  0.45503432  1.77241206  0.48598987 -0.19603463  0.62342739\n",
      " -0.28581443 -1.68366933 -1.29396343  5.51000786 -0.02630313  1.71006966\n",
      " -0.45583376  1.74399924  1.91439617  2.29675508  0.87310314  1.45533311\n",
      "  2.4629128  -0.00800036  1.76306212 -1.18711591  3.93522739  3.79581332\n",
      "  0.02762886  1.53619325  0.31614617 -0.08858164  0.86725718 -0.08668464\n",
      "  3.14633536  5.34504795 -0.00735868  0.58026201  0.88394499  1.524876\n",
      " -0.2799972   0.63548577 -0.8487798  -0.0197631  -0.03428796 -0.17134026\n",
      " -0.01232282 -0.20907333  1.322492    0.19782865  0.1726096   0.46545157\n",
      "  2.98773122  0.05923635  0.0192916   2.11264873  3.45107317  0.15503553\n",
      "  1.16716337  0.79630387  3.41199231  2.28103614 -1.18197358  0.64179146\n",
      "  0.0349035   0.06411094 -0.01636218  0.01400144  0.0223705   0.75868112\n",
      "  0.03154705 -1.12465    -0.33665654 -0.03624693  3.19853497  0.04825925\n",
      "  2.91152072  0.299346    3.52241039  0.61567116  4.98891258  3.29594588\n",
      " -0.1974256   5.14031601  3.26431298  0.46737498  1.58523679 -0.09522966\n",
      "  0.72984499 -0.08363263  5.13377666  2.6981988   2.05323291  0.96600771\n",
      "  2.32890534 -1.59002006 -0.05867134  0.25444266  2.71917868  0.3952128\n",
      "  1.01329684  1.47243226  3.60865808 -0.04209217  4.90215921 -0.09545956\n",
      "  0.03944332 -0.2469881 ]\n",
      "[ -1.62857456e+01   2.36994550e-01   3.68160933e-01  -1.58168221e+00\n",
      "  -3.64298415e+00   1.02406514e+00   3.36134225e-01   7.03423977e+00\n",
      "   1.72216690e+00  -1.53163648e+00  -1.91409457e+00   1.92484006e-01\n",
      "   4.56330739e-02   2.82312840e-01  -1.82308555e+00  -2.26906109e+00\n",
      "   3.29711318e+00   9.53502581e-02   5.39282036e+00   1.59590340e+01\n",
      "  -5.78078270e-01  -1.00097692e+00   3.91717249e-35  -1.69104505e+00\n",
      "  -1.60801068e-01  -5.24731874e+00  -2.01815918e-01   4.58267093e-01\n",
      "   1.00542545e+00   1.74359590e-01   6.42381048e+00   9.26621914e+00\n",
      "  -2.69595795e+01   1.78625524e+00   1.85959613e+00  -1.44229203e-01\n",
      "   4.61823940e+00   3.10543686e-01  -8.22982043e-02  -1.75826386e-01\n",
      "   7.32099712e-01  -1.72647119e+00   2.04983354e+00  -3.46644968e-02\n",
      "  -3.22400308e+00   3.91766725e-35   1.27896145e-01  -1.62688696e+00\n",
      "   6.38542509e+00  -1.38984251e+01   9.66760874e-01  -3.32768989e+00\n",
      "  -1.53330767e+00   2.70483637e+00   1.99987459e+00  -1.04498279e+00\n",
      "   4.53105688e-01  -2.25654811e-01   4.86887068e-01   5.08301878e+00\n",
      "   1.15261326e+01   1.04510081e+00   2.62209558e+00   3.90204757e-01\n",
      "  -8.99654478e-02  -2.66094893e-01   1.06770444e+00  -6.80564225e-01\n",
      "   3.39944363e-01  -5.42577505e-01   5.43082094e+00   8.67362201e-01\n",
      "  -9.42090005e-02   8.07936311e-01   2.28375182e-01   4.27778065e-02\n",
      "  -7.46880412e-01   9.72988755e-02   1.86985981e+00   3.06159782e+00\n",
      "   8.01661849e-01   1.49351206e+01   3.91756652e-35   1.90995574e-01\n",
      "  -1.07430443e-01   1.00079119e+00  -3.03950691e+00   5.91260970e-01\n",
      "  -2.02048838e-01  -1.33536386e+00   1.82889390e+00   3.91733062e-35\n",
      "  -1.10508022e+01   4.86638211e-03   6.56612921e+00   9.79586184e-01\n",
      "  -4.95578623e+00   1.38369128e-01  -1.84351528e+00   2.26834512e+00\n",
      "  -3.66257572e+00  -1.16146708e+00   1.92451513e+00   3.38294244e+00\n",
      "  -5.02274632e-01   2.50613785e+00   3.72205186e+00   7.17671335e-01\n",
      "   2.50098443e+00  -5.18723869e+00  -1.37048221e+00  -2.91559160e-01\n",
      "   1.92680669e+00  -1.98285460e+00  -3.08727050e+00   1.31152964e+00\n",
      "  -1.42882776e+00   5.41563988e+00  -2.15205574e+00   2.01092219e+00\n",
      "  -5.92545319e+00  -5.48168600e-01   3.58069211e-01  -5.08073688e-01\n",
      "  -9.95631337e-01  -8.23518157e-01   2.30404854e-01  -3.18591565e-01]\n",
      "[  3.76103210e+01   1.16115789e+01   3.29946976e+01   1.05694513e+01\n",
      "   3.80222917e+00   5.01570559e+00   2.82293534e+00   1.15944424e+01\n",
      "   7.49789524e+00   1.40843506e+01   1.24580240e+01   5.31352119e+01\n",
      "   3.56017232e-01   2.69156246e+01   3.57640743e+00   3.29109039e+01\n",
      "   4.33164501e+00   2.71569401e-01   1.94177265e+01   4.46240730e+01\n",
      "   1.82479362e+01   8.35522079e+01   3.91784059e-35   7.65668154e+00\n",
      "   1.29563093e+01   2.17927818e+01   6.23036575e+01   8.90553570e+00\n",
      "   1.44125929e+01   9.73539352e+00   1.67458553e+01   1.35288358e+00\n",
      "   3.32631798e+01   2.65456848e+01   1.47194748e+01   2.57456994e+00\n",
      "   1.09607992e+01   1.23434591e+01   3.61420441e+01   5.57796974e+01\n",
      "   3.87422943e+01   1.03648567e+01   3.68167877e+01   1.24355049e+01\n",
      "   2.82823429e+01   3.91750138e-35   1.08790314e+02   1.37621384e+01\n",
      "   2.17773457e+01   8.00522423e+00   4.09728546e+01   1.04315786e+01\n",
      "   2.72701225e+01   4.09051514e+01   1.19584866e+01   1.87313442e+01\n",
      "   8.32246628e+01   1.32809057e+01   7.25432110e+00   2.53678322e+01\n",
      "   2.61727695e+01   1.40628576e+01   1.13949747e+01   3.17351913e+01\n",
      "   1.19382162e+01   3.10877800e+00   2.61934662e+01   9.24599361e+00\n",
      "   5.83549385e+01   2.73752556e+01   1.71087036e+01   9.68938637e+00\n",
      "   2.64679699e+01   8.77896423e+01   1.43164787e+01   8.36222935e+00\n",
      "   1.64544144e+01   6.07497644e+00   4.14567680e+01   4.25868149e+01\n",
      "   6.91938066e+00   6.45029907e+01   3.91750396e-35   1.22446785e+01\n",
      "   7.09793167e+01   4.72387886e+01   2.06681466e+00   1.81621532e+01\n",
      "   3.37568665e+01   3.52695727e+00   9.28300552e+01   3.91784920e-35\n",
      "   4.41573572e+00   5.15706015e+00   1.06214409e+01   1.22181854e+01\n",
      "   1.37447462e+01   7.64488411e+00   1.07888832e+01   8.24712563e+00\n",
      "   1.00330257e+01   4.06247950e+00   1.05051718e+01   1.90270424e+01\n",
      "   2.46264291e+00   9.16028309e+00   4.98442497e+01   3.18259525e+01\n",
      "   2.99212666e+01   9.13469696e+01   8.12077999e+00   6.87551346e+01\n",
      "   8.64203739e+00   1.25060053e+01   6.45190811e+01   3.18356347e+00\n",
      "   6.86607838e+00   1.19642820e+01   8.85173225e+00   1.68207359e+01\n",
      "   4.25426369e+01   3.87855415e+01   7.90406895e+00   2.54926472e+01\n",
      "   5.51207066e+00   2.25328102e+01   2.42359695e+01   1.46592426e+01]\n"
     ]
    }
   ],
   "source": [
    "import math as m\n",
    "batchNorm = model.layers[19].get_weights()\n",
    "\n",
    "fMean = open(\"data/SixthLayer/Sixth_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/SixthLayer/Sixth_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/SixthLayer/Sixth_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/SixthLayer/Sixth_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 2 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "batchNorm = model.layers[6].get_weights()\n",
    "\n",
    "fMean = open(\"data/SecondLayer/Second_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/SecondLayer/Second_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/SecondLayer/Second_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/SecondLayer/Second_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 3  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_three(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(1):\n",
    "            for k in range(64):\n",
    "                for l in range(32):\n",
    "                    fTemp.write(str(W[i][j][l][k]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer8 = model.layers[8]\n",
    "W = np.array(layer8.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer8.get_weights()[0]\n",
    "write_to_file_weights_layer_three(\"data/ThirdLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_three(\"data/ThirdLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 3 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "batchNorm = model.layers[9].get_weights()\n",
    "\n",
    "fMean = open(\"data/ThirdLayer/Third_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/ThirdLayer/Third_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/ThirdLayer/Third_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/ThirdLayer/Third_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 4  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_four(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(64):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer12 = model.layers[12]\n",
    "W = np.array(layer12.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer12.get_weights()[0]\n",
    "write_to_file_weights_layer_four(\"data/FourthLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_four(\"data/FourthLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 5 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "layer16 = model.layers[16]\n",
    "W = np.array(layer16.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "batchNorm = model.layers[16].get_weights()\n",
    "\n",
    "fMean = open(\"data/FifthLayer/Fifth_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/FifthLayer/Fifth_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/FifthLayer/Fifth_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/FifthLayer/Fifth_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 4 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "layer13 = model.layers[13]\n",
    "W = np.array(layer13.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "fMean = open(\"data/FourthLayer/Fourth_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/FourthLayer/Fourth_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/FourthLayer/Fourth_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/FourthLayer/Fourth_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 5  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_five(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(128):\n",
    "            for k in range(1):\n",
    "                for l in range(64):\n",
    "                    fTemp.write(str(W[i][k][l][j]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer15 = model.layers[15]\n",
    "W = np.array(layer15.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer15.get_weights()[0]\n",
    "write_to_file_weights_layer_five(\"data/FifthLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_five(\"data/FifthLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 6  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_six(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(128):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                for l in range(1):\n",
    "                    fTemp.write(str(W[j][k][i][l]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7fda5f453a90>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fda5f441e10>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fda5f441c50>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f4f3e10>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f4cec50>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fda5f527a20>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f592e48>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f36ab00>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fda5f317d68>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f335b70>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f249e10>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fda5f26c780>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fda5f26c8d0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f1bdc88>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f1bdfd0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fda5f169c50>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f109a58>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f0a2e10>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fda5f047668>\n",
      "(1, 3, 3, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer18 = model.layers[18]\n",
    "W = np.array(layer18.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer18.get_weights()[0]\n",
    "write_to_file_weights_layer_six(\"data/SixthLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_six(\"data/SixthLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 7  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_seven(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(1):\n",
    "            for k in range(128):\n",
    "                for l in range(128):\n",
    "                    fTemp.write(str(W[i][j][l][k]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7fe7f7ffcef0>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fe78e7ce208>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe78e7ce470>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78e7ce630>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78e7cee80>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fe78e7ceac8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78e7cef28>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78df5d6a0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe78c65fa58>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78c623358>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78c5e7c88>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fe78c5bb588>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fe78c5bbfd0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78c4a36a0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78c4a37b8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe78c4d3fd0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78c487be0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78c44d240>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fe78c3aaac8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78c36c438>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78c300b38>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe78c2aeda0>\n",
      "(1, 1, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer21 = model.layers[21]\n",
    "W = np.array(layer21.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer21.get_weights()[0]\n",
    "write_to_file_weights_layer_seven(\"data/SeventhLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_seven(\"data/SeventhLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "layer22 = model.layers[2]\n",
    "W = np.array(layer22.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "fMean = open(\"data/SeventhLayer/Seventh_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/SeventhLayer/Seventh_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/SeventhLayer/Seventh_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/SeventhLayer/Seventh_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Layer Descriptions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7fe7f7ffcef0>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fe78e7ce208>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe78e7ce470>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78e7ce630>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78e7cee80>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fe78e7ceac8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78e7cef28>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78df5d6a0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe78c65fa58>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78c623358>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78c5e7c88>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fe78c5bb588>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fe78c5bbfd0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78c4a36a0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78c4a37b8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe78c4d3fd0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78c487be0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78c44d240>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fe78c3aaac8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78c36c438>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78c300b38>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe78c2aeda0>\n",
      "\n",
      "\n",
      " Weight Size\n",
      "(1, 1, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer21 = model.layers[21]\n",
    "W = np.array(layer21.get_weights())\n",
    "\n",
    "print(\"\\n\\n Weight Size\")\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
