{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import Model\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import Conv3D\n",
    "\n",
    "fileName = \"Trump.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "# Global MobileNets model\n",
    "mobile = keras.applications.mobilenet.MobileNet(weights=\"imagenet\")\n",
    "model = Model(mobile.input, mobile.layers[11].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_input(fileName, X):\n",
    "    fhandler = open(fileName, \"w\")\n",
    "    for i in range(3):\n",
    "        for j in range(224):\n",
    "            for k in range(224):\n",
    "                fhandler.write(str(X[j][k][i]) + \"\\n\")\n",
    "    fhandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_Input_Files():\n",
    "    \n",
    "    img_width = 224\n",
    "    img_height = 224\n",
    "\n",
    "    img = image.load_img(fileName, target_size=(img_width, img_height))\n",
    "    X = image.img_to_array(img)\n",
    "\n",
    "    # Normalizing the Input\n",
    "    X = tf.keras.utils.normalize(X, axis=2)\n",
    "    \n",
    "    # Write Normalized Input to file\n",
    "    write_to_file_input(\"data/FirstLayer/inputNorm.txt\", X)\n",
    "    \n",
    "    \n",
    "    # Write combination input to file\n",
    "    X[:, :, 0] = 1\n",
    "    X[:, :, 1] = 10\n",
    "    X[:, :, 2] = 100\n",
    "    write_to_file_input(\"data/FirstLayer/inputComb.txt\", X)\n",
    "    \n",
    "    # Write all 1's input to file\n",
    "    X[:, :, 0] = 1\n",
    "    X[:, :, 1] = 1\n",
    "    X[:, :, 2] = 1\n",
    "    write_to_file_input(\"data/FirstLayer/inputSet1.txt\", X)\n",
    "\n",
    "    print(\"Creating Input files Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_Input_Files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_one(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(32):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = model.layers[2].get_weights()[0]\n",
    "write_to_file_weights_layer_one(\"data/FirstLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_one(\"data/FirstLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_second(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(32):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = model.layers[5].get_weights()[0]\n",
    "write_to_file_weights_layer_second(\"data/SecondLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_second(\"data/SecondLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkCalculations():\n",
    "\n",
    "    img_width = 224\n",
    "    img_height = 224\n",
    "\n",
    "    img = image.load_img(fileName, target_size=(img_width, img_height))\n",
    "    X = image.img_to_array(img)\n",
    "\n",
    "    # Normalized the Input\n",
    "    X = tf.keras.utils.normalize(X, axis=2)\n",
    "    \n",
    "    # Set as 1\n",
    "    #X[:,:,0] = 1\n",
    "    #X[:,:,1] = 1\n",
    "    #X[:,:,2] = 1\n",
    "\n",
    "    # Set as Combination\n",
    "    #X[:,:,0] = 1\n",
    "    #X[:,:,1] = 10\n",
    "    #X[:,:,2] = 100\n",
    "\n",
    "    print(X[0][0][0])\n",
    "    print(X[0][1][0])\n",
    "    print(X[0][2][0])\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    print(X.shape)\n",
    "\n",
    "    # Weights part\n",
    "    W = model.layers[2].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[2].set_weights(W)\n",
    "    \n",
    "    \n",
    "    W = model.layers[5].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[5].set_weights(W)\n",
    "    \n",
    "    W = model.layers[8].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[8].set_weights(W)\n",
    "    \n",
    "    \n",
    "    output = model.predict(X)\n",
    "    print(\"Output Shape ---> \")\n",
    "    print(output.shape)\n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "    # Save Output to file\n",
    "    fOutput = open(\"data/ThirdLayer/Third_Layer_Output.txt\", \"w\")\n",
    "    for i in range(len(output)):\n",
    "        for j in range(len(output[0][0][0])):\n",
    "            for k in range(len(output[0])):\n",
    "                for l in range(len(output[0][0])):\n",
    "                    fOutput.write(str(output[i][k][l][j]) + \"\\n\")\n",
    "    fOutput.close()\n",
    "    print(\"Output File Writing Complete!!!\")\n",
    "\n",
    "    print(\"\\n\\n Description of Layers\")\n",
    "    for layer in model.layers:\n",
    "        print(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:2198: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return sqrt(add.reduce(s, axis=axis, keepdims=keepdims))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.145017\n",
      "0.351735\n",
      "0.563547\n",
      "(1, 224, 224, 3)\n",
      "Output Shape ---> \n",
      "(1, 113, 113, 64)\n",
      "--------------------------------\n",
      "Output File Writing Complete!!!\n",
      "\n",
      "\n",
      " Description of Layers\n",
      "<keras.engine.input_layer.InputLayer object at 0x7f5fdd5c08d0>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f5fdd4d26d8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f5fdd4d2e10>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f5fdd581908>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f5fdd49bc50>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f5fdf1a5278>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f5fdd421a58>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f5fdd38d2b0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f5fdd304a58>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f5fdd31fe80>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f5fdd232f60>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f5fdd202e80>\n",
      "Total Time --> 3.550283908843994\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "checkCalculations()\n",
    "end = time.time()\n",
    "print(\"Total Time -->\", (end - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 1 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_FirstLayer():\n",
    "    fExp = open('data/FirstLayer/First_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/FirstLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkFile_FirstLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 2 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checkFile_SecondLayer():\n",
    "    fExp = open('data/SecondLayer/Second_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/SecondLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            print(str(cAct[i].strip()) + \"--->\" + str(cExp[i].strip()) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkFile_SecondLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_ThirdLayer():\n",
    "    fExp = open('data/ThirdLayer/Third_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/ThirdLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 2 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "batchNorm = model.layers[6].get_weights()\n",
    "\n",
    "fMean = open(\"data/SecondLayer/Second_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/SecondLayer/Second_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/SecondLayer/Second_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/SecondLayer/Second_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 3  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_three(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(1):\n",
    "            for k in range(64):\n",
    "                for l in range(32):\n",
    "                    fTemp.write(str(W[i][j][l][k]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer8 = model.layers[8]\n",
    "W = np.array(layer8.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer8.get_weights()[0]\n",
    "write_to_file_weights_layer_three(\"data/ThirdLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_three(\"data/ThirdLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 3 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.55478859  0.80603528  4.44496584  0.55382186  1.64092946  0.5194791\n",
      "  6.46401167  0.58865696  0.62877941  1.27855957  6.39427185  2.50745797\n",
      "  0.766868    0.820961    0.63612634  1.3644129   0.67660272  0.61109668\n",
      "  4.09073114  2.42642546  8.09107208  0.6966244   0.79401189  1.05641937\n",
      "  0.35251275  1.00756812  0.64977342  0.58691591  8.56960964  0.9598673\n",
      "  1.93179536  0.770042    0.7616275   2.87511683  1.60333228  0.89937705\n",
      "  0.88263619  0.53141242  0.70134759  1.01101303  0.94076937  1.22446883\n",
      "  3.75858974  0.38871551  0.88171715  0.9766621   1.12599266  1.27942169\n",
      "  0.66282862  1.69274092  1.1402272   4.21048164  0.48742834  0.647829\n",
      "  0.99179316  1.63962936  0.81399584  1.01274407  4.93946648  0.8023783\n",
      "  0.70030314  0.41994435  2.28768444  0.64417058]\n",
      "[-0.02793363  2.14558077  0.98886108  2.91445994  0.24405284  3.24074364\n",
      "  3.55818558  3.18861461  2.75455713 -0.0865751   2.14182782 -0.28570506\n",
      "  0.0809503   2.55627084  2.7854445  -0.03284101  2.38453317  2.06265545\n",
      "  3.14890838 -3.44445062 -0.21069559  2.12663174  1.45661116  1.19889104\n",
      " -2.02898264 -0.06220192  2.23638892  2.8302536   2.0235076   0.39703578\n",
      " -1.12102783 -0.04090455 -0.08677105  0.92831099  1.44001245  2.75278759\n",
      "  1.53917253  2.16071272  3.25207639  0.03931964  0.03494855 -0.08322124\n",
      "  0.53803217  2.5850997   1.88381362 -0.01954886  0.86964983  2.48104668\n",
      "  2.21345639  0.16828005  0.17178841  0.49071983  2.61687326  0.11631043\n",
      "  0.10643472 -1.08383596  2.88288641 -0.05684916  0.33174849  3.06832361\n",
      "  2.49582076  2.18155909  0.09838496  2.22314072]\n",
      "[  1.91535139e+00  -5.53428009e-02   4.73121834e+00   1.87899768e+00\n",
      "   1.79442465e+00   5.01272261e-01   1.94660568e+00  -1.20355940e+00\n",
      "  -2.55671573e+00   3.35318065e+00  -1.75271273e+00   6.60111952e+00\n",
      "  -2.44898987e+00   2.60531020e+00   3.38488317e+00   3.18218374e+00\n",
      "   5.59730768e+00   1.63165736e+00   2.82330441e+00   2.07197905e+00\n",
      "  -1.66571736e+00   7.08741546e-01  -3.21840525e+00   1.70739520e+00\n",
      "  -3.43934733e-13  -2.46939516e+00   8.32500815e-01   2.03860307e+00\n",
      "   7.68979406e+00  -4.51272540e-03  -3.13822126e+00  -6.93254757e+00\n",
      "  -3.50951624e+00  -2.86277127e+00   1.15135491e+00  -4.19345424e-02\n",
      "  -2.58504796e+00  -4.70991917e-02  -1.28985596e+00   6.23762274e+00\n",
      "  -2.71537757e+00  -1.97079957e+00   2.34028864e+00  -2.11556172e+00\n",
      "  -1.10271597e+00  -1.86856687e+00  -2.01180005e+00  -6.71383023e-01\n",
      "   2.30880690e+00  -7.45047405e-02  -1.70146668e+00  -4.95200872e+00\n",
      "   1.22116947e+00   5.76375341e+00   2.74707675e+00  -5.02088249e-01\n",
      "  -4.57622480e+00  -4.64879437e-13  -2.93411565e+00  -9.70871747e-01\n",
      "   9.44010854e-01   2.01738167e+00   4.82885027e+00  -5.04229498e+00]\n",
      "[  2.61733460e+00   9.15170312e-01   8.94674540e-01   1.29958105e+00\n",
      "   4.44526881e-01   4.11472559e-01   5.97111344e-01   3.79080027e-01\n",
      "   1.71153462e+00   1.55417109e+00   4.96412903e-01   2.89160752e+00\n",
      "   1.52239537e+00   1.00156951e+00   1.26686001e+00   1.54204583e+00\n",
      "   2.13250232e+00   7.83155680e-01   5.84762692e-01   5.57429850e-01\n",
      "   2.67288899e+00   8.71193409e-01   9.94503319e-01   3.25341016e-01\n",
      "   8.57076271e-25   1.66117036e+00   1.51374567e+00   2.27404326e-01\n",
      "   3.10276985e+00   2.16450439e-06   6.86032176e-01   1.00513828e+00\n",
      "   1.62949830e-01   7.39253759e-01   2.90780514e-01   4.92529571e-01\n",
      "   5.76947987e-01   3.10988635e-01   7.62586951e-01   1.42516994e+00\n",
      "   2.18286443e+00   1.82616532e+00   1.00090563e+00   3.57988268e-01\n",
      "   5.63346088e-01   1.94843805e+00   4.69872117e-01   6.80901349e-01\n",
      "   1.59867430e+00   1.49342954e+00   1.81674421e+00   2.04653478e+00\n",
      "   4.42223579e-01   1.14068794e+00   1.36092257e+00   3.53378534e-01\n",
      "   1.22665703e+00   4.36704338e-26   2.78706765e+00   4.47997153e-01\n",
      "   3.69410127e-01   4.62760299e-01   1.91588163e+00   1.52676034e+00]\n"
     ]
    }
   ],
   "source": [
    "import math as m\n",
    "batchNorm = model.layers[9].get_weights()\n",
    "\n",
    "fMean = open(\"data/ThirdLayer/Third_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/ThirdLayer/Third_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/ThirdLayer/Third_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/ThirdLayer/Third_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Layer Descriptions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f5fdd5c08d0>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f5fdd4d26d8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f5fdd4d2e10>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f5fdd581908>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f5fdd49bc50>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f5fdf1a5278>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f5fdd421a58>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f5fdd38d2b0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f5fdd304a58>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f5fdd31fe80>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f5fdd232f60>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f5fdd202e80>\n",
      "(4, 64)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer8 = model.layers[9]\n",
    "W = np.array(layer8.get_weights())\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
