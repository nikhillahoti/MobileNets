{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import Model\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import Conv3D\n",
    "\n",
    "fileName = \"Trump.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "# Global MobileNets model\n",
    "mobile = keras.applications.mobilenet.MobileNet(weights=\"imagenet\")\n",
    "model = Model(mobile.input, mobile.layers[30].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f0e7cf33b00>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f0e7cf339b0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f0e7d36d518>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0e7cff5b38>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0ea0ea6ba8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f0ea2d2c9e8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0ea0e92ba8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0e7cea7048>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f0e7ce6df98>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0e7ce34e48>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0e7cdcaeb8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f0e7cd6e5f8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f0e7cd6e518>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0e7cd6eef0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0e7cccecf8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f0e7cc6e978>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0e7cc8b6d8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0e7cba5da0>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f0e7cb88e80>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0e7cb70e80>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0e7cb0ae48>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f0e7caabb00>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0e7ca6f390>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0e7ca32828>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f0e7c9b2b38>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f0e7ca04c18>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0e7c8e9cc0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0e7c8e9b70>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f0e7c90de80>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0e7c8d1278>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0e7c814748>\n",
      "\n",
      "\n",
      " Weight Size\n",
      "(1, 1, 1, 128, 256)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer28 = model.layers[28]\n",
    "W = np.array(layer28.get_weights())\n",
    "\n",
    "print(\"\\n\\n Weight Size\")\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_nine(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(1):\n",
    "            for k in range(256):\n",
    "                for l in range(128):\n",
    "                    fTemp.write(str(W[i][j][l][k]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f0e7cf33b00>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f0e7cf339b0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f0e7d36d518>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0e7cff5b38>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0ea0ea6ba8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f0ea2d2c9e8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0ea0e92ba8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0e7cea7048>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f0e7ce6df98>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0e7ce34e48>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0e7cdcaeb8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f0e7cd6e5f8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f0e7cd6e518>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0e7cd6eef0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0e7cccecf8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f0e7cc6e978>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0e7cc8b6d8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0e7cba5da0>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f0e7cb88e80>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0e7cb70e80>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0e7cb0ae48>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f0e7caabb00>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0e7ca6f390>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0e7ca32828>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f0e7c9b2b38>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f0e7ca04c18>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0e7c8e9cc0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0e7c8e9b70>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f0e7c90de80>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f0e7c8d1278>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f0e7c814748>\n",
      "(1, 1, 1, 128, 256)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer28 = model.layers[28]\n",
    "W = np.array(layer28.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer28.get_weights()[0]\n",
    "write_to_file_weights_layer_nine(\"data/NinthLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_nine(\"data/NinthLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 256)\n",
      "[ 0.66240013  1.4128356   0.3931132   0.97899055  0.97652197  0.59571284\n",
      "  1.04558396  1.429757    1.47476923  0.61825949  1.43982446  1.43047726\n",
      "  1.34254134  0.80899674  0.82289445  0.8527295   1.01371849  1.5707953\n",
      "  0.45839885  0.96014792  1.06084216  0.73861229  1.27862585  0.59722924\n",
      "  1.07211757  0.93673396  1.28546071  1.71717191  0.64462715  1.77261555\n",
      "  1.03405523  1.01783001  0.93919909  0.68757957  0.95124066  0.62745994\n",
      "  0.60116255  1.77209997  1.39171493  0.96124101  1.10831201  1.78064561\n",
      "  0.68411422  1.72399187  0.8680476   0.76053387  1.50316095  1.04740858\n",
      "  1.39424968  0.74713701  1.70776463  0.74029458  1.29589403  0.7547155\n",
      "  2.17446661  0.5144437   1.28865492  1.21277761  0.87550622  0.75301844\n",
      "  1.63678491  2.28336358  0.88345742  0.97221792  1.42640638  0.73087776\n",
      "  1.69151032  1.11075103  0.70728368  0.68067735  1.00357926  1.11645794\n",
      "  0.8017863   0.60921317  1.30191135  2.09965205  0.92875415  1.50069129\n",
      "  0.93991935  1.12510788  1.03749967  0.46237686  1.09038675  1.74222302\n",
      "  0.85611427  0.81024736  0.80506533  1.4628607   0.81636125  0.46804595\n",
      "  0.86014056  0.58394158  0.59825373  1.58136141  1.76505017  0.39817053\n",
      "  0.78515214  0.64051563  1.01718831  1.17411172  1.27073944  1.01681828\n",
      "  0.72829568  0.9718821   0.9689666   0.76293051  0.85731786  1.0340997\n",
      "  1.01894617  1.485551    0.45786956  0.80629766  1.76841378  0.49774867\n",
      "  0.60653168  1.18058324  1.49000049  1.8580333   0.79128855  0.86502475\n",
      "  0.55640405  0.92233211  1.11997092  1.63989389  1.48601997  1.43418491\n",
      "  0.59566045  0.820333    0.63288504  1.21128559  0.93254989  1.19713545\n",
      "  1.56541193  1.56034756  1.66242194  0.89211041  0.73710668  1.34863138\n",
      "  1.2061044   1.56015193  1.4257853   0.79002011  0.95723295  0.83353877\n",
      "  1.10346615  0.5386616   0.83554286  1.17857301  1.86510432  1.05079043\n",
      "  1.78390408  1.32322943  1.51164162  1.48347342  2.23365808  0.97995991\n",
      "  0.88706821  1.45786071  2.17358351  1.31720984  0.83987969  1.2156651\n",
      "  2.31910992  0.8925842   0.7471149   1.35175717  1.03032851  1.40487003\n",
      "  0.92257661  1.03439736  0.62915957  0.89975613  1.14146721  0.80903161\n",
      "  1.52607286  1.66957474  1.01754808  0.58662289  1.0830313   1.33128989\n",
      "  0.85014242  3.13397074  1.18755221  0.80354184  0.79789603  1.10838735\n",
      "  0.89658332  1.35054255  1.46085978  1.44562554  0.90737742  1.06452131\n",
      "  0.67331433  1.53966057  0.68385035  1.39126027  1.36126578  0.35331151\n",
      "  0.59297824  0.95779878  0.83230245  2.15769267  0.66215497  1.02083194\n",
      "  1.23739684  0.50463694  0.92383832  1.15905726  0.78187603  2.84377789\n",
      "  1.54736555  0.72527272  0.90594721  0.99165809  0.79121536  1.5706017\n",
      "  1.24572098  1.23468649  0.7795229   1.27244341  0.84431392  1.14184189\n",
      "  1.5056529   2.016958    1.27583265  1.27656376  0.73000777  1.30407262\n",
      "  1.60429573  0.5938645   0.84311676  1.09925497  0.77003688  0.6688509\n",
      "  1.66648138  0.42581949  0.82301551  1.57698512  1.15693843  1.12726891\n",
      "  1.68650186  0.85519844  1.01266515  0.50346178  1.32336462  1.27248073\n",
      "  0.96312535  0.80216187  0.6119104   1.77497518  1.27361417  2.20159721\n",
      "  0.94986701  1.09897661  1.71045566  1.77739823]\n",
      "[ 1.90794384 -0.77054322  1.78272152  0.63726532  2.73085952  1.75001645\n",
      "  0.74507552 -2.79875612 -0.84001863  1.50394094  1.27603054  1.60720515\n",
      " -0.52244955  1.9687351   1.21122146  1.5515269   1.53493285 -1.36318505\n",
      "  2.23774552  1.49791276  1.95977628  0.53701019  1.76954401  2.35308313\n",
      "  2.08560944  2.3491807   2.97691393 -0.47982514  1.86184764 -0.34333497\n",
      "  1.19429374  1.6485126   3.07639241  2.17570448  2.12653637  1.45596838\n",
      "  2.1496346   1.82915235  0.68656772  1.70299697  1.52472532  0.69704473\n",
      "  1.71647358  2.18935013  1.50452912  1.80133212  1.42079031  0.03107805\n",
      "  1.44712698  1.42614996  0.65424389  2.60632396  1.5052352   1.74176848\n",
      " -0.11475962  1.08036721  0.13040955  1.12552571  1.05546176  2.17770576\n",
      "  0.72166622 -0.27058083  1.95864964  1.42417598  0.52852845  1.62683415\n",
      "  2.47833514 -0.08060694  2.4707787   1.99935496  1.80894935  2.66813183\n",
      "  1.41854644  2.39504814  1.48639679  0.19805832  1.54950786  3.14624476\n",
      "  1.57701004  0.51895458  1.31390786  1.91102052  2.19627333  0.02801771\n",
      "  0.93778402  2.23705673  1.63639939  2.89782715  2.20698237  1.86915517\n",
      "  1.7053014   2.00864625  1.6223681   1.87316585  1.96010721  2.08134413\n",
      "  1.52279389  1.93767917 -1.23280811  0.97330242  0.2355497   1.61492193\n",
      "  1.96068954  1.58758628  1.48353028  2.16467571  1.88962591  3.11431813\n",
      "  1.70521486  2.36551523  1.6756053   1.03339159  2.66255307  1.87439919\n",
      "  1.90987468  1.59643996 -0.1814785  -0.01846365  2.00300384  1.37377775\n",
      "  1.11366832  1.63275731  1.24666691 -0.23159766 -0.95445949  0.18519387\n",
      "  1.97211134  1.79852951  1.62767613  1.28333402  1.61753964  2.16530418\n",
      "  1.55064785  0.09065317  0.25793111  1.47269642  1.55075264  0.41532835\n",
      "  0.17654511  2.30347586  0.04076585  1.92849314  0.78687596  1.05674791\n",
      "  2.71285939  2.05501413  2.46553993  1.6604929   0.60093367  1.35938466\n",
      "  1.40672493  1.61474562 -0.02940765 -1.57319844 -0.34200612  1.19135046\n",
      "  1.46781921  1.05808735  0.08609675  2.23629069  1.76210749  1.40270257\n",
      "  0.30176133  0.89303362  2.20525408  0.91475719  2.00891662  1.48856437\n",
      "  1.66337621  2.09640884  2.30974388  0.79867768  0.28616914  1.43980789\n",
      "  2.17627311  0.2843222   0.36354521  1.33363271  2.22676802  1.10065401\n",
      "  1.42202318  2.90265918  0.05906684  0.30914956  2.19950676  2.80791545\n",
      "  1.67719638  0.12594356  2.4362886   2.89715171  1.15945649  1.95375407\n",
      "  2.11172485  1.96674836  2.51290536  1.38480413 -0.39222082  1.92708588\n",
      "  2.86184096  1.4744221   1.62685061  0.65318114  1.49643672  1.01228952\n",
      "  0.37844074  2.24801278  1.86902177  1.18013513  2.53091407  0.75432885\n",
      " -0.06081377  1.23240626  1.67695987  2.11746478  0.38025719  2.88358498\n",
      "  2.62099242  0.28127357  2.13089061  0.55993295  1.8700211   2.41024542\n",
      "  1.92759037  0.50537914  0.99952888  0.95512688  2.22371769  1.74463439\n",
      "  3.00921154  2.00898695  1.86761498  1.57320964  1.52457929  1.81971419\n",
      "  0.73244709  2.12482595  0.6754477   1.15398002  2.50875044  1.11093855\n",
      " -1.65711081  1.31121218  1.33609641  1.71969306  2.27371144  0.54678673\n",
      "  0.9615261   1.53259397  2.1853888   0.8501218   1.63073623  2.72594762\n",
      "  1.35552824  2.86333013  1.9327153   0.12093896]\n",
      "[ -1.59521079e+00  -9.57281113e-01  -1.73545587e+00   9.62639302e-02\n",
      "  -4.24468637e-01   6.01872742e-01  -4.10709172e-01   1.71091199e+00\n",
      "  -2.49090338e+00  -2.38791704e+00  -3.46897316e+00   1.14656329e+00\n",
      "   1.72735140e-01  -1.95216858e+00   1.57730138e+00   8.74920368e-01\n",
      "  -4.34597611e-01   1.21965396e+00  -7.85982311e-01   1.37026513e+00\n",
      "   2.23476052e+00  -3.12720275e+00   1.42230010e+00  -4.18735564e-01\n",
      "  -9.27864552e-01  -1.06062520e+00   2.87938714e-01   9.08233076e-02\n",
      "  -1.44277704e+00  -1.05899572e+00  -2.46869430e-01  -1.07193303e+00\n",
      "  -1.12734532e+00   2.78893083e-01  -3.48735899e-01   4.89945292e-01\n",
      "   1.00056231e+00  -1.28877568e+00  -6.99958444e-01   3.22459221e-01\n",
      "  -6.82652593e-01  -1.82524800e+00  -1.47827017e+00   3.14427502e-02\n",
      "   1.07675113e-01   5.07191563e+00  -2.02951026e+00   9.19030547e-01\n",
      "  -1.29247832e+00   3.45700055e-01   2.64871216e+00  -1.93056583e+00\n",
      "  -1.79498875e+00   1.46970940e+00   2.68774557e+00   1.32525682e+00\n",
      "  -6.75190330e-01   6.49773777e-02  -1.60497222e-02  -2.88963675e+00\n",
      "  -6.85640693e-01  -1.37734199e+00  -4.99612540e-01   1.42945385e+00\n",
      "   1.90268874e+00  -4.14877355e-01  -6.49973691e-01  -1.80765879e+00\n",
      "   3.73901755e-01  -3.93809724e+00  -1.27904963e+00  -2.58431077e+00\n",
      "   4.23703045e-01  -3.83247405e-01   1.10772014e+00   3.09416413e+00\n",
      "  -8.98658991e-01  -9.73271132e-02   6.05090380e-01   8.02434981e-02\n",
      "   3.12315464e+00  -1.77107322e+00   2.82370973e+00  -1.21810488e-01\n",
      "   2.41334128e+00   4.47891563e-01  -2.96129376e-01   5.32834791e-03\n",
      "  -2.43623704e-01   1.50127208e+00   1.30127084e+00  -9.92927104e-02\n",
      "   1.78746805e-02   2.23941159e+00   5.56722999e-01  -2.68455887e+00\n",
      "   6.22445066e-03  -1.37609971e+00   1.56602430e+00   1.75354087e+00\n",
      "  -2.07490489e-01   4.90129024e-01  -2.91797012e-01   4.32611704e-01\n",
      "  -4.81656283e-01  -2.28228521e+00   1.32239366e+00  -1.87096727e+00\n",
      "   1.56499016e+00  -1.42673731e+00   9.24085379e-01   3.35022283e+00\n",
      "   1.63010919e+00   2.29355431e+00  -3.27035785e-01  -1.56143212e+00\n",
      "  -6.63046837e-01  -3.48866940e-01   1.61289203e+00  -1.59656787e+00\n",
      "   7.74061918e+00  -2.86434460e+00   2.25157857e+00   1.66692340e+00\n",
      "   1.21307695e+00  -2.36621571e+00  -1.60381007e+00  -1.44627854e-01\n",
      "  -1.07904911e+00  -7.77081788e-01   2.93814850e+00   2.21227837e+00\n",
      "  -2.02677298e+00  -4.85082082e-02  -3.02434377e-02  -2.27035761e+00\n",
      "  -2.03221545e-01   9.15788352e-01   3.28496397e-01  -1.01404178e+00\n",
      "   1.82778791e-01  -1.50906429e-01   1.21050370e+00   3.95329863e-01\n",
      "  -4.88076150e-01   1.11491516e-01  -3.25495154e-01  -4.05381680e+00\n",
      "   6.76482022e-01   4.73602682e-01  -1.59042966e+00  -1.21218991e+00\n",
      "   4.15629447e-01   8.42762768e-01  -1.99545372e+00  -2.11349034e+00\n",
      "   2.01407775e-01   1.22731411e+00   1.44380736e+00  -1.18137014e+00\n",
      "   1.34331334e+00  -6.28364146e-01  -1.27760112e-01   1.16799879e+00\n",
      "  -2.91006351e+00   2.15085059e-01  -1.15238652e-01  -1.79822719e+00\n",
      "  -1.28184402e+00  -1.21939099e+00  -1.57175100e+00  -5.09244949e-02\n",
      "  -1.30468035e+00   1.54912853e+00  -1.58037877e+00  -6.47279501e-01\n",
      "  -4.95729089e-01  -2.34022403e+00  -1.42423356e+00  -8.11066568e-01\n",
      "  -1.75330698e+00   1.94328356e+00   6.96734071e-01  -3.85213733e-01\n",
      "   6.17498517e-01  -1.99747157e+00  -1.99144137e+00   1.93184984e+00\n",
      "  -1.91593373e+00   9.43365037e-01  -9.20786858e-01  -2.18820500e+00\n",
      "   3.64040613e-01   4.63913620e-01  -2.83836389e+00   4.23499870e+00\n",
      "   3.82193297e-01  -2.39390516e+00  -2.41279745e+00   1.09742594e+00\n",
      "   1.51847219e+00   6.15482368e-02   4.95903283e-01   3.56732011e+00\n",
      "   1.90630388e+00  -6.12454526e-02   2.36126971e+00   2.27232718e+00\n",
      "   4.10478055e-01  -2.02460453e-01   1.64030170e+00   9.01470184e-02\n",
      "  -2.30265188e+00   1.23215663e+00  -2.49652243e+00  -1.42969704e+00\n",
      "  -1.11455336e-01   2.29853749e+00   3.11139196e-01  -1.67630398e+00\n",
      "   6.11176252e+00  -1.00823319e+00   1.51439106e+00   2.84437686e-01\n",
      "   1.26406658e+00  -2.88175178e+00   1.77581415e-01   1.15118515e+00\n",
      "  -2.21209705e-01  -7.96379983e-01   6.50671124e-02  -2.43560481e+00\n",
      "   3.12391996e+00   3.81792307e-01  -1.31899154e+00  -7.83060253e-01\n",
      "  -5.29188573e-01  -8.18951309e-01  -4.97033983e-01  -8.14093277e-03\n",
      "   3.75950724e-01  -9.80462968e-01  -3.57439041e-01  -1.11364231e-01\n",
      "   4.23074752e-01  -1.06435525e+00  -1.77443933e+00   4.00566292e+00\n",
      "  -2.65583229e+00  -6.01566255e-01  -3.83497775e-01  -5.36429882e-01\n",
      "   1.44986367e+00  -1.66383755e+00  -1.01867437e+00   1.13208997e+00]\n",
      "[ 0.48977104  0.6489532   0.23444864  0.87624913  1.49001455  0.42373157\n",
      "  0.68660885  0.45135596  0.34439689  0.34576401  0.57390696  0.36806875\n",
      "  0.78308976  1.14042413  1.10078084  0.61774647  0.43530458  0.65742403\n",
      "  0.66083556  1.41167307  0.71469688  0.57162178  1.01560032  0.57188696\n",
      "  2.29711914  1.62506378  0.41966206  0.8652966   0.9084726   0.57780111\n",
      "  0.30191156  1.58300436  1.58062387  0.42716748  0.41519165  0.97469729\n",
      "  0.61381334  1.08228207  1.3345089   0.49228173  0.98466486  0.56715405\n",
      "  0.39443007  0.89772528  1.20666111  1.84439468  0.49893796  0.2965982\n",
      "  1.06013775  0.31023622  0.67366767  0.6106652   0.51906049  0.72076309\n",
      "  0.89567566  0.44261622  0.44060737  0.8485837   1.04990935  0.91295356\n",
      "  0.61922264  0.74989682  0.93361795  0.80255103  0.82916462  1.29854751\n",
      "  0.50382578  0.60119021  0.87888241  1.03772616  0.35510778  0.43667638\n",
      "  0.9693104   0.95426518  0.59049296  1.82690275  1.03163302  0.54742759\n",
      "  0.78498405  0.89582211  2.81233048  0.87480092  1.53042305  0.49346811\n",
      "  0.48384142  1.33205378  0.36090541  0.55132079  2.83524442  0.43987259\n",
      "  0.62808275  0.75578552  0.53814131  0.4219473   0.616741    0.55317032\n",
      "  0.29405904  0.43870512  0.27628767  0.6286298   0.89037204  0.81669253\n",
      "  0.51665658  0.60876119  1.09790039  0.66708624  0.81001544  1.69425666\n",
      "  0.52817649  0.54985821  0.68157202  0.4985545   0.68442917  0.45123515\n",
      "  1.47925818  0.38402718  0.84142226  1.11740041  2.56598711  0.62471622\n",
      "  0.96632749  0.59996343  1.58653402  0.9908973   0.61974543  0.98307455\n",
      "  0.5674299   0.42415789  0.88038164  0.26353285  0.73269284  0.60513204\n",
      "  0.3657937   0.63458723  0.51276332  0.72658157  0.37134036  1.17431939\n",
      "  0.44717762  0.52034628  1.08381999  0.46777773  0.53407925  0.5663808\n",
      "  0.58810818  0.45034033  1.45217752  1.75747228  0.72379696  1.10078096\n",
      "  0.58222049  0.56744409  0.4903163   0.22553664  0.44372544  0.53838956\n",
      "  0.85965043  0.68172145  0.93233675  0.65535331  0.42810783  0.37639725\n",
      "  0.85414761  0.78936672  2.88564301  0.55988032  0.35385486  0.70420909\n",
      "  0.36237726  1.07735229  0.53119773  0.71263832  0.65079486  1.03447604\n",
      "  2.10003662  0.6719014   0.26530603  0.64572924  1.08733046  1.21627462\n",
      "  0.89022106  0.56468856  0.67221969  0.59990633  1.74172997  0.80945271\n",
      "  2.08388615  0.73982036  1.54893792  0.42708945  0.57389116  0.71895355\n",
      "  0.39285204  0.86584026  1.16721654  1.12552345  0.54252994  0.4960084\n",
      "  0.41725135  1.58831692  1.12727225  0.70224231  0.74539775  1.88891757\n",
      "  0.63659263  0.67416775  0.74626535  0.60890037  0.66685021  0.29494864\n",
      "  0.56264019  0.81833047  0.61382222  0.77451885  0.51419145  0.6278106\n",
      "  0.51372766  0.6192717   1.65022802  0.86072129  0.71053964  0.97626811\n",
      "  0.70830351  0.47401607  0.85474986  0.6673519   1.61542845  1.44638491\n",
      "  0.87801999  1.47934687  1.08494997  0.4055174   0.35291705  0.4704558\n",
      "  0.29291436  0.61558384  0.49103338  0.46135336  0.65422952  1.39844978\n",
      "  0.61692894  0.47058046  1.31387484  0.84733289  0.77310336  0.39256027\n",
      "  0.65871221  1.65582621  1.03181231  0.37876871  0.7366305   0.43454012\n",
      "  0.49046415  1.63186538  0.80009156  0.69344449]\n"
     ]
    }
   ],
   "source": [
    "import math as m\n",
    "layer29 = model.layers[29]\n",
    "W = np.array(layer29.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "batchNorm = model.layers[29].get_weights()\n",
    "\n",
    "fMean = open(\"data/NinthLayer/Ninth_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/NinthLayer/Ninth_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/NinthLayer/Ninth_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/NinthLayer/Ninth_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
