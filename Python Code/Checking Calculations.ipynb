{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import Model\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import Conv3D\n",
    "\n",
    "fileName = \"Trump.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "# Global MobileNets model\n",
    "mobile = keras.applications.mobilenet.MobileNet(weights=\"imagenet\")\n",
    "model = Model(mobile.input, mobile.layers[23].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_input(fileName, X):\n",
    "    fhandler = open(fileName, \"w\")\n",
    "    for i in range(3):\n",
    "        for j in range(224):\n",
    "            for k in range(224):\n",
    "                fhandler.write(str(X[j][k][i]) + \"\\n\")\n",
    "    fhandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_Input_Files():\n",
    "    \n",
    "    img_width = 224\n",
    "    img_height = 224\n",
    "\n",
    "    img = image.load_img(fileName, target_size=(img_width, img_height))\n",
    "    X = image.img_to_array(img)\n",
    "\n",
    "    # Normalizing the Input\n",
    "    X = tf.keras.utils.normalize(X, axis=2)\n",
    "    \n",
    "    # Write Normalized Input to file\n",
    "    write_to_file_input(\"data/FirstLayer/inputNorm.txt\", X)\n",
    "    \n",
    "    \n",
    "    # Write combination input to file\n",
    "    X[:, :, 0] = 1\n",
    "    X[:, :, 1] = 10\n",
    "    X[:, :, 2] = 100\n",
    "    write_to_file_input(\"data/FirstLayer/inputComb.txt\", X)\n",
    "    \n",
    "    # Write all 1's input to file\n",
    "    X[:, :, 0] = 1\n",
    "    X[:, :, 1] = 1\n",
    "    X[:, :, 2] = 1\n",
    "    write_to_file_input(\"data/FirstLayer/inputSet1.txt\", X)\n",
    "\n",
    "    print(\"Creating Input files Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_Input_Files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_one(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(32):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = model.layers[2].get_weights()[0]\n",
    "write_to_file_weights_layer_one(\"data/FirstLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_one(\"data/FirstLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_second(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(32):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = model.layers[5].get_weights()[0]\n",
    "write_to_file_weights_layer_second(\"data/SecondLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_second(\"data/SecondLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkCalculations():\n",
    "\n",
    "    img_width = 224\n",
    "    img_height = 224\n",
    "\n",
    "    img = image.load_img(fileName, target_size=(img_width, img_height))\n",
    "    X = image.img_to_array(img)\n",
    "\n",
    "    # Normalized the Input\n",
    "    X = tf.keras.utils.normalize(X, axis=2)\n",
    "    \n",
    "    # Set as 1\n",
    "    #X[:,:,0] = 1\n",
    "    #X[:,:,1] = 1\n",
    "    #X[:,:,2] = 1\n",
    "\n",
    "    # Set as Combination\n",
    "    #X[:,:,0] = 1\n",
    "    #X[:,:,1] = 10\n",
    "    #X[:,:,2] = 100\n",
    "\n",
    "    print(X[0][0][0])\n",
    "    print(X[0][1][0])\n",
    "    print(X[0][2][0])\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    print(X.shape)\n",
    "\n",
    "    # Weights part\n",
    "    W = model.layers[2].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[2].set_weights(W)\n",
    "    \n",
    "    \n",
    "    W = model.layers[5].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[5].set_weights(W)\n",
    "    \n",
    "    W = model.layers[8].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[8].set_weights(W)\n",
    "    \n",
    "    W = model.layers[12].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[12].set_weights(W)\n",
    "    \n",
    "    W = model.layers[15].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[15].set_weights(W)\n",
    "    \n",
    "    W = model.layers[18].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[18].set_weights(W)\n",
    "    \n",
    "    W = model.layers[21].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[21].set_weights(W)\n",
    "    \n",
    "    \n",
    "    output = model.predict(X)\n",
    "    print(\"Output Shape ---> \")\n",
    "    print(output.shape)\n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "    # Save Output to file\n",
    "    fOutput = open(\"data/SeventhLayer/Seventh_Layer_Output.txt\", \"w\")\n",
    "    for i in range(len(output)):\n",
    "        for j in range(len(output[0][0][0])):\n",
    "            for k in range(len(output[0])):\n",
    "                for l in range(len(output[0][0])):\n",
    "                    fOutput.write(str(output[i][k][l][j]) + \"\\n\")\n",
    "    fOutput.close()\n",
    "    print(\"Output File Writing Complete!!!\")\n",
    "\n",
    "    print(\"\\n\\n Description of Layers\")\n",
    "    for layer in model.layers:\n",
    "        print(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:2198: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return sqrt(add.reduce(s, axis=axis, keepdims=keepdims))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.145017\n",
      "0.351735\n",
      "0.563547\n",
      "(1, 224, 224, 3)\n",
      "Output Shape ---> \n",
      "(1, 56, 56, 128)\n",
      "--------------------------------\n",
      "Output File Writing Complete!!!\n",
      "\n",
      "\n",
      " Description of Layers\n",
      "<keras.engine.input_layer.InputLayer object at 0x7fe70db7d320>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fe70dbd3da0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe70dbd3be0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe70db8ba20>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe70dcf3d68>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fe80c872518>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe70db0fcf8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe70da4be10>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe70da6aac8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe70da2f358>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe70d9f27f0>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fe70d96db38>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fe70d93fbe0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe70d89fc88>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe70d89fb38>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe70d841e48>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe70d805240>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe70d7c8710>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fe70d744a20>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe70d764780>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe70d6fdcf8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe70d648e80>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe70d660b70>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe70d626320>\n",
      "Total Time --> 10.095700740814209\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "checkCalculations()\n",
    "end = time.time()\n",
    "print(\"Total Time -->\", (end - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 6 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_SixthLayer():\n",
    "    fExp = open('data/SixthLayer/Sixth_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/SixthLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    mismatchStart = 0;\n",
    "    boo = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            if(boo < 500):\n",
    "                boo += 1\n",
    "                print(str(cAct[i].strip()) + \"  --->   \" + str(cExp[i].strip()) + \" <---- \" + str(i) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    print(mismatchStart)\n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500014  --->   0.499986 <---- 5299\n",
      "2.500029  --->   2.5 <---- 12677\n",
      "0.499984  --->   0.500016 <---- 30045\n",
      "0.499934  --->   0.500131 <---- 248054\n",
      "0.499856  --->   0.500051 <---- 249042\n",
      "0.500026  --->   0.499958 <---- 341187\n",
      "Number of mismatch - 6\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "checkFile_SixthLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 5 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_FifthLayer():\n",
    "    fExp = open('data/FifthLayer/Fifth_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/FifthLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            print(str(cAct[i].strip()) + \"  --->   \" + str(cExp[i].strip()) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkFile_FifthLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 1 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_FirstLayer():\n",
    "    fExp = open('data/FirstLayer/First_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/FirstLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mismatch - 388864\n"
     ]
    }
   ],
   "source": [
    "checkFile_FirstLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 4 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_FourthLayer():\n",
    "    fExp = open('data/FourthLayer/Fourth_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/FourthLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            print(str(cAct[i].strip()) + \"--->\" + str(cExp[i].strip()) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkFile_FourthLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 2 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checkFile_SecondLayer():\n",
    "    fExp = open('data/SecondLayer/Second_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/SecondLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            print(str(cAct[i].strip()) + \"--->\" + str(cExp[i].strip()) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkFile_SecondLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_ThirdLayer():\n",
    "    fExp = open('data/ThirdLayer/Third_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/ThirdLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 7 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_SeventhLayer():\n",
    "    fExp = open('data/SeventhLayer/Seventh_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/SeventhLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mismatch - 19\n"
     ]
    }
   ],
   "source": [
    "checkFile_SeventhLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 6 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.17376578  0.92570347  1.33578944  0.76546639  0.88438272  1.28590727\n",
      "  0.64942753  1.40510738  1.05130637  1.72453225  0.9786219   1.67618835\n",
      "  0.58891213  1.50489914  1.79923272  2.04591084  1.34045398  0.81471074\n",
      "  0.99819231  0.89749551  1.47205436  1.69671047  1.45804167  0.6779514\n",
      "  0.94730163  1.63231707  2.26928258  1.84552538  1.11021316  1.17338729\n",
      "  1.29545557  2.00494432  2.32145643  1.48001683  1.37820995  1.05569613\n",
      "  1.46535122  0.66719675  0.95240086  7.10886765  1.99117792  0.85256547\n",
      "  2.21908903  1.20690072  1.69672048  0.94427353  3.62987256  0.92673427\n",
      "  1.22302294  1.07908344  1.08553994  1.00814819  1.09811568  1.27662528\n",
      "  1.04946864  1.33240819  1.17767119  1.200719    1.43957746  0.66142839\n",
      "  1.62856257  1.56319773  1.19957316  1.26731813  1.12130773  1.65475392\n",
      "  1.28627729  2.31529236  4.39884281  1.97971916  1.06841552  0.95823908\n",
      "  1.17420721  1.62769365  1.38963318  1.01462626  0.86462164  1.54941881\n",
      "  1.35129344  1.17098308  0.76067418  0.94015956  0.72020191  1.56491935\n",
      "  2.03240156  1.3279444   1.13324714  1.38579226  1.5140686   1.45908129\n",
      "  1.27209127  0.83640563  1.67506766  1.13486207  1.04992676  1.06743562\n",
      "  0.72675216  1.77436161  0.75012028  0.86915714  1.18154442  0.50819468\n",
      "  1.73744273  1.22357368  0.76849401  0.89601618  1.07886708  1.37949109\n",
      "  1.12686002  1.53349817  0.70203727  1.60559881  0.77601296  1.62249327\n",
      "  3.12489629  1.22871459  1.65109372  1.04824734  0.58185148  0.95162141\n",
      "  0.69721955  3.97329402  0.85076779  1.47501397  0.69098943  1.29685533\n",
      "  1.29523468  2.28140354]\n",
      "[ 0.72143465  0.01363674  0.05389157  5.05492496  2.49030423 -1.059587\n",
      " -0.40610358 -0.26670736 -0.23595124 -0.43631679  3.56390285  0.15713345\n",
      "  0.04360056 -0.015995   -0.07100134  2.56553316 -0.35836366 -1.17873263\n",
      "  0.15068009  2.44716811 -0.05382602  0.00852313 -0.15267693  2.2692802\n",
      "  0.98935497  0.45503432  1.77241206  0.48598987 -0.19603463  0.62342739\n",
      " -0.28581443 -1.68366933 -1.29396343  5.51000786 -0.02630313  1.71006966\n",
      " -0.45583376  1.74399924  1.91439617  2.29675508  0.87310314  1.45533311\n",
      "  2.4629128  -0.00800036  1.76306212 -1.18711591  3.93522739  3.79581332\n",
      "  0.02762886  1.53619325  0.31614617 -0.08858164  0.86725718 -0.08668464\n",
      "  3.14633536  5.34504795 -0.00735868  0.58026201  0.88394499  1.524876\n",
      " -0.2799972   0.63548577 -0.8487798  -0.0197631  -0.03428796 -0.17134026\n",
      " -0.01232282 -0.20907333  1.322492    0.19782865  0.1726096   0.46545157\n",
      "  2.98773122  0.05923635  0.0192916   2.11264873  3.45107317  0.15503553\n",
      "  1.16716337  0.79630387  3.41199231  2.28103614 -1.18197358  0.64179146\n",
      "  0.0349035   0.06411094 -0.01636218  0.01400144  0.0223705   0.75868112\n",
      "  0.03154705 -1.12465    -0.33665654 -0.03624693  3.19853497  0.04825925\n",
      "  2.91152072  0.299346    3.52241039  0.61567116  4.98891258  3.29594588\n",
      " -0.1974256   5.14031601  3.26431298  0.46737498  1.58523679 -0.09522966\n",
      "  0.72984499 -0.08363263  5.13377666  2.6981988   2.05323291  0.96600771\n",
      "  2.32890534 -1.59002006 -0.05867134  0.25444266  2.71917868  0.3952128\n",
      "  1.01329684  1.47243226  3.60865808 -0.04209217  4.90215921 -0.09545956\n",
      "  0.03944332 -0.2469881 ]\n",
      "[ -1.62857456e+01   2.36994550e-01   3.68160933e-01  -1.58168221e+00\n",
      "  -3.64298415e+00   1.02406514e+00   3.36134225e-01   7.03423977e+00\n",
      "   1.72216690e+00  -1.53163648e+00  -1.91409457e+00   1.92484006e-01\n",
      "   4.56330739e-02   2.82312840e-01  -1.82308555e+00  -2.26906109e+00\n",
      "   3.29711318e+00   9.53502581e-02   5.39282036e+00   1.59590340e+01\n",
      "  -5.78078270e-01  -1.00097692e+00   3.91717249e-35  -1.69104505e+00\n",
      "  -1.60801068e-01  -5.24731874e+00  -2.01815918e-01   4.58267093e-01\n",
      "   1.00542545e+00   1.74359590e-01   6.42381048e+00   9.26621914e+00\n",
      "  -2.69595795e+01   1.78625524e+00   1.85959613e+00  -1.44229203e-01\n",
      "   4.61823940e+00   3.10543686e-01  -8.22982043e-02  -1.75826386e-01\n",
      "   7.32099712e-01  -1.72647119e+00   2.04983354e+00  -3.46644968e-02\n",
      "  -3.22400308e+00   3.91766725e-35   1.27896145e-01  -1.62688696e+00\n",
      "   6.38542509e+00  -1.38984251e+01   9.66760874e-01  -3.32768989e+00\n",
      "  -1.53330767e+00   2.70483637e+00   1.99987459e+00  -1.04498279e+00\n",
      "   4.53105688e-01  -2.25654811e-01   4.86887068e-01   5.08301878e+00\n",
      "   1.15261326e+01   1.04510081e+00   2.62209558e+00   3.90204757e-01\n",
      "  -8.99654478e-02  -2.66094893e-01   1.06770444e+00  -6.80564225e-01\n",
      "   3.39944363e-01  -5.42577505e-01   5.43082094e+00   8.67362201e-01\n",
      "  -9.42090005e-02   8.07936311e-01   2.28375182e-01   4.27778065e-02\n",
      "  -7.46880412e-01   9.72988755e-02   1.86985981e+00   3.06159782e+00\n",
      "   8.01661849e-01   1.49351206e+01   3.91756652e-35   1.90995574e-01\n",
      "  -1.07430443e-01   1.00079119e+00  -3.03950691e+00   5.91260970e-01\n",
      "  -2.02048838e-01  -1.33536386e+00   1.82889390e+00   3.91733062e-35\n",
      "  -1.10508022e+01   4.86638211e-03   6.56612921e+00   9.79586184e-01\n",
      "  -4.95578623e+00   1.38369128e-01  -1.84351528e+00   2.26834512e+00\n",
      "  -3.66257572e+00  -1.16146708e+00   1.92451513e+00   3.38294244e+00\n",
      "  -5.02274632e-01   2.50613785e+00   3.72205186e+00   7.17671335e-01\n",
      "   2.50098443e+00  -5.18723869e+00  -1.37048221e+00  -2.91559160e-01\n",
      "   1.92680669e+00  -1.98285460e+00  -3.08727050e+00   1.31152964e+00\n",
      "  -1.42882776e+00   5.41563988e+00  -2.15205574e+00   2.01092219e+00\n",
      "  -5.92545319e+00  -5.48168600e-01   3.58069211e-01  -5.08073688e-01\n",
      "  -9.95631337e-01  -8.23518157e-01   2.30404854e-01  -3.18591565e-01]\n",
      "[  3.76103210e+01   1.16115789e+01   3.29946976e+01   1.05694513e+01\n",
      "   3.80222917e+00   5.01570559e+00   2.82293534e+00   1.15944424e+01\n",
      "   7.49789524e+00   1.40843506e+01   1.24580240e+01   5.31352119e+01\n",
      "   3.56017232e-01   2.69156246e+01   3.57640743e+00   3.29109039e+01\n",
      "   4.33164501e+00   2.71569401e-01   1.94177265e+01   4.46240730e+01\n",
      "   1.82479362e+01   8.35522079e+01   3.91784059e-35   7.65668154e+00\n",
      "   1.29563093e+01   2.17927818e+01   6.23036575e+01   8.90553570e+00\n",
      "   1.44125929e+01   9.73539352e+00   1.67458553e+01   1.35288358e+00\n",
      "   3.32631798e+01   2.65456848e+01   1.47194748e+01   2.57456994e+00\n",
      "   1.09607992e+01   1.23434591e+01   3.61420441e+01   5.57796974e+01\n",
      "   3.87422943e+01   1.03648567e+01   3.68167877e+01   1.24355049e+01\n",
      "   2.82823429e+01   3.91750138e-35   1.08790314e+02   1.37621384e+01\n",
      "   2.17773457e+01   8.00522423e+00   4.09728546e+01   1.04315786e+01\n",
      "   2.72701225e+01   4.09051514e+01   1.19584866e+01   1.87313442e+01\n",
      "   8.32246628e+01   1.32809057e+01   7.25432110e+00   2.53678322e+01\n",
      "   2.61727695e+01   1.40628576e+01   1.13949747e+01   3.17351913e+01\n",
      "   1.19382162e+01   3.10877800e+00   2.61934662e+01   9.24599361e+00\n",
      "   5.83549385e+01   2.73752556e+01   1.71087036e+01   9.68938637e+00\n",
      "   2.64679699e+01   8.77896423e+01   1.43164787e+01   8.36222935e+00\n",
      "   1.64544144e+01   6.07497644e+00   4.14567680e+01   4.25868149e+01\n",
      "   6.91938066e+00   6.45029907e+01   3.91750396e-35   1.22446785e+01\n",
      "   7.09793167e+01   4.72387886e+01   2.06681466e+00   1.81621532e+01\n",
      "   3.37568665e+01   3.52695727e+00   9.28300552e+01   3.91784920e-35\n",
      "   4.41573572e+00   5.15706015e+00   1.06214409e+01   1.22181854e+01\n",
      "   1.37447462e+01   7.64488411e+00   1.07888832e+01   8.24712563e+00\n",
      "   1.00330257e+01   4.06247950e+00   1.05051718e+01   1.90270424e+01\n",
      "   2.46264291e+00   9.16028309e+00   4.98442497e+01   3.18259525e+01\n",
      "   2.99212666e+01   9.13469696e+01   8.12077999e+00   6.87551346e+01\n",
      "   8.64203739e+00   1.25060053e+01   6.45190811e+01   3.18356347e+00\n",
      "   6.86607838e+00   1.19642820e+01   8.85173225e+00   1.68207359e+01\n",
      "   4.25426369e+01   3.87855415e+01   7.90406895e+00   2.54926472e+01\n",
      "   5.51207066e+00   2.25328102e+01   2.42359695e+01   1.46592426e+01]\n"
     ]
    }
   ],
   "source": [
    "import math as m\n",
    "batchNorm = model.layers[19].get_weights()\n",
    "\n",
    "fMean = open(\"data/SixthLayer/Sixth_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/SixthLayer/Sixth_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/SixthLayer/Sixth_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/SixthLayer/Sixth_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 2 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "batchNorm = model.layers[6].get_weights()\n",
    "\n",
    "fMean = open(\"data/SecondLayer/Second_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/SecondLayer/Second_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/SecondLayer/Second_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/SecondLayer/Second_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 3  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_three(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(1):\n",
    "            for k in range(64):\n",
    "                for l in range(32):\n",
    "                    fTemp.write(str(W[i][j][l][k]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer8 = model.layers[8]\n",
    "W = np.array(layer8.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer8.get_weights()[0]\n",
    "write_to_file_weights_layer_three(\"data/ThirdLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_three(\"data/ThirdLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 3 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "batchNorm = model.layers[9].get_weights()\n",
    "\n",
    "fMean = open(\"data/ThirdLayer/Third_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/ThirdLayer/Third_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/ThirdLayer/Third_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/ThirdLayer/Third_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 4  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_four(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(64):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer12 = model.layers[12]\n",
    "W = np.array(layer12.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer12.get_weights()[0]\n",
    "write_to_file_weights_layer_four(\"data/FourthLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_four(\"data/FourthLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 5 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "layer16 = model.layers[16]\n",
    "W = np.array(layer16.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "batchNorm = model.layers[16].get_weights()\n",
    "\n",
    "fMean = open(\"data/FifthLayer/Fifth_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/FifthLayer/Fifth_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/FifthLayer/Fifth_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/FifthLayer/Fifth_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 4 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "layer13 = model.layers[13]\n",
    "W = np.array(layer13.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "fMean = open(\"data/FourthLayer/Fourth_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/FourthLayer/Fourth_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/FourthLayer/Fourth_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/FourthLayer/Fourth_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 5  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_five(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(128):\n",
    "            for k in range(1):\n",
    "                for l in range(64):\n",
    "                    fTemp.write(str(W[i][k][l][j]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer15 = model.layers[15]\n",
    "W = np.array(layer15.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer15.get_weights()[0]\n",
    "write_to_file_weights_layer_five(\"data/FifthLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_five(\"data/FifthLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 6  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_six(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(128):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                for l in range(1):\n",
    "                    fTemp.write(str(W[j][k][i][l]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7fda5f453a90>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fda5f441e10>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fda5f441c50>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f4f3e10>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f4cec50>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fda5f527a20>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f592e48>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f36ab00>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fda5f317d68>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f335b70>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f249e10>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fda5f26c780>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fda5f26c8d0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f1bdc88>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f1bdfd0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fda5f169c50>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f109a58>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f0a2e10>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fda5f047668>\n",
      "(1, 3, 3, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer18 = model.layers[18]\n",
    "W = np.array(layer18.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer18.get_weights()[0]\n",
    "write_to_file_weights_layer_six(\"data/SixthLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_six(\"data/SixthLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 7  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_seven(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(1):\n",
    "            for k in range(128):\n",
    "                for l in range(128):\n",
    "                    fTemp.write(str(W[i][j][l][k]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7fe7f7ffcef0>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fe78e7ce208>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe78e7ce470>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78e7ce630>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78e7cee80>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fe78e7ceac8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78e7cef28>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78df5d6a0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe78c65fa58>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78c623358>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78c5e7c88>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fe78c5bb588>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fe78c5bbfd0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78c4a36a0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78c4a37b8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe78c4d3fd0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78c487be0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78c44d240>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fe78c3aaac8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe78c36c438>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe78c300b38>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe78c2aeda0>\n",
      "(1, 1, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer21 = model.layers[21]\n",
    "W = np.array(layer21.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer21.get_weights()[0]\n",
    "write_to_file_weights_layer_seven(\"data/SeventhLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_seven(\"data/SeventhLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 3, 32)\n",
      "[ 1.05056036  0.57910722  1.76207137  1.84479833  1.41026509  0.60256934\n",
      "  1.24274731  0.42947298  1.26381314  3.03325653  1.29197574  1.21629047\n",
      "  1.7493304   0.88670272  1.14918911  1.23011827  1.97115421  2.43784595\n",
      "  1.33370745  1.20197749  0.4182142   1.33236325  1.00239277  1.27573729\n",
      "  1.26219618  1.176705    0.18780169  3.93668509  1.7225306   1.46456468\n",
      "  1.0148164   2.50519514  1.46467161  2.33769035  1.39787662  1.60222232\n",
      "  1.8232336   1.30929077  1.5724057   1.22389412  1.12228286  2.14964604\n",
      "  1.71093667  2.03067923  1.07103086  3.16209316  0.95092404  2.5516119\n",
      "  1.43246007  3.33769584  2.34382176  4.09600353  1.89060473  0.69922721\n",
      "  1.99524808  1.93345535  1.25142837  0.83385456  1.25391245  0.86113846\n",
      "  2.35615373  1.80018473  1.02557981  2.05879235  2.70441008  0.82349062\n",
      "  1.70190358  1.34319293  1.53885257  0.63403744  1.53616238  0.75365496\n",
      "  1.1811868   0.98377353  1.22031295  1.72789145  2.66385555  1.59993422\n",
      "  1.13872051  4.04538012  2.0944171   3.30056548  1.3120786   1.21914375\n",
      "  2.34494805  1.83359241  1.19624007  2.49831581  2.18560386  2.5982244\n",
      "  1.0752722   0.18756729  2.12485385  1.45852208  1.25945699  2.3376646\n",
      "  0.87136644  1.31848311  0.95300549  0.43815097  2.57513428  1.63579941\n",
      "  1.73644495  1.63258827  1.24595869  1.74151826  3.44675565  3.69923639\n",
      "  1.25336468  2.0315671   1.94417644  1.02419591  3.45607495  1.77218127\n",
      "  1.58918536  2.03422713  1.75530434  1.2228533   3.2289784   0.78679413\n",
      "  0.60116827  1.49168241  1.91346669  1.37069297  1.0319804   1.53899002\n",
      "  0.6749168   1.96157253]\n",
      "[ 1.37265384  1.9337225  -0.4275859   0.45966831  1.90571523  3.10698295\n",
      "  2.16025639  1.64340281  0.06552611  0.34556508  1.27673697 -0.13176943\n",
      " -0.16817823  0.379803   -0.16727634 -0.18414244 -0.11949538  4.20403242\n",
      " -1.11676192 -0.33154118  1.80451512 -0.31445459  0.82911772  0.06047173\n",
      "  2.45823026 -0.19144356 -2.01320243  1.21578252 -0.50406128 -0.861422\n",
      "  2.0811317  -1.43296885 -0.25472727 -0.67203468  0.01744555 -0.07057729\n",
      " -0.3827537  -0.74370444 -0.95024139  0.78957099 -0.91117501  0.14091317\n",
      "  0.21259372 -0.11106931  0.22444989  1.20935524  2.29332423 -0.38162875\n",
      "  0.96895415  1.88567317 -3.43597364  0.58670568 -0.65941894  2.27478838\n",
      "  0.09890039 -0.51969272 -0.21610326  2.10127711  1.02459264 -0.96349174\n",
      "  0.80302435  1.80490661  0.958799   -0.16800994 -0.2888307   2.22199059\n",
      " -0.14596179  2.91236115 -0.32895011  2.61666608 -0.46688372  1.41919947\n",
      " -0.24241407  0.55335182  0.12249853 -0.38204476 -0.65039057  2.43765044\n",
      " -0.22311573  0.13065745 -0.67969424  1.34610319  3.14788795 -0.18944089\n",
      " -0.45388359 -0.06187332 -0.2685689   0.91854686  2.36902332 -0.88759124\n",
      "  2.4488132   1.83831692 -0.26920208  0.5959022  -0.50750905  0.51064682\n",
      "  0.1895366  -0.70517623 -0.20727065  1.6565181  -0.72306579  5.08148813\n",
      " -0.1415799  -1.01212978  0.97695088 -0.45813024  1.73187804  0.67062575\n",
      " -0.10114212 -0.82642198  2.57383633 -0.15365389  0.63633811 -0.60334283\n",
      " -0.25108281 -0.43604031 -0.79011434  0.51446211 -0.44929591  2.01557589\n",
      "  2.20561123  1.95224404  1.77795124 -0.48286238  0.11404155 -0.61678702\n",
      "  0.43513077 -2.52419019]\n",
      "[ -8.38062227e-01   1.72363460e+00   1.07538521e+00   5.40693521e+00\n",
      "  -2.19357580e-01   2.53496742e+00   1.87434459e+00   3.77432853e-01\n",
      "  -1.34305811e+00  -2.35995531e+00   2.93567252e+00  -1.39303297e-01\n",
      "  -3.20602298e-01   1.22487473e+00   6.93437767e+00   4.84573506e-02\n",
      "  -2.88593245e+00  -4.99837017e+00  -1.73516214e+00   1.25632644e+00\n",
      "   2.35032701e+00  -6.05534792e-01   1.42609799e+00  -3.68939066e+00\n",
      "   4.62253809e+00   5.13590717e+00   5.95235840e-12  -1.12638330e+00\n",
      "  -3.68959993e-01   3.57009590e-01   3.04491907e-01  -2.21810293e+00\n",
      "   3.42683053e+00   2.01885819e+00   2.42712593e+00  -3.94407719e-01\n",
      "   3.49812597e-01   2.00943843e-01   4.78250933e+00  -2.62565327e+00\n",
      "  -2.10399580e+00   1.14639199e+00   4.47692537e+00  -1.40545940e+00\n",
      "  -5.79183772e-02   1.70990527e+00  -3.30736446e+00   3.04026365e-01\n",
      "   1.63905966e+00  -4.48159599e+00  -1.80584446e-01   1.77059519e+00\n",
      "   1.14509666e+00  -5.68514490e+00  -1.69478738e+00   5.20807648e+00\n",
      "   3.50338912e+00   5.27592778e-01   6.24958575e-01  -1.44309437e+00\n",
      "   4.99360487e-02   2.30156803e+00   1.48507670e-01  -2.61059570e+00\n",
      "  -1.98071077e-02  -1.65751278e+00  -1.11545646e+00   8.68363440e-01\n",
      "   1.21068861e-02  -3.28513980e+00   3.75920534e-01  -1.92449260e+00\n",
      "   4.20070410e+00  -1.64712548e+00   6.71229780e-01  -2.14343810e+00\n",
      "  -5.11297047e-01   1.77571583e+00   5.86336279e+00   4.62082326e-02\n",
      "  -6.59788787e-01   8.05086017e-01   2.67099798e-01   5.31867683e-01\n",
      "   2.12555543e-01  -3.86089265e-01   2.24732184e+00   3.81956553e+00\n",
      "   2.97091746e+00  -3.08492088e+00  -1.72885442e+00   3.60219860e+00\n",
      "  -1.85222256e+00   6.97446465e-01   1.21187019e+00   6.12108529e-01\n",
      "   7.93669701e-01   1.54220188e+00   1.94967401e+00  -6.46305978e-01\n",
      "  -7.73514330e-01  -6.56268775e-01  -1.60516632e+00   3.75085163e+00\n",
      "   3.64202231e-01   2.89270592e+00   3.96967947e-01   6.50834203e-01\n",
      "   3.20730877e+00   3.08322406e+00  -1.27607155e+00  -4.15523142e-01\n",
      "  -2.65218830e+00   3.39371413e-01  -1.72026503e+00   4.51901436e-01\n",
      "   4.16413641e+00   1.02270782e+00   1.39290488e+00   2.57016683e+00\n",
      "   2.56167269e+00   2.85741538e-01  -2.23067927e+00  -3.63870168e+00\n",
      "  -2.61048913e+00   1.04774129e+00   3.43152452e+00  -1.03147745e+00]\n",
      "[  9.96715367e-01   1.58896255e+00   2.56640625e+00   1.21486700e+00\n",
      "   1.37680721e+00   1.19716370e+00   1.17963290e+00   8.99641037e-01\n",
      "   7.64323890e-01   1.14802241e+00   1.10909462e+00   1.59556758e+00\n",
      "   2.03418183e+00   1.11261308e+00   1.75489783e+00   1.58398509e+00\n",
      "   1.20647204e+00   9.18176472e-01   1.41453242e+00   1.74353886e+00\n",
      "   6.29960299e-01   1.57618475e+00   2.76562428e+00   1.82785320e+00\n",
      "   4.05374914e-01   1.74723911e+00   3.91628924e-23   2.04270172e+00\n",
      "   1.15283024e+00   8.24670196e-01   9.23377156e-01   3.49753976e+00\n",
      "   1.95072663e+00   1.10316110e+00   2.14506006e+00   2.05354071e+00\n",
      "   2.93755269e+00   1.05969644e+00   9.46161628e-01   2.00973487e+00\n",
      "   1.09282053e+00   1.66543150e+00   2.52487731e+00   1.54499424e+00\n",
      "   1.12595546e+00   1.45830321e+00   6.64857209e-01   1.87220109e+00\n",
      "   7.47650266e-01   2.27403736e+00   8.21067095e-01   1.24311852e+00\n",
      "   2.49208784e+00   9.49720860e-01   3.32553840e+00   3.10620427e+00\n",
      "   9.36835468e-01   9.62598741e-01   1.40628159e+00   7.49689996e-01\n",
      "   1.47244275e+00   9.23238873e-01   5.60583532e-01   1.60926342e+00\n",
      "   1.39678681e+00   1.27483690e+00   3.49079633e+00   1.35214901e+00\n",
      "   1.24790037e+00   1.25891125e+00   2.35427690e+00   6.83549464e-01\n",
      "   1.52630341e+00   9.20882523e-01   5.53385973e-01   2.70208001e+00\n",
      "   1.22069204e+00   5.65000474e-01   1.44587862e+00   1.38327241e+00\n",
      "   1.64558434e+00   1.78969312e+00   1.13359177e+00   1.45684576e+00\n",
      "   1.40880144e+00   1.52125621e+00   8.80076826e-01   1.34121525e+00\n",
      "   1.48328388e+00   2.45492339e+00   1.10290110e+00   6.34244084e-01\n",
      "   1.80560303e+00   1.04103887e+00   1.43701613e+00   1.65173316e+00\n",
      "   1.27426744e+00   1.07670319e+00   1.26876748e+00   1.03438890e+00\n",
      "   1.60988808e+00   1.84967697e+00   1.55145490e+00   1.43088603e+00\n",
      "   9.35320795e-01   2.01729345e+00   1.05425656e+00   1.23297250e+00\n",
      "   1.56704998e+00   3.00755358e+00   1.03336275e+00   1.03721070e+00\n",
      "   1.39556336e+00   2.11952257e+00   1.58265579e+00   1.51623857e+00\n",
      "   1.09678197e+00   5.72463930e-01   1.45521557e+00   7.76128471e-01\n",
      "   1.09751844e+00   1.04238343e+00   9.48275864e-01   1.57336879e+00\n",
      "   1.30721414e+00   1.33693504e+00   6.74388647e-01   7.58969247e-01]\n"
     ]
    }
   ],
   "source": [
    "import math as m\n",
    "layer22 = model.layers[2]\n",
    "W = np.array(layer22.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "batchNorm = model.layers[22].get_weights()\n",
    "\n",
    "fMean = open(\"data/SeventhLayer/Seventh_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/SeventhLayer/Seventh_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/SeventhLayer/Seventh_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/SeventhLayer/Seventh_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Layer Descriptions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7fe70db7d320>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fe70dbd3da0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe70dbd3be0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe70db8ba20>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe70dcf3d68>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fe80c872518>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe70db0fcf8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe70da4be10>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe70da6aac8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe70da2f358>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe70d9f27f0>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fe70d96db38>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fe70d93fbe0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe70d89fc88>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe70d89fb38>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe70d841e48>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe70d805240>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe70d7c8710>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fe70d744a20>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe70d764780>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe70d6fdcf8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fe70d648e80>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fe70d660b70>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fe70d626320>\n",
      "\n",
      "\n",
      " Weight Size\n",
      "(1, 1, 1, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer21 = model.layers[21]\n",
    "W = np.array(layer21.get_weights())\n",
    "\n",
    "print(\"\\n\\n Weight Size\")\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
