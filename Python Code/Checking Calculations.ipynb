{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import Model\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import Conv3D\n",
    "\n",
    "fileName = \"Trump.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "# Global MobileNets model\n",
    "mobile = keras.applications.mobilenet.MobileNet(weights=\"imagenet\")\n",
    "model = Model(mobile.input, mobile.layers[17].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_input(fileName, X):\n",
    "    fhandler = open(fileName, \"w\")\n",
    "    for i in range(3):\n",
    "        for j in range(224):\n",
    "            for k in range(224):\n",
    "                fhandler.write(str(X[j][k][i]) + \"\\n\")\n",
    "    fhandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_Input_Files():\n",
    "    \n",
    "    img_width = 224\n",
    "    img_height = 224\n",
    "\n",
    "    img = image.load_img(fileName, target_size=(img_width, img_height))\n",
    "    X = image.img_to_array(img)\n",
    "\n",
    "    # Normalizing the Input\n",
    "    X = tf.keras.utils.normalize(X, axis=2)\n",
    "    \n",
    "    # Write Normalized Input to file\n",
    "    write_to_file_input(\"data/FirstLayer/inputNorm.txt\", X)\n",
    "    \n",
    "    \n",
    "    # Write combination input to file\n",
    "    X[:, :, 0] = 1\n",
    "    X[:, :, 1] = 10\n",
    "    X[:, :, 2] = 100\n",
    "    write_to_file_input(\"data/FirstLayer/inputComb.txt\", X)\n",
    "    \n",
    "    # Write all 1's input to file\n",
    "    X[:, :, 0] = 1\n",
    "    X[:, :, 1] = 1\n",
    "    X[:, :, 2] = 1\n",
    "    write_to_file_input(\"data/FirstLayer/inputSet1.txt\", X)\n",
    "\n",
    "    print(\"Creating Input files Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_Input_Files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_one(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(32):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = model.layers[2].get_weights()[0]\n",
    "write_to_file_weights_layer_one(\"data/FirstLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_one(\"data/FirstLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_second(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(32):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = model.layers[5].get_weights()[0]\n",
    "write_to_file_weights_layer_second(\"data/SecondLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_second(\"data/SecondLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkCalculations():\n",
    "\n",
    "    img_width = 224\n",
    "    img_height = 224\n",
    "\n",
    "    img = image.load_img(fileName, target_size=(img_width, img_height))\n",
    "    X = image.img_to_array(img)\n",
    "\n",
    "    # Normalized the Input\n",
    "    X = tf.keras.utils.normalize(X, axis=2)\n",
    "    \n",
    "    # Set as 1\n",
    "    #X[:,:,0] = 1\n",
    "    #X[:,:,1] = 1\n",
    "    #X[:,:,2] = 1\n",
    "\n",
    "    # Set as Combination\n",
    "    #X[:,:,0] = 1\n",
    "    #X[:,:,1] = 10\n",
    "    #X[:,:,2] = 100\n",
    "\n",
    "    print(X[0][0][0])\n",
    "    print(X[0][1][0])\n",
    "    print(X[0][2][0])\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    print(X.shape)\n",
    "\n",
    "    # Weights part\n",
    "    W = model.layers[2].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[2].set_weights(W)\n",
    "    \n",
    "    \n",
    "    W = model.layers[5].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[5].set_weights(W)\n",
    "    \n",
    "    W = model.layers[8].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[8].set_weights(W)\n",
    "    \n",
    "    W = model.layers[12].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[12].set_weights(W)\n",
    "    \n",
    "    W = model.layers[15].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[15].set_weights(W)\n",
    "    \n",
    "    \n",
    "    output = model.predict(X)\n",
    "    print(\"Output Shape ---> \")\n",
    "    print(output.shape)\n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "    # Save Output to file\n",
    "    fOutput = open(\"data/FifthLayer/Fifth_Layer_Output.txt\", \"w\")\n",
    "    for i in range(len(output)):\n",
    "        for j in range(len(output[0][0][0])):\n",
    "            for k in range(len(output[0])):\n",
    "                for l in range(len(output[0][0])):\n",
    "                    fOutput.write(str(output[i][k][l][j]) + \"\\n\")\n",
    "    fOutput.close()\n",
    "    print(\"Output File Writing Complete!!!\")\n",
    "\n",
    "    print(\"\\n\\n Description of Layers\")\n",
    "    for layer in model.layers:\n",
    "        print(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:2198: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return sqrt(add.reduce(s, axis=axis, keepdims=keepdims))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.145017\n",
      "0.351735\n",
      "0.563547\n",
      "(1, 224, 224, 3)\n",
      "Output Shape ---> \n",
      "(1, 56, 56, 128)\n",
      "--------------------------------\n",
      "Output File Writing Complete!!!\n",
      "\n",
      "\n",
      " Description of Layers\n",
      "<keras.engine.input_layer.InputLayer object at 0x7f4e05093668>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f4e05086d30>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4e05093710>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f4e71f9e978>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f4e05093b00>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f4e05093eb8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f4e05095be0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f4e05066c88>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4e04fd1ef0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f4e04fecd68>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f4e04f501d0>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f4e04f238d0>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f4e04f23940>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f4e04e76dd8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f4e04e76fd0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4e04e24da0>\n",
      "Total Time --> 9.515028715133667\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "checkCalculations()\n",
    "end = time.time()\n",
    "print(\"Total Time -->\", (end - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 5 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_FifthLayer():\n",
    "    fExp = open('data/FifthLayer/Fifth_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/FifthLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            print(str(cAct[i].strip()) + \"  --->   \" + str(cExp[i].strip()) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.500035  --->   4.49998\n",
      "2.500063  --->   2.49995\n",
      "2.499894  --->   2.50006\n",
      "-0.500034  --->   -0.499943\n",
      "-1.500010  --->   -1.49991\n",
      "-2.500011  --->   -2.49987\n",
      "-1.500065  --->   -1.4999\n",
      "-1.500054  --->   -1.4999\n",
      "6.499984  --->   6.50001\n",
      "5.499949  --->   5.50002\n",
      "Number of mismatch - 10\n"
     ]
    }
   ],
   "source": [
    "checkFile_FifthLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 1 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_FirstLayer():\n",
    "    fExp = open('data/FirstLayer/First_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/FirstLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkFile_FirstLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 4 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_FourthLayer():\n",
    "    fExp = open('data/FourthLayer/Fourth_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/FourthLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            print(str(cAct[i].strip()) + \"--->\" + str(cExp[i].strip()) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkFile_FourthLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 2 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checkFile_SecondLayer():\n",
    "    fExp = open('data/SecondLayer/Second_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/SecondLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            print(str(cAct[i].strip()) + \"--->\" + str(cExp[i].strip()) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkFile_SecondLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_ThirdLayer():\n",
    "    fExp = open('data/ThirdLayer/Third_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/ThirdLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 2 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "batchNorm = model.layers[6].get_weights()\n",
    "\n",
    "fMean = open(\"data/SecondLayer/Second_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/SecondLayer/Second_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/SecondLayer/Second_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/SecondLayer/Second_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 3  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_three(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(1):\n",
    "            for k in range(64):\n",
    "                for l in range(32):\n",
    "                    fTemp.write(str(W[i][j][l][k]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer8 = model.layers[8]\n",
    "W = np.array(layer8.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer8.get_weights()[0]\n",
    "write_to_file_weights_layer_three(\"data/ThirdLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_three(\"data/ThirdLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 3 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "batchNorm = model.layers[9].get_weights()\n",
    "\n",
    "fMean = open(\"data/ThirdLayer/Third_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/ThirdLayer/Third_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/ThirdLayer/Third_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/ThirdLayer/Third_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 4  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_four(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(64):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer12 = model.layers[12]\n",
    "W = np.array(layer12.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer12.get_weights()[0]\n",
    "write_to_file_weights_layer_four(\"data/FourthLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_four(\"data/FourthLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 5 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 128)\n",
      "[ 0.84625638  1.02383471  1.56685507  1.53392398  0.33904353  1.4458853\n",
      "  1.51170194  0.83082479  0.955477    1.13123095  1.1013515   1.41879785\n",
      "  2.21474695  1.38700569  0.36252537  1.04316986  0.54315537  1.87376118\n",
      "  1.21386123  0.78254294  0.86010754  1.48871362 -0.26212534  1.78281236\n",
      "  1.88884306  0.94749653  1.58474302  0.69490999  2.27740693  1.29992759\n",
      "  0.89829856  0.20925736  1.09463227  1.1502974   0.82470417  2.89493084\n",
      "  1.00403166  1.78319514  1.32927835  0.89183581  0.96568424  2.31965899\n",
      "  0.91589761  0.70276219  0.9103806   0.34250018  1.04436719  0.79942542\n",
      "  1.0013448   0.75979525  1.87278211  1.48174322  1.71409392  1.46655822\n",
      "  1.06877542  0.85482883  4.11016703  2.34360766  0.63329691  0.86797684\n",
      "  0.69916892  0.79891354  2.03621101  1.6476953   1.1087749   0.76154518\n",
      "  1.02903056  0.60557914  0.90426254  0.83299804  0.97486693  1.30345845\n",
      "  3.07375693  2.13497806  1.16518438  1.79575491  0.85507828  0.73220152\n",
      "  1.76756811  2.80637932  1.28168058  0.94105053  0.26032412  0.84911436\n",
      "  1.05059719  1.54086471  0.55047792  1.09201944  1.19467473  0.41630363\n",
      "  1.77263498  0.31247005  0.54490399  1.32209897  0.87102264  1.35330725\n",
      "  1.28850865  0.50652963  2.16738224  1.17123127  0.70780027  1.75695705\n",
      "  0.60951686  1.01565087  2.34497237  1.00945032  2.3709259   2.58278918\n",
      "  1.75686741  1.52191794  1.75420833  1.36335933  1.13484061  0.73029494\n",
      "  0.82306904  1.5537492   0.90581673  0.87791067  1.54703879  1.49025655\n",
      "  2.15317988  0.80707783  1.24062574  1.16192377  1.2445606   1.68142521\n",
      "  1.03349674  0.43790144]\n",
      "[  2.22966433e+00   8.68525863e-01   6.71184957e-01  -2.07291350e-01\n",
      "   2.78047824e+00   1.66661683e-02  -1.48949027e+00   1.93569601e+00\n",
      "   6.25438750e-01   1.67780006e+00   1.62504268e+00   1.65959299e+00\n",
      "  -2.74881434e+00   5.33926845e-01   2.08204389e+00   1.99711418e+00\n",
      "   2.26625109e+00  -3.07523155e+00   7.80203462e-01   2.60935140e+00\n",
      "   2.96730709e+00   2.48650312e+00  -1.69486511e+00  -2.45093033e-01\n",
      "  -2.14503959e-01   1.80889082e+00   2.58232427e+00   1.85632205e+00\n",
      "  -2.59792566e-01   1.14573896e+00   1.80366457e+00   2.40566611e+00\n",
      "   3.17414689e+00   1.53386867e+00   1.81060159e+00  -1.67040741e+00\n",
      "   1.67025042e+00  -9.33003187e-01   1.54176939e+00   2.51930928e+00\n",
      "   2.52176666e+00  -1.06658053e+00   1.95622301e+00   1.77226734e+00\n",
      "   3.57683659e+00  -1.55051684e+00   3.11135435e+00   2.20113897e+00\n",
      "   1.37666821e+00   3.27002263e+00   2.81002253e-01   1.98067939e+00\n",
      "   9.99758780e-01   9.11185026e-01   1.16348660e+00   2.02130699e+00\n",
      "   1.47740853e+00   3.71160746e-01   1.40998089e+00   1.38002849e+00\n",
      "   2.56959081e+00   1.84127021e+00  -2.57879764e-01   2.98145354e-01\n",
      "   1.76125860e+00   2.05764794e+00   1.12725544e+00   2.62982297e+00\n",
      "   2.23727489e+00   2.54431081e+00   9.51959372e-01  -9.74949971e-02\n",
      "  -5.19101918e-01   2.49927163e+00   1.05245352e+00  -2.44895324e-01\n",
      "   8.31034362e-01   2.50068688e+00   1.32711136e+00  -4.17224225e-03\n",
      "   6.51682675e-01   2.14992094e+00  -1.52908957e+00   1.91840291e+00\n",
      "   2.39470887e+00   9.92376208e-01   2.19141436e+00   1.44525146e+00\n",
      "   1.28118777e+00   1.51636302e+00   2.31541777e+00  -1.57507837e+00\n",
      "   2.35987735e+00  -1.73593909e-01   3.48225713e+00   2.79945344e-01\n",
      "   2.18480110e+00   2.10408688e+00   2.15190008e-01   3.87032658e-01\n",
      "   2.33737087e+00  -5.41231573e-01   2.76971912e+00   1.47496784e+00\n",
      "  -1.02273512e+00   3.61037791e-01   1.74494326e-01   4.67099369e-01\n",
      "   3.99026811e-01   2.60901785e+00  -4.20787930e-01   3.46976423e+00\n",
      "   1.91266346e+00   1.46990740e+00   4.22875118e+00  -5.21526858e-03\n",
      "   1.43006325e+00   9.96794164e-01   1.34757888e+00   1.70990318e-01\n",
      "   2.55437642e-01   2.61345601e+00   6.66950464e-01   1.69380724e+00\n",
      "  -2.14783341e-01  -7.78562874e-02   1.51455808e+00   3.00471783e+00]\n",
      "[ -5.79303312e+00   1.18225670e+00  -2.26325497e-01   2.02375725e-01\n",
      "  -5.72519016e+00  -7.49914527e-01  -3.30884337e-01   5.18264771e-01\n",
      "   1.37183294e-01  -3.70606351e+00  -5.06622362e+00   3.37276161e-01\n",
      "   2.08969429e-01  -2.13847303e+00  -1.08889699e+00  -1.43507469e+00\n",
      "   1.55465376e+00   3.83542037e+00  -1.81889808e+00  -2.88800693e+00\n",
      "   7.32525408e-01  -1.04064107e+00  -6.71117513e-13   4.54404473e-01\n",
      "  -8.01356912e-01  -1.17766285e+00  -1.47231758e+00   3.55301547e+00\n",
      "   4.01420116e+00   2.37430286e+00   2.17561316e+00  -2.59283352e+00\n",
      "   5.14191031e-01  -3.73794985e+00  -7.88143635e-01   2.44766736e+00\n",
      "  -9.08331811e-01   1.14830756e+00   1.23091149e+00   1.58857918e+00\n",
      "   4.07049465e+00   2.78390288e+00  -5.02347040e+00   3.21191639e-01\n",
      "   3.44866872e+00  -1.01046146e-12   6.05340385e+00  -3.03216791e+00\n",
      "  -5.11065054e+00   3.41136122e+00   1.71108282e+00   1.25106192e+00\n",
      "  -1.40278625e+00  -2.74631649e-01  -1.77399051e+00   1.84228599e+00\n",
      "   1.59480155e+00  -1.39734960e+00  -3.16161585e+00   6.46932364e-01\n",
      "   6.86749220e-01  -4.78267384e+00  -4.95055690e-03   8.50562334e-01\n",
      "   2.04320356e-01   2.32833672e+00   2.37763977e+00  -1.87003815e+00\n",
      "   7.30577111e-01   9.10631418e-01   3.43216109e+00   1.86255693e-01\n",
      "   2.19443226e+00   1.24154770e+00  -1.76429784e+00   6.45652413e-01\n",
      "   5.62900972e+00  -1.81408393e+00   1.08376879e-03   2.35487270e+00\n",
      "   1.41806388e+00  -7.29516029e-01   2.10749699e-11   2.69428468e+00\n",
      "   4.13581312e-01   1.89504302e+00   2.76614577e-01   1.36650741e+00\n",
      "  -3.45275044e-01   2.74401575e-01  -7.25445330e-01   1.85034952e-12\n",
      "  -1.45992887e+00   2.22494459e+00   9.28819847e+00   4.36410666e-01\n",
      "  -4.00284815e+00  -2.63692141e+00  -2.74577403e+00  -7.34215689e+00\n",
      "  -8.80430877e-01   5.39063644e+00  -1.38601542e+00  -6.27158880e+00\n",
      "   5.02064896e+00   9.50145912e+00  -2.26376486e+00  -9.81983304e-01\n",
      "  -1.54859638e+00  -9.71726120e-01   1.89253318e+00   2.61747897e-01\n",
      "  -4.02699232e+00  -1.05802524e+00   3.51282167e+00   1.12242877e+00\n",
      "   2.04508781e+00   2.97046566e+00   1.02845299e+00  -1.69569278e+00\n",
      "  -2.28688502e+00  -3.83291423e-01   1.89737093e+00  -1.88399863e+00\n",
      "  -2.15671539e+00   3.34998906e-01  -4.77854431e-01  -8.13561261e-01]\n",
      "[  1.29786718e+00   6.81126237e-01   5.72486699e-01   7.73748219e-01\n",
      "   4.36989427e-01   3.22971165e-01   2.86038160e-01   5.26552498e-01\n",
      "   6.63632989e-01   1.90903544e+00   3.18621683e+00   1.20669723e+00\n",
      "   6.80730104e-01   2.86603123e-01   9.27404165e-01   5.53639948e-01\n",
      "   2.76085436e-01   1.28381109e+00   9.99029875e-01   1.25082719e+00\n",
      "   2.56121635e-01   4.43476558e-01   3.45555466e-26   5.13830960e-01\n",
      "   4.60103065e-01   1.54298174e+00   6.61907673e-01   1.66633737e+00\n",
      "   6.10423505e-01   7.73172319e-01   4.71268833e-01   1.48541367e+00\n",
      "   1.11258745e+00   2.75376272e+00   3.62892151e-01   1.71724427e+00\n",
      "   4.70869720e-01   5.18843830e-01   4.21993673e-01   3.99802327e+00\n",
      "   2.61750627e+00   6.12651289e-01   2.76652479e+00   4.15118188e-01\n",
      "   1.36925888e+00   2.01969457e-25   2.26813531e+00   7.16403961e-01\n",
      "   6.42337501e-01   9.94341254e-01   6.19527221e-01   6.69295371e-01\n",
      "   3.74497294e-01   4.61128622e-01   2.59312630e-01   1.20132637e+00\n",
      "   2.31596962e-01   5.01459897e-01   1.28082681e+00   1.49788463e+00\n",
      "   5.14503360e-01   1.39956999e+00   6.48362994e-01   5.01742125e-01\n",
      "   8.50633204e-01   1.17052066e+00   4.09958184e-01   1.45196068e+00\n",
      "   3.04439616e+00   4.63321596e-01   8.40574563e-01   9.91539180e-01\n",
      "   7.33912647e-01   4.80444252e-01   3.85854304e-01   1.91323921e-01\n",
      "   4.41771954e-01   7.91439712e-01   6.04874551e-01   1.88094950e+00\n",
      "   6.59853518e-01   2.05490947e+00   6.26630019e-23   1.75182378e+00\n",
      "   1.58457768e+00   4.31963146e-01   5.89328289e-01   3.17136884e-01\n",
      "   3.50504071e-01   3.94946873e-01   3.49276453e-01   1.43351242e-24\n",
      "   1.40939188e+00   2.81259984e-01   3.94784713e+00   6.18474424e-01\n",
      "   1.82126439e+00   7.05381393e-01   1.23008072e+00   6.06348276e-01\n",
      "   4.90991741e-01   5.42346597e-01   3.49501491e-01   2.84781051e+00\n",
      "   2.40280437e+00   9.94039416e-01   2.63707829e+00   5.66909671e-01\n",
      "   1.34364808e+00   4.31521177e-01   6.82090819e-01   5.06962061e-01\n",
      "   1.18882239e+00   5.74465871e-01   2.81112194e+00   3.87565345e-01\n",
      "   8.86686087e-01   8.46966565e-01   1.06374443e+00   9.08775270e-01\n",
      "   5.03704846e-01   2.83657980e+00   6.04222238e-01   2.00068280e-01\n",
      "   5.40736020e-01   2.65898347e-01   3.16018045e-01   7.55368471e-01]\n"
     ]
    }
   ],
   "source": [
    "import math as m\n",
    "layer16 = model.layers[16]\n",
    "W = np.array(layer16.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "batchNorm = model.layers[16].get_weights()\n",
    "\n",
    "fMean = open(\"data/FifthLayer/Fifth_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/FifthLayer/Fifth_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/FifthLayer/Fifth_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/FifthLayer/Fifth_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 4 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "layer13 = model.layers[13]\n",
    "W = np.array(layer13.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "fMean = open(\"data/FourthLayer/Fourth_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/FourthLayer/Fourth_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/FourthLayer/Fourth_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/FourthLayer/Fourth_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 5  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_five(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(128):\n",
    "            for k in range(1):\n",
    "                for l in range(64):\n",
    "                    fTemp.write(str(W[i][k][l][j]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f4ee174eac8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f4e67fb71d0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4e67fb7438>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f4e67fb75f8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f4e67fb7e48>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f4e67fb7a90>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f4e67fb7ef0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f4e646c76a0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4e6464ba58>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f4e6460c358>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f4e645d0c88>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f4e645a5588>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f4e645a5fd0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f4e6448d6a0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f4e6448d7b8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4e644bbfd0>\n",
      "(1, 1, 1, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer15 = model.layers[15]\n",
    "W = np.array(layer15.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer15.get_weights()[0]\n",
    "write_to_file_weights_layer_five(\"data/FifthLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_five(\"data/FifthLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Layer Descriptions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f4db6e86da0>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f4db6ef5f60>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4db6ef5358>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f4db6f2cf60>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f4db6f05358>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f4db6f74c18>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f4de40d9128>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f4db6dd8048>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4db6da1f98>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f4db6d6af60>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f4db6cfed30>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f4db6c4bdd8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f4db6c63c18>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f4db6b83a90>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f4db6b83dd8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4db6ba2a58>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f4db6b40e10>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f4db6ad5e80>\n",
      "\n",
      "\n",
      " Weight Size\n",
      "(1, 1, 1, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer8 = model.layers[15]\n",
    "W = np.array(layer8.get_weights())\n",
    "\n",
    "print(\"\\n\\n Weight Size\")\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
