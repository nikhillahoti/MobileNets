{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import Model\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import Conv3D\n",
    "\n",
    "fileName = \"Trump.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "# Global MobileNets model\n",
    "mobile = keras.applications.mobilenet.MobileNet(weights=\"imagenet\")\n",
    "model = Model(mobile.input, mobile.layers[18].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_input(fileName, X):\n",
    "    fhandler = open(fileName, \"w\")\n",
    "    for i in range(3):\n",
    "        for j in range(224):\n",
    "            for k in range(224):\n",
    "                fhandler.write(str(X[j][k][i]) + \"\\n\")\n",
    "    fhandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_Input_Files():\n",
    "    \n",
    "    img_width = 224\n",
    "    img_height = 224\n",
    "\n",
    "    img = image.load_img(fileName, target_size=(img_width, img_height))\n",
    "    X = image.img_to_array(img)\n",
    "\n",
    "    # Normalizing the Input\n",
    "    X = tf.keras.utils.normalize(X, axis=2)\n",
    "    \n",
    "    # Write Normalized Input to file\n",
    "    write_to_file_input(\"data/FirstLayer/inputNorm.txt\", X)\n",
    "    \n",
    "    \n",
    "    # Write combination input to file\n",
    "    X[:, :, 0] = 1\n",
    "    X[:, :, 1] = 10\n",
    "    X[:, :, 2] = 100\n",
    "    write_to_file_input(\"data/FirstLayer/inputComb.txt\", X)\n",
    "    \n",
    "    # Write all 1's input to file\n",
    "    X[:, :, 0] = 1\n",
    "    X[:, :, 1] = 1\n",
    "    X[:, :, 2] = 1\n",
    "    write_to_file_input(\"data/FirstLayer/inputSet1.txt\", X)\n",
    "\n",
    "    print(\"Creating Input files Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_Input_Files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_one(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(32):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = model.layers[2].get_weights()[0]\n",
    "write_to_file_weights_layer_one(\"data/FirstLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_one(\"data/FirstLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_second(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(32):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = model.layers[5].get_weights()[0]\n",
    "write_to_file_weights_layer_second(\"data/SecondLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_second(\"data/SecondLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkCalculations():\n",
    "\n",
    "    img_width = 224\n",
    "    img_height = 224\n",
    "\n",
    "    img = image.load_img(fileName, target_size=(img_width, img_height))\n",
    "    X = image.img_to_array(img)\n",
    "\n",
    "    # Normalized the Input\n",
    "    X = tf.keras.utils.normalize(X, axis=2)\n",
    "    \n",
    "    # Set as 1\n",
    "    #X[:,:,0] = 1\n",
    "    #X[:,:,1] = 1\n",
    "    #X[:,:,2] = 1\n",
    "\n",
    "    # Set as Combination\n",
    "    #X[:,:,0] = 1\n",
    "    #X[:,:,1] = 10\n",
    "    #X[:,:,2] = 100\n",
    "\n",
    "    print(X[0][0][0])\n",
    "    print(X[0][1][0])\n",
    "    print(X[0][2][0])\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    print(X.shape)\n",
    "\n",
    "    # Weights part\n",
    "    W = model.layers[2].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[2].set_weights(W)\n",
    "    \n",
    "    \n",
    "    W = model.layers[5].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[5].set_weights(W)\n",
    "    \n",
    "    W = model.layers[8].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[8].set_weights(W)\n",
    "    \n",
    "    W = model.layers[12].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[12].set_weights(W)\n",
    "    \n",
    "    W = model.layers[15].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[15].set_weights(W)\n",
    "    \n",
    "    \n",
    "    output = model.predict(X)\n",
    "    print(\"Output Shape ---> \")\n",
    "    print(output.shape)\n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "    # Save Output to file\n",
    "    fOutput = open(\"data/FifthLayer/Fifth_Layer_Output.txt\", \"w\")\n",
    "    for i in range(len(output)):\n",
    "        for j in range(len(output[0][0][0])):\n",
    "            for k in range(len(output[0])):\n",
    "                for l in range(len(output[0][0])):\n",
    "                    fOutput.write(str(output[i][k][l][j]) + \"\\n\")\n",
    "    fOutput.close()\n",
    "    print(\"Output File Writing Complete!!!\")\n",
    "\n",
    "    print(\"\\n\\n Description of Layers\")\n",
    "    for layer in model.layers:\n",
    "        print(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "checkCalculations()\n",
    "end = time.time()\n",
    "print(\"Total Time -->\", (end - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 5 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_FifthLayer():\n",
    "    fExp = open('data/FifthLayer/Fifth_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/FifthLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            print(str(cAct[i].strip()) + \"  --->   \" + str(cExp[i].strip()) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkFile_FifthLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 1 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_FirstLayer():\n",
    "    fExp = open('data/FirstLayer/First_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/FirstLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mismatch - 388864\n"
     ]
    }
   ],
   "source": [
    "checkFile_FirstLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 4 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_FourthLayer():\n",
    "    fExp = open('data/FourthLayer/Fourth_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/FourthLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            print(str(cAct[i].strip()) + \"--->\" + str(cExp[i].strip()) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkFile_FourthLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 2 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checkFile_SecondLayer():\n",
    "    fExp = open('data/SecondLayer/Second_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/SecondLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            print(str(cAct[i].strip()) + \"--->\" + str(cExp[i].strip()) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkFile_SecondLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_ThirdLayer():\n",
    "    fExp = open('data/ThirdLayer/Third_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/ThirdLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 2 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "batchNorm = model.layers[6].get_weights()\n",
    "\n",
    "fMean = open(\"data/SecondLayer/Second_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/SecondLayer/Second_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/SecondLayer/Second_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/SecondLayer/Second_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 3  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_three(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(1):\n",
    "            for k in range(64):\n",
    "                for l in range(32):\n",
    "                    fTemp.write(str(W[i][j][l][k]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer8 = model.layers[8]\n",
    "W = np.array(layer8.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer8.get_weights()[0]\n",
    "write_to_file_weights_layer_three(\"data/ThirdLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_three(\"data/ThirdLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 3 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "batchNorm = model.layers[9].get_weights()\n",
    "\n",
    "fMean = open(\"data/ThirdLayer/Third_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/ThirdLayer/Third_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/ThirdLayer/Third_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/ThirdLayer/Third_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 4  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_four(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(64):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer12 = model.layers[12]\n",
    "W = np.array(layer12.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer12.get_weights()[0]\n",
    "write_to_file_weights_layer_four(\"data/FourthLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_four(\"data/FourthLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 5 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "layer16 = model.layers[16]\n",
    "W = np.array(layer16.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "batchNorm = model.layers[16].get_weights()\n",
    "\n",
    "fMean = open(\"data/FifthLayer/Fifth_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/FifthLayer/Fifth_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/FifthLayer/Fifth_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/FifthLayer/Fifth_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 4 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "layer13 = model.layers[13]\n",
    "W = np.array(layer13.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "fMean = open(\"data/FourthLayer/Fourth_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/FourthLayer/Fourth_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/FourthLayer/Fourth_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/FourthLayer/Fourth_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 5  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_five(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(128):\n",
    "            for k in range(1):\n",
    "                for l in range(64):\n",
    "                    fTemp.write(str(W[i][k][l][j]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer15 = model.layers[15]\n",
    "W = np.array(layer15.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer15.get_weights()[0]\n",
    "write_to_file_weights_layer_five(\"data/FifthLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_five(\"data/FifthLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 6  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_six(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(128):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[i][k][l][j]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7fda5f453a90>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fda5f441e10>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fda5f441c50>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f4f3e10>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f4cec50>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fda5f527a20>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f592e48>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f36ab00>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fda5f317d68>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f335b70>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f249e10>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fda5f26c780>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fda5f26c8d0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f1bdc88>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f1bdfd0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fda5f169c50>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f109a58>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f0a2e10>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fda5f047668>\n",
      "(1, 3, 3, 128, 1)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/SixthLayer/weightsNorm.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-88c5dcd21ae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer18\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mwrite_to_file_weights_layer_six\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/SixthLayer/weightsNorm.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-24db21d345f6>\u001b[0m in \u001b[0;36mwrite_to_file_weights_layer_six\u001b[0;34m(fileName, W)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrite_to_file_weights_layer_six\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfTemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/SixthLayer/weightsNorm.txt'"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer18 = model.layers[18]\n",
    "W = np.array(layer18.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer18.get_weights()[0]\n",
    "write_to_file_weights_layer_six(\"data/SixthLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_six(\"data/SixthLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Layer Descriptions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7fda5f453a90>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fda5f441e10>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fda5f441c50>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f4f3e10>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f4cec50>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fda5f527a20>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f592e48>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f36ab00>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fda5f317d68>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f335b70>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f249e10>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fda5f26c780>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fda5f26c8d0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f1bdc88>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f1bdfd0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fda5f169c50>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fda5f109a58>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fda5f0a2e10>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fda5f047668>\n",
      "\n",
      "\n",
      " Weight Size\n",
      "(1, 3, 3, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer18 = model.layers[18]\n",
    "W = np.array(layer18.get_weights())\n",
    "\n",
    "print(\"\\n\\n Weight Size\")\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
