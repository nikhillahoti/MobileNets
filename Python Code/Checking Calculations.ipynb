{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import Model\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import Conv3D\n",
    "\n",
    "fileName = \"Trump.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "# Global MobileNets model\n",
    "mobile = keras.applications.mobilenet.MobileNet(weights=\"imagenet\")\n",
    "model = Model(mobile.input, mobile.layers[14].output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_input(fileName, X):\n",
    "    fhandler = open(fileName, \"w\")\n",
    "    for i in range(3):\n",
    "        for j in range(224):\n",
    "            for k in range(224):\n",
    "                fhandler.write(str(X[j][k][i]) + \"\\n\")\n",
    "    fhandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_Input_Files():\n",
    "    \n",
    "    img_width = 224\n",
    "    img_height = 224\n",
    "\n",
    "    img = image.load_img(fileName, target_size=(img_width, img_height))\n",
    "    X = image.img_to_array(img)\n",
    "\n",
    "    # Normalizing the Input\n",
    "    X = tf.keras.utils.normalize(X, axis=2)\n",
    "    \n",
    "    # Write Normalized Input to file\n",
    "    write_to_file_input(\"data/FirstLayer/inputNorm.txt\", X)\n",
    "    \n",
    "    \n",
    "    # Write combination input to file\n",
    "    X[:, :, 0] = 1\n",
    "    X[:, :, 1] = 10\n",
    "    X[:, :, 2] = 100\n",
    "    write_to_file_input(\"data/FirstLayer/inputComb.txt\", X)\n",
    "    \n",
    "    # Write all 1's input to file\n",
    "    X[:, :, 0] = 1\n",
    "    X[:, :, 1] = 1\n",
    "    X[:, :, 2] = 1\n",
    "    write_to_file_input(\"data/FirstLayer/inputSet1.txt\", X)\n",
    "\n",
    "    print(\"Creating Input files Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_Input_Files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_one(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(32):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = model.layers[2].get_weights()[0]\n",
    "write_to_file_weights_layer_one(\"data/FirstLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_one(\"data/FirstLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_second(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(32):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = model.layers[5].get_weights()[0]\n",
    "write_to_file_weights_layer_second(\"data/SecondLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_second(\"data/SecondLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkCalculations():\n",
    "\n",
    "    img_width = 224\n",
    "    img_height = 224\n",
    "\n",
    "    img = image.load_img(fileName, target_size=(img_width, img_height))\n",
    "    X = image.img_to_array(img)\n",
    "\n",
    "    # Normalized the Input\n",
    "    X = tf.keras.utils.normalize(X, axis=2)\n",
    "    \n",
    "    # Set as 1\n",
    "    #X[:,:,0] = 1\n",
    "    #X[:,:,1] = 1\n",
    "    #X[:,:,2] = 1\n",
    "\n",
    "    # Set as Combination\n",
    "    #X[:,:,0] = 1\n",
    "    #X[:,:,1] = 10\n",
    "    #X[:,:,2] = 100\n",
    "\n",
    "    print(X[0][0][0])\n",
    "    print(X[0][1][0])\n",
    "    print(X[0][2][0])\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    print(X.shape)\n",
    "\n",
    "    # Weights part\n",
    "    W = model.layers[2].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[2].set_weights(W)\n",
    "    \n",
    "    \n",
    "    W = model.layers[5].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[5].set_weights(W)\n",
    "    \n",
    "    W = model.layers[8].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[8].set_weights(W)\n",
    "    \n",
    "    W = model.layers[12].get_weights()[0]\n",
    "    # Weights set as 1\n",
    "    #W[:,:,:,:] = 1\n",
    "    W = np.expand_dims(W, axis=0)\n",
    "    model.layers[12].set_weights(W)\n",
    "    \n",
    "    \n",
    "    output = model.predict(X)\n",
    "    print(\"Output Shape ---> \")\n",
    "    print(output.shape)\n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "    # Save Output to file\n",
    "    fOutput = open(\"data/FourthLayer/Fourth_Layer_Output.txt\", \"w\")\n",
    "    for i in range(len(output)):\n",
    "        for j in range(len(output[0][0][0])):\n",
    "            for k in range(len(output[0])):\n",
    "                for l in range(len(output[0][0])):\n",
    "                    fOutput.write(str(output[i][k][l][j]) + \"\\n\")\n",
    "    fOutput.close()\n",
    "    print(\"Output File Writing Complete!!!\")\n",
    "\n",
    "    print(\"\\n\\n Description of Layers\")\n",
    "    for layer in model.layers:\n",
    "        print(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:2198: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return sqrt(add.reduce(s, axis=axis, keepdims=keepdims))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.145017\n",
      "0.351735\n",
      "0.563547\n",
      "(1, 224, 224, 3)\n",
      "Output Shape ---> \n",
      "(1, 56, 56, 64)\n",
      "--------------------------------\n",
      "Output File Writing Complete!!!\n",
      "\n",
      "\n",
      " Description of Layers\n",
      "<keras.engine.input_layer.InputLayer object at 0x7f65ed35f6d8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f65ed34b048>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f65ed34b780>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f65ed32cc18>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f65ed3e2c88>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f65ed435f60>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6608609ac8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f65ed1c4438>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f65ed191e10>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f65ed1575f8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f65ed0ee828>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f65ed053e10>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f65ed03ada0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f65ecfced68>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f65ecfefb00>\n",
      "Total Time --> 1.910287618637085\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "checkCalculations()\n",
    "end = time.time()\n",
    "print(\"Total Time -->\", (end - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 1 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_FirstLayer():\n",
    "    fExp = open('data/FirstLayer/First_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/FirstLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checkFile_FirstLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 4 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_FourthLayer():\n",
    "    fExp = open('data/FourthLayer/Fourth_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/FourthLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            print(str(cAct[i].strip()) + \"--->\" + str(cExp[i].strip()) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.499965--->1.50003\n",
      "1.499946--->1.50001\n",
      "0.499976--->0.500001\n",
      "5.500043--->5.49995\n",
      "0.500012--->0.499979\n",
      "0.500025--->0.499972\n",
      "Number of mismatch - 6\n"
     ]
    }
   ],
   "source": [
    "checkFile_FourthLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Checking calculations for Layer 2 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checkFile_SecondLayer():\n",
    "    fExp = open('data/SecondLayer/Second_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/SecondLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            print(str(cAct[i].strip()) + \"--->\" + str(cExp[i].strip()) )\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkFile_SecondLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_ThirdLayer():\n",
    "    fExp = open('data/ThirdLayer/Third_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/ThirdLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 2 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "batchNorm = model.layers[6].get_weights()\n",
    "\n",
    "fMean = open(\"data/SecondLayer/Second_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/SecondLayer/Second_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/SecondLayer/Second_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/SecondLayer/Second_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 3  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_three(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(1):\n",
    "            for k in range(64):\n",
    "                for l in range(32):\n",
    "                    fTemp.write(str(W[i][j][l][k]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer8 = model.layers[8]\n",
    "W = np.array(layer8.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer8.get_weights()[0]\n",
    "write_to_file_weights_layer_three(\"data/ThirdLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_three(\"data/ThirdLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 3 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "batchNorm = model.layers[9].get_weights()\n",
    "\n",
    "fMean = open(\"data/ThirdLayer/Third_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/ThirdLayer/Third_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/ThirdLayer/Third_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/ThirdLayer/Third_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Weights for Layer 4  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_four(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(64):\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    fTemp.write(str(W[k][l][j][i]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f660b3bb908>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f660b5472b0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f660b38a588>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f660b2f9208>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f660b27cc50>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f660b1805f8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f660b1a6a90>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f660b16b080>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f660b0e1a58>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f660b07f8d0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f660b015eb8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f660b03a5f8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f660b03a518>\n",
      "(1, 3, 3, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer12 = model.layers[12]\n",
    "W = np.array(layer12.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer12.get_weights()[0]\n",
    "write_to_file_weights_layer_four(\"data/FourthLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_four(\"data/FourthLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Saving Batch Norm for Layer 4 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 64)\n",
      "[ 1.38348353  1.47560787  0.94327289  2.52066731  1.1112169   1.52000153\n",
      "  0.73906952  1.63390362  1.92089713  0.81571817  0.53765494  0.80437833\n",
      "  0.86839521  1.08065605  2.18609071  0.80576593  2.43806696  1.15816617\n",
      "  0.71519762  0.62076974  2.79951119  1.06928027  0.99761575  0.70051205\n",
      "  0.52957755  0.85605872  1.84557652  0.82739472  0.75509226 -0.0601096\n",
      "  0.61765569  0.7890318   0.48274291  0.81780404  0.69774002  1.0890398\n",
      "  1.01850903  0.74624085  1.75462723  0.75666267  0.8766976   0.82982421\n",
      "  0.95094448  0.76329172  1.00105667  0.86809069  0.75934273  1.66352975\n",
      "  1.81950665  0.74744266  0.89606416  0.80732352  1.16010153  0.82986408\n",
      "  0.9129914   0.4588367   1.71780777  0.45880765  2.36448312  1.29939568\n",
      "  0.77315372  1.06951511  0.86357665  2.44567943]\n",
      "[  1.94595993e-01   1.51977777e-01   9.39456224e-01   5.48644364e-01\n",
      "   2.34944916e+00  -1.00530587e-01   3.01193976e+00   2.48573739e-02\n",
      "  -9.34216604e-02   4.89758158e+00   1.19078231e+00   9.99139249e-01\n",
      "   9.04175639e-01   3.22879124e+00   2.58294344e-01   1.01746035e+00\n",
      "   2.12563902e-01   5.16658127e-01   1.93890524e+00   8.47025692e-01\n",
      "  -2.25495553e+00   3.02036190e+00   9.68777001e-01   3.82850528e+00\n",
      "   1.86462033e+00   5.07349968e+00  -1.02700174e-01   1.29439509e+00\n",
      "   1.97007561e+00  -3.11007023e-01   9.43113625e-01   7.44570136e-01\n",
      "   3.08012873e-01   2.05742836e+00   2.21463656e+00   5.65352701e-02\n",
      "   7.41952136e-02   2.28834224e+00   5.16576409e-01   5.27720737e+00\n",
      "   4.89698648e+00   5.02598476e+00   1.82889736e+00   2.16016698e+00\n",
      "   5.64551890e-01   1.04913354e+00   1.14713025e+00  -1.35319218e-01\n",
      "  -7.62317702e-02   2.51163268e+00   4.94478416e+00   2.11370277e+00\n",
      "   1.17479661e-03   9.05685484e-01   5.07857323e+00   4.71551746e-01\n",
      "  -3.23699981e-01  -4.91452605e-01  -6.50695682e-01   2.17335727e-02\n",
      "   2.28245473e+00   1.00500464e-01   1.17908251e+00   1.26385415e+00]\n",
      "[ -1.72885723e+01  -1.90928154e+01  -1.71862316e+01   2.48619258e-01\n",
      "  -2.60068512e+00  -5.26923835e-02   2.70744371e+00  -3.96359563e-01\n",
      "  -2.12914780e-01  -5.25664377e+00   1.45108891e+01   7.80962515e+00\n",
      "   3.60897923e+00  -3.00903893e+01   5.70316792e-01   5.01133728e+00\n",
      "  -4.47830781e-02  -1.62367058e+01  -9.89846897e+00   6.56075895e-01\n",
      "  -1.82380714e+01  -2.13885956e+01   1.98509445e+01  -8.01062775e+00\n",
      "  -3.91816747e-35  -3.97713709e+00  -3.24994534e-01   9.24212575e-01\n",
      "   3.99095154e+01   8.79466534e-01   2.93885899e+00   2.97306013e+00\n",
      "   1.19921196e+00  -1.19593077e+01  -4.05245876e+00  -2.42420867e-01\n",
      "   2.71849442e+00   2.25634837e+00  -1.16046822e+00  -4.86652613e+00\n",
      "  -5.24933434e+00  -4.98054409e+00  -1.20078926e+01   5.55926847e+00\n",
      "   8.49936783e-01   4.57328987e+00   4.99430132e+00  -2.26121922e+01\n",
      "  -1.89195916e-01  -7.91849184e+00  -5.88915634e+00   1.98672886e+01\n",
      "  -8.83314705e+00   4.22226191e+00  -4.37779570e+00   2.37829924e+00\n",
      "  -2.37958488e+01  -3.91799958e-35  -1.66127129e+01   7.84285646e-03\n",
      "   1.48593202e-01  -1.68775547e+00   1.09012470e+01   2.85693347e-01]\n",
      "[  2.16115082e+02   4.61600533e+01   2.47267288e+02   1.25081816e+01\n",
      "   3.13560123e+01   1.68116169e+01   2.07015076e+02   1.76281414e+01\n",
      "   1.69909706e+01   2.60191593e+01   2.09496094e+02   4.98770981e+01\n",
      "   1.60633030e+01   8.47220688e+01   1.74106216e+01   2.91394100e+01\n",
      "   1.05469666e+01   1.82938309e+01   2.48121384e+02   4.56133080e+00\n",
      "   1.56060349e+02   4.27346115e+01   1.10564880e+02   2.77039871e+01\n",
      "   3.91799643e-35   1.86071987e+01   1.13521757e+01   8.04750824e+00\n",
      "   4.18235596e+02   6.16343971e-03   2.09827347e+01   1.35495052e+01\n",
      "   3.54205990e+00   2.14184021e+02   1.11148163e+02   2.43733368e+01\n",
      "   3.16214447e+01   9.14760876e+00   4.07237091e+01   3.00689220e+01\n",
      "   2.66773338e+01   2.61629181e+01   1.61447952e+02   7.75324297e+00\n",
      "   2.46145210e+01   2.17415218e+01   2.72230415e+01   1.11060661e+02\n",
      "   1.24335003e+01   6.42429199e+01   3.85871315e+01   2.88041351e+02\n",
      "   2.67231407e+01   2.14386978e+01   2.67309589e+01   1.67454967e+01\n",
      "   4.25629921e+01   3.91818153e-35   2.31220810e+02   2.20746994e+01\n",
      "   6.90791607e+00   8.78969669e+00   1.25377609e+02   7.44254827e+00]\n"
     ]
    }
   ],
   "source": [
    "import math as m\n",
    "layer13 = model.layers[13]\n",
    "W = np.array(layer13.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "fMean = open(\"data/FourthLayer/Fourth_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/FourthLayer/Fourth_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/FourthLayer/Fourth_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/FourthLayer/Fourth_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Layer Descriptions </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f65ed35f6d8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f65ed34b048>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f65ed34b780>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f65ed32cc18>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f65ed3e2c88>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f65ed435f60>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f6608609ac8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f65ed1c4438>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f65ed191e10>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f65ed1575f8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f65ed0ee828>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7f65ed053e10>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7f65ed03ada0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f65ecfced68>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7f65ecfefb00>\n",
      "\n",
      "\n",
      " Weight Size\n",
      "(1, 3, 3, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer8 = model.layers[12]\n",
    "W = np.array(layer8.get_weights())\n",
    "\n",
    "print(\"\\n\\n Weight Size\")\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
