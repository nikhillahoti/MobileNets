{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import Model\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import Conv3D\n",
    "\n",
    "fileName = \"Trump.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "# Global MobileNets model\n",
    "mobile = keras.applications.mobilenet.MobileNet(weights=\"imagenet\")\n",
    "model = Model(mobile.input, mobile.layers[77].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7fb450a98ac8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fb450a98d30>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb450a932e8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb450a95c18>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb450a93be0>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fb450acaa20>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb450a8fe80>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb450a26a20>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb4509d49b0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb45093b198>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb45093b940>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fb4508bbcc0>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fb4508db7f0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb45080fa58>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb45080fc88>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb4507b0d68>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb45076d048>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb45074dbe0>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fb450767198>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb4506c84a8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb4506292e8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb4506435f8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb450624f60>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb450585e80>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fb4505a3438>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fb450545668>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb450496358>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb450496588>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb45043b668>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb4503f6128>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb4504965c0>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fb4503e5f28>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb450356780>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb4502c7b38>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb450277908>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb4502341d0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb450234b00>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fb4501b4e80>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fb4501d59b0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb450113c18>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb450113e48>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb450113e80>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb450073128>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb450058da0>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fb44bfca358>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb44bfaa668>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb44bf0d4a8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb44bf287b8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb44bea0278>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb44be8c860>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fb44be0cac8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb44be617f0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb44bd40748>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb44bd6b6d8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb44bcdd518>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb44bcc4b00>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fb44bc4cd68>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb44bc9da90>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb450abfa20>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb450aca0b8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb450a729b0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb450b22278>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fb450b0b5c0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb450af9160>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb450b5aac8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb450b52d68>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb450b9b748>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb450b7f470>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fb450b74da0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb450b6a4a8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb450c234e0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fb450c06320>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb450bf04e0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb450c19f60>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fb450c47e10>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fb450c2b828>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fb450ce2e48>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fb450ce2c18>\n",
      "\n",
      "\n",
      " Weight Size\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer75 = model.layers[75]\n",
    "W = np.array(layer75.get_weights())\n",
    "\n",
    "print(\"\\n\\n Weight Size\")\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_TwentyThree(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(1):\n",
    "            for k in range(512):\n",
    "                for l in range(512):\n",
    "                    fTemp.write(str(W[i][j][l][k]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7fdc913d2da0>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fdc034f80f0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fdc034c13c8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdc03341f28>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdc03341dd8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fdc02b059b0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdc0027bfd0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdc001d54a8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fdc001f32e8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdc00166278>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdc001cf860>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fdc0014fac8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fdc00105208>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdc0003f518>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdc0003f748>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fdbf0618828>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdbf05d80b8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdbf05d8a20>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fdbf0557da0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdbf0536940>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdbf04a6cf8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fdbf0458ac8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdbf03d5f60>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdbf03fcdd8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fdbf03b8b70>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fdbf0375be0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdbf02f4dd8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdbf02f4e80>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fdbf02966a0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdbf0256908>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdbf022da90>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fdbf01d68d0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdbf01e5eb8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdbf018a668>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fdbf01365f8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdbf00a8438>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdbf010fa20>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7fdbf0015c88>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fdbf0033f60>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdbf0064d30>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdbdc7d7c50>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fdbdc7117f0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdbdc6cd9e8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdbdc64de48>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fdbdc66d978>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdbdc62d9e8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdbdc599f98>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fdbdc54ec50>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdbdc508ba8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdbdc4edba8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fdbdc48a160>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdbdc4684a8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdbdc3ce400>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fdbdc3e76a0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdbdc35e0b8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdbdc346780>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fdbdc2c9a90>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdbdc321860>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdbdc1fc860>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fdbdc228780>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdbdc196780>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdbdc184be0>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fdbdc10aef0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdbdc0f6780>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdbdc067be0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fdb9d7da9b0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdb9d799ba8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdb9d7080b8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7fdb9d73ab38>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdb9d6f5208>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdb9d65e1d0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fdb9d678400>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7fdb9d5d6e48>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7fdb9d5bad68>\n",
      "(1, 1, 1, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer71 = model.layers[71]\n",
    "W = np.array(layer71.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer71.get_weights()[0]\n",
    "write_to_file_weights_layer_TwentyThree(\"data/TwentyThreeLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_TwentyThree(\"data/TwentyThreeLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 512)\n",
      "[1.5173318  1.6008642  1.4689811  1.4713336  1.4275397  1.6264757\n",
      " 1.1663939  1.4125123  1.4875103  1.4873332  1.3715508  1.5657916\n",
      " 1.5420094  1.3985534  1.341749   1.3711243  0.6012167  1.0912454\n",
      " 1.3560206  0.6727117  1.4602525  1.4753789  1.2908301  1.4374319\n",
      " 1.411629   1.3761029  0.79788584 1.4887654  1.1458087  0.81084347\n",
      " 1.2344173  1.5000337  1.7883689  1.2608628  1.5946541  1.428438\n",
      " 1.1252297  0.74069566 1.4709011  1.2167107  1.6330926  1.565382\n",
      " 0.49414116 1.4730585  0.55366814 1.4106207  1.2917628  1.3022705\n",
      " 0.56583965 1.1041473  1.5583454  1.4460151  1.5329043  1.4865532\n",
      " 1.5679955  1.7021731  1.308258   1.2945687  1.4162587  1.0285407\n",
      " 1.5922552  1.3466315  0.5645584  0.61929196 0.83206093 0.8298447\n",
      " 1.5051054  1.4326208  1.6800714  1.3012834  1.4323012  1.281575\n",
      " 1.5035267  1.5872813  1.4633898  1.3264426  1.5618507  1.5743729\n",
      " 1.5910784  0.71949327 0.6420845  1.5542271  1.2872199  1.3908677\n",
      " 0.7322533  1.2263584  1.4935468  1.0205264  1.2836174  1.4915713\n",
      " 0.93642366 0.66771734 1.4471635  1.143187   1.3628716  1.5911251\n",
      " 0.616983   1.4144716  1.3932885  1.3761946  1.2442688  1.5490893\n",
      " 1.4051313  1.2786944  0.27339667 0.5865263  1.3260021  1.5126541\n",
      " 1.4052941  1.4491274  1.5564649  1.3549486  1.0682782  1.1652782\n",
      " 1.5569103  1.4676268  1.5833951  1.2184142  1.3588579  1.3388344\n",
      " 1.14969    1.5617605  1.1789131  0.5737923  1.4632349  1.4749463\n",
      " 1.5621777  1.2551016  1.6428874  0.57819134 1.6432027  1.4070361\n",
      " 1.3039111  0.7551579  1.6199661  1.5267508  1.3616334  1.415661\n",
      " 1.6282384  1.011106   0.6251071  1.6143025  1.4479847  1.5490211\n",
      " 1.3105892  1.5797435  1.5942998  1.410649   1.5287368  1.4662606\n",
      " 1.3299639  1.3976458  0.5830146  1.4570947  0.53706765 1.2153254\n",
      " 1.522886   1.3188773  2.1908965  1.4888116  0.55807066 0.611873\n",
      " 0.67077833 1.4476608  1.2623117  1.3242371  0.5135164  1.4993002\n",
      " 1.1977687  1.2780678  1.3103625  1.3161801  1.3945987  1.2980136\n",
      " 1.0683715  1.5771219  1.581612   1.1162021  1.4405226  1.3622414\n",
      " 1.454549   1.3796608  1.3249811  1.5568376  1.4732822  1.3888694\n",
      " 0.61702865 1.3655082  1.3003088  1.3220727  1.3597695  1.3876462\n",
      " 1.0752387  0.5220312  1.6355988  1.3947018  1.5186363  1.4676781\n",
      " 1.4689633  1.1402186  0.99966455 1.7715285  1.1759968  1.2737916\n",
      " 0.7261566  0.75267005 1.4413098  1.4012396  1.5300162  1.5069368\n",
      " 1.047854   1.4845781  1.3087673  1.3439867  1.5299996  1.2483735\n",
      " 1.309963   1.3532408  1.4244304  1.5063866  0.9668772  1.461954\n",
      " 0.7704041  1.5234151  1.0670669  1.1374024  1.3361555  1.9560512\n",
      " 1.3490895  0.88849616 0.5758225  1.6569082  1.3740795  1.0126904\n",
      " 1.4714333  1.7011187  0.991238   1.2104551  0.5801631  1.5995415\n",
      " 1.6293243  0.9738159  1.5169761  1.2462744  1.3037121  1.4447825\n",
      " 1.4010894  1.4967568  1.0780147  1.555029   0.6221227  1.2330135\n",
      " 1.3611127  1.4521499  1.4007158  0.89814454 1.1707417  1.4933584\n",
      " 1.4231166  1.5010178  1.5583475  1.4390335  1.3117667  1.2788272\n",
      " 1.37357    1.1933731  1.1569164  0.722223   1.3020551  1.3132244\n",
      " 1.552482   0.54846764 1.1948149  1.4333636  0.6777366  1.0004303\n",
      " 1.445027   1.4646821  1.5034161  1.1492225  1.2546229  1.5662042\n",
      " 1.2964929  1.4751787  0.7017593  1.2413152  1.4193416  1.2927158\n",
      " 0.80550903 1.4667778  1.2467525  1.3427353  0.8403311  1.3325053\n",
      " 0.42969018 1.1622505  1.4686329  1.1893846  1.4974253  0.72464335\n",
      " 1.7079213  1.3838865  1.4512372  1.4068918  1.4897747  0.7123395\n",
      " 1.2787286  1.445638   1.3936611  1.0079648  1.3963252  1.1838185\n",
      " 1.2491429  1.5414581  1.5213366  1.3838582  0.83661026 1.3323172\n",
      " 1.4275603  1.2284542  1.3354812  0.6387261  1.6118217  0.7011801\n",
      " 0.9093018  1.2309053  0.611062   1.377092   0.75852305 0.9462519\n",
      " 1.0989583  0.66504425 1.2312418  0.6030431  1.3823563  1.276852\n",
      " 1.262574   1.41762    1.4422126  1.2396692  1.0917872  1.7238841\n",
      " 0.89204586 0.57109845 1.6170131  1.4624215  0.7883056  1.0101285\n",
      " 1.0530558  1.2958422  0.5902393  0.78187555 1.2965988  0.480076\n",
      " 1.4830663  1.6146724  1.969911   1.4240241  1.102957   1.2799379\n",
      " 1.5238224  1.4338957  1.1598212  1.4060173  1.0900594  1.333161\n",
      " 1.2887754  0.37293938 1.6407294  1.6026396  0.5460927  1.536169\n",
      " 0.57410675 1.3405827  0.6199948  1.345972   1.2984484  0.5701061\n",
      " 1.4691203  1.2899758  1.2767407  1.3999255  1.4696872  0.5037326\n",
      " 1.3230025  1.3276933  1.2368205  1.288008   1.2232451  2.2724884\n",
      " 1.2338499  1.6210185  1.3244919  0.5515108  1.0796129  1.3977543\n",
      " 1.5172495  1.203347   1.4409395  1.4243752  1.5173851  1.2120593\n",
      " 1.4049813  1.4977878  0.8155624  1.1239072  1.4365382  1.3691128\n",
      " 1.4968349  1.5930862  0.67404926 1.3146573  1.3708862  1.4072584\n",
      " 1.5419707  1.0731784  1.4731637  1.2455223  1.0426635  1.2766802\n",
      " 1.3697921  1.5340167  1.6321143  0.6527867  0.6085334  1.4238011\n",
      " 1.3497983  1.3239645  1.2450467  1.5656347  0.60650444 1.3703079\n",
      " 0.8607694  1.2468667  0.9688715  0.74747735 1.3453712  1.8233061\n",
      " 0.5634313  1.6011249  1.4674948  1.592797   1.3024356  1.2515916\n",
      " 1.3056072  1.1878592  1.3353064  1.2076652  1.4564297  1.2562479\n",
      " 1.5845891  1.4354085  1.1507375  1.5635903  0.5525506  1.301837\n",
      " 1.4088663  1.3515708  1.363643   1.6007327  1.1324235  1.0131665\n",
      " 1.1828934  1.4991208  1.5904757  1.5005326  1.2517782  1.332651\n",
      " 1.5123515  1.2977009  1.4612379  0.81820726 1.1761777  1.2582529\n",
      " 1.5601745  1.3067703  1.6737036  1.1452287  1.3202662  1.6532573\n",
      " 1.5740808  1.5119331  1.2517753  1.3883835  1.372562   1.5020493\n",
      " 1.4423319  1.578533   0.96910137 0.94278336 1.3802588  1.0465918\n",
      " 1.5311502  1.3404728  1.4185162  1.5244833  1.4587357  1.4059277\n",
      " 1.3809502  0.67993253 1.4975228  1.094695   1.3375729  1.2561051\n",
      " 1.3981795  1.3473078  0.75485104 1.4950029  1.0128671  0.6042947\n",
      " 1.3097804  1.4770476 ]\n",
      "[-0.67440253 -1.0727941  -1.1834638  -1.8396465  -0.84419894 -0.70820266\n",
      " -0.92045546 -1.1814325  -0.48703727 -0.47120985 -1.3050656  -1.5850357\n",
      " -1.8114499  -0.7167865  -0.38442895 -0.88053906  1.5305741  -0.5580642\n",
      " -0.60791534  2.1075752  -2.0024428  -0.6376584  -1.5173411  -1.5204703\n",
      " -0.67193484 -1.4064862   1.3866316  -1.0303092  -1.0186388   1.2221814\n",
      " -0.93273765 -0.5421027  -1.2279806  -0.29164582 -1.2525536  -0.76573884\n",
      " -0.49659008  1.1516311  -0.04900115  0.25964692 -0.92944634 -0.6944738\n",
      "  1.7897118  -1.5007012   1.5258535  -1.3696656  -1.3134913  -1.1929404\n",
      "  1.334145    0.59735644 -0.22935696 -0.69662964 -1.205324   -0.911714\n",
      " -0.94260144 -1.5580878  -0.5482986  -0.7095964  -1.0039301   0.55109096\n",
      " -0.97230124  0.21122228  1.3438991   1.31533     1.3167207   1.3687166\n",
      " -1.4024996  -1.7930031  -1.2849163  -0.14642172 -1.363948   -1.3222824\n",
      " -1.1550523  -1.1075646  -0.49106947 -0.50840676 -0.778046   -1.0287707\n",
      " -1.760915    1.7468483   1.763817   -1.1081244  -0.7559734  -0.7055816\n",
      "  1.5785614   0.07182497 -0.9190306   1.2635812  -0.8297239  -0.9556569\n",
      "  0.8279101   1.5732279  -0.8790673   0.7598038  -1.4883419  -1.1732053\n",
      "  1.800793    0.08692364  0.36207014 -0.38813573 -1.0771608  -1.1185156\n",
      " -1.5417588  -0.59833807  1.329074    1.5862626  -0.9113995  -0.97241116\n",
      " -1.3262553  -1.243568   -1.1717037  -0.65638125 -0.13376473  0.7123253\n",
      " -0.984946   -0.92063904 -0.7342154  -0.5775919   1.200348   -0.90851533\n",
      "  0.1659332   1.3297876  -0.51661104  1.6694602  -1.6454356  -1.4191418\n",
      " -1.2685214  -1.1135962  -1.8040123   1.330761   -0.88021564 -1.2241526\n",
      " -1.1199442   1.9626609  -0.06934009 -0.8367839  -1.1546196  -0.9996317\n",
      " -1.139116   -0.60386515  1.3926387   0.15711081 -0.5584363  -0.58307236\n",
      " -0.29902497 -0.19478057 -1.7787441  -0.72225016 -1.208695   -1.1908432\n",
      "  0.02975889  0.19654839  2.052466   -0.9948891   1.7243037  -1.4296092\n",
      " -1.4685123   0.2553158  -1.8226782  -0.952645    1.6106471   1.6112503\n",
      "  1.9113214  -1.0491172  -0.7362612  -0.8325435   1.3453765  -1.0144485\n",
      " -0.0074856   0.8067943  -1.5649499  -1.0180298  -0.9851566  -0.48151508\n",
      " -0.578317   -0.6715463  -2.031724   -0.36280316 -0.8573447  -1.3597357\n",
      " -0.20390867 -0.634114   -0.4852986  -0.11044893 -1.4541836  -0.09150425\n",
      "  1.4035082  -1.1082366  -0.20807509 -1.1573672  -0.7095978  -0.88869464\n",
      " -0.40227294  1.7130393  -0.27686402 -1.0721812  -1.8548049  -0.89451164\n",
      " -0.78558743 -1.4284359   0.98272145 -0.01123461 -0.438133    0.00474392\n",
      "  1.4436977   1.6238177  -0.94686913 -1.0840781  -0.8957552  -1.1568584\n",
      " -0.62038094 -1.3708724  -0.806049   -1.1070799  -1.9825872  -0.8951457\n",
      " -0.9627129  -0.15932286 -1.2619483  -1.1320727   1.0489037  -0.9376576\n",
      "  1.5364295  -0.78634983 -0.62230295 -0.47448727 -0.45918763 -1.0353383\n",
      " -0.6109813   0.9743637   1.3012803  -0.8405506   0.48229313  0.3372862\n",
      " -0.9947716  -1.8052919   0.793202    0.18523118  1.780032   -1.1501093\n",
      " -1.4397796   0.980896   -1.528187   -0.7741546  -0.9598898  -1.4739062\n",
      " -1.1448263  -0.71465343 -0.566527   -0.49480367  1.370714   -1.6223242\n",
      " -1.2653726  -1.6510234  -0.99103814  0.6418816   1.2168689  -0.719452\n",
      "  1.1185284  -0.86376023 -1.432233   -0.91534656 -1.2730359  -1.1702502\n",
      " -0.44891274 -1.146402   -1.7484589   1.3593365   0.07045636 -1.5637591\n",
      " -1.3390037   1.5681055  -0.45198587 -1.1267511   1.6212833   0.55028194\n",
      " -1.2144547  -0.53022754 -0.80393535  0.53786755 -0.08084231 -0.3828669\n",
      "  0.12693302 -1.4105021   1.3865696  -1.3784255  -0.22595072 -0.23101825\n",
      "  2.0672143  -0.57361656 -0.65087223 -0.95769644  1.3935822  -0.7339922\n",
      "  1.3986018  -0.34307924 -1.0022494  -0.96889824 -1.6942228   1.3675091\n",
      " -1.8900251  -1.7277931  -0.66534364 -0.42032164  0.36058995  1.8696687\n",
      " -1.2580141  -1.4331272  -0.65831244  1.0354439  -1.7842467  -0.05960438\n",
      " -0.7773883  -1.4905859  -0.86854947 -0.9635765   1.0955966  -0.80078924\n",
      " -1.1482744   1.2187009  -1.2730031   1.9937719  -1.8581916   1.6742816\n",
      "  1.4933456  -0.08081102  2.0437007  -1.4799842   0.94190603  0.8537902\n",
      " -0.49151048  2.055757   -0.37995654  2.025569   -0.72452605 -0.9692499\n",
      " -0.69334924 -1.192587   -0.4247826   0.264696    0.53405356  0.9218092\n",
      "  1.0219733   1.3450924  -0.3639486   0.25989547  1.6228434   1.3783317\n",
      " -0.9454951  -0.9802744   1.6146284   1.7092385  -1.1131755   1.5226746\n",
      " -1.2869259  -0.6851752  -2.0782542  -1.2275196  -1.3362577  -0.7631719\n",
      " -0.29277146 -0.5560674  -0.8920801   0.09208228  1.1070619  -0.6930608\n",
      "  0.52777076  1.3429657  -1.2414619  -0.48635888  1.5620058  -0.8717545\n",
      "  1.7125454  -1.5116845   1.7753778  -1.2188331  -1.2192839   1.4882991\n",
      " -1.4542007  -0.82189    -0.7684174  -0.5285045  -0.76136476  1.5309322\n",
      " -1.1486673  -1.0068264   0.42761505 -0.46913594 -1.0286101   0.10594016\n",
      " -0.26086038 -0.9106952  -0.44556934  1.4854736  -0.76663214 -1.0534369\n",
      " -1.7888025  -0.63534594 -0.63851416 -1.0508484  -0.9323898   0.13115679\n",
      " -1.2378647   0.23586571  1.7069848   0.79252523 -1.539167   -1.4171851\n",
      " -0.11064856 -1.5688978   1.8151584  -1.1677508  -0.5306489  -0.6245736\n",
      " -0.688702    1.0003955  -1.018917   -0.78321296  0.9564054   0.06695199\n",
      "  0.16116835  0.15159218 -1.2838615   2.1666937   1.5388407  -1.4181466\n",
      " -0.92021966 -1.121836    0.25602698 -1.3732408   1.5858586  -0.6255045\n",
      "  1.336315   -0.7967481   1.3378338   1.0544102  -1.4639289  -1.4426891\n",
      "  1.8763987  -0.6145165   0.34467566 -1.5763457  -0.09194904 -0.9010806\n",
      " -1.0271215  -0.5716845  -1.0490167   0.2500379  -1.3649362  -1.1370877\n",
      " -1.2402506  -1.1627712  -0.6414997  -0.77762747  1.3743725   0.30271184\n",
      " -1.5167489  -1.0453379  -1.2697777  -1.1408019  -0.68794984 -0.08340559\n",
      "  1.7387648   0.9163664  -1.3214877  -0.5724952  -1.2291968  -0.36752892\n",
      " -1.4064815  -1.0101901  -1.0654966   1.8855431  -0.6532935  -0.76523834\n",
      " -0.8566897  -0.44586396 -1.7316872  -1.4305716  -0.84703296 -1.4269372\n",
      " -1.844851   -0.16842267 -0.24339281  0.71141607 -0.00976317 -1.0645558\n",
      " -1.1037846  -0.30030298 -0.60749996  1.1805879  -1.0509926   0.9984836\n",
      " -0.9389227  -0.4177657  -0.06408396 -1.3234266  -0.11703834  0.10687743\n",
      "  0.9552004   1.3499079  -1.030123   -0.71922797 -0.866285   -0.5389534\n",
      " -0.93325275 -1.4068501   1.5681986  -0.266146    1.2252072   1.646609\n",
      " -0.00391971  0.15597585]\n",
      "[-9.63203430e-01 -1.00791430e+00  2.45049524e+00 -6.24782264e-01\n",
      " -2.93378472e+00 -2.01471829e+00  1.20720994e+00  1.79396129e+00\n",
      " -2.19201684e+00  3.09259510e+00  1.77880204e+00  1.54992551e-01\n",
      " -1.38398036e-01  5.91143131e-01  1.25275147e+00 -1.53914118e+00\n",
      "  1.72285676e+00  1.78885400e-01 -1.53502321e+00 -7.03184962e-01\n",
      " -1.95871908e-02 -2.30139828e+00  2.02586770e+00 -3.78067642e-01\n",
      "  3.51138067e+00  2.91733146e+00 -4.63284701e-01  3.84818029e+00\n",
      " -2.92172813e+00 -1.86521888e-01  4.91600215e-01  1.48755297e-01\n",
      "  1.43382728e+00  6.48463666e-01 -7.04167902e-01 -3.54204321e+00\n",
      "  2.04612088e+00  2.59327769e-01  3.71113837e-01 -3.09975520e-02\n",
      "  7.83388853e-01 -1.00526750e+00 -1.07777822e+00 -8.98037136e-01\n",
      " -9.53908637e-02  6.59477770e-01 -1.18043530e+00  2.54694891e+00\n",
      " -3.90222967e-01 -5.43683410e-01  2.39628506e+00 -6.68955803e-01\n",
      " -3.16265893e+00 -9.68618035e-01  1.00218356e+00  1.24763179e+00\n",
      " -1.33391905e+00 -9.25800920e-01  9.89194632e-01  1.16578448e+00\n",
      " -8.12216640e-01 -6.16241634e-01 -3.63064098e+00 -6.34098113e-01\n",
      " -9.26225066e-01 -3.84738296e-01 -3.65096354e+00 -1.35910422e-01\n",
      " -2.86698818e-01 -2.33611512e+00  2.49011207e+00  7.90449500e-01\n",
      "  1.23232567e+00  1.08087814e+00 -5.35669708e+00  2.76797223e+00\n",
      " -3.16181159e+00 -5.06944180e-01 -1.17154670e+00 -2.10125422e+00\n",
      "  1.40686941e+00 -2.87292361e+00 -3.21514428e-01  5.65410890e-02\n",
      "  6.54998660e-01 -4.90331739e-01  2.03775484e-02  1.73011565e+00\n",
      "  1.01013660e+00 -5.34815311e-01  5.31557560e-01  1.60270452e-01\n",
      "  1.96079302e+00 -2.86167216e+00 -1.15094471e+00  1.64701939e-01\n",
      "  4.69083428e-01  2.69306564e+00  8.74757469e-01  1.65928698e+00\n",
      " -6.86910808e-01 -9.64703381e-01  1.55710328e+00 -2.57995105e+00\n",
      "  1.05703557e+00  1.69205785e+00  3.67997974e-01  2.48381925e+00\n",
      "  8.56028199e-01  6.15184069e-01  3.29882646e+00 -1.82790065e+00\n",
      "  3.78246874e-01  1.15078676e+00 -1.25328505e+00 -9.64225903e-02\n",
      "  2.98791718e+00 -5.88194013e-01 -1.70608199e+00  1.99402606e+00\n",
      "  3.03006387e+00  1.49362490e-01 -9.93974745e-01 -1.58775699e+00\n",
      " -1.70012975e+00  4.61339355e-01 -5.20906687e-01  9.31711137e-01\n",
      " -1.94044018e+00  9.11120534e-01 -3.11216974e+00  1.22132182e+00\n",
      " -2.02713346e+00 -9.23620284e-01  1.61485994e+00 -1.73833892e-01\n",
      "  2.44845796e+00 -8.62784870e-03 -1.12321246e+00 -7.77479529e-01\n",
      "  1.53668666e+00  4.39569473e-01  5.05270183e-01  1.16564655e+00\n",
      " -4.72799873e+00 -3.19419563e-01  1.18167078e+00  6.03658378e-01\n",
      " -2.02857780e+00  1.01528347e+00 -6.80543423e-01  1.15161371e+00\n",
      "  2.30091497e-01 -2.17440987e+00 -1.82614541e+00  2.90914726e+00\n",
      " -9.42919552e-01 -9.27310348e-01 -1.09266210e+00  1.34574449e+00\n",
      " -1.56402135e+00 -2.76085019e+00  1.67952561e+00 -3.31718493e+00\n",
      "  2.91429877e+00 -1.93312895e+00 -6.94835007e-01  1.88478246e-01\n",
      " -2.48646665e+00  1.07256567e+00 -2.78808546e+00  2.01875567e+00\n",
      "  1.10275984e+00 -2.94288325e+00  1.21693611e+00 -1.73894107e+00\n",
      " -3.00314760e+00  1.58102143e+00 -1.77077198e+00 -4.57732350e-01\n",
      "  5.63539565e-01 -4.64932024e-01 -9.21735168e-01 -9.66158748e-01\n",
      " -1.47109628e+00  1.63231385e+00 -1.59539032e+00  9.60731208e-01\n",
      " -3.36438388e-01 -3.52339223e-02  1.78332675e+00  3.67513156e+00\n",
      "  5.68301797e-01 -1.46532416e+00  3.17953515e+00 -2.83033371e-01\n",
      "  1.20168495e+00  1.82023942e+00 -2.49370193e+00  4.56882548e-03\n",
      " -1.10775578e+00 -8.57467875e-02  1.00899148e+00 -1.98656285e+00\n",
      " -4.31609154e-01 -1.67675722e+00  1.68682766e+00  1.11012913e-01\n",
      "  4.77999374e-02 -3.01071548e+00 -7.54802287e-01 -3.07309055e+00\n",
      " -7.64203012e-01  1.16023040e+00 -1.86677182e+00 -1.06550527e+00\n",
      " -1.05347288e+00 -2.90884447e+00 -7.17037082e-01  1.19818532e+00\n",
      " -2.96163410e-01  2.80582333e+00 -2.98455834e+00 -1.42679542e-01\n",
      " -1.18014503e+00  9.77074623e-01  2.40773544e-01 -2.00145054e+00\n",
      " -1.62541831e+00 -6.99552536e-01  3.48934472e-01 -1.42290497e+00\n",
      " -2.06728175e-01 -2.87521571e-01 -2.46411085e+00 -1.32095361e+00\n",
      " -4.29667145e-01  4.49321687e-01 -1.75045714e-01  1.70891929e+00\n",
      " -2.63670230e+00  1.17760487e-01 -1.18321991e+00 -5.26409447e-01\n",
      "  2.02149653e+00 -1.31658733e+00 -6.26793206e-01 -1.31514060e+00\n",
      " -1.92703784e+00  6.65801048e-01 -9.49643672e-01 -8.97726417e-02\n",
      " -6.58237875e-01 -5.26383996e-01 -2.09687328e+00  6.31060719e-01\n",
      " -2.33181596e+00  1.70521270e-02 -1.97984719e+00 -1.61316502e+00\n",
      " -5.96118331e-01  7.79706895e-01 -1.72032249e+00 -1.20919573e+00\n",
      "  9.14706439e-02 -3.80229616e+00  1.01449442e+00 -2.18071198e+00\n",
      "  1.33895898e+00  1.10875018e-01  6.27652824e-01 -2.53247666e+00\n",
      "  1.10213205e-01 -4.06931728e-01  5.89415170e-02 -2.08430791e+00\n",
      " -6.36829793e-01 -5.53355455e-01  1.52891827e+00  4.44992840e-01\n",
      "  5.96425474e-01 -1.60055959e+00 -1.27276886e+00 -1.56347358e+00\n",
      "  9.94006455e-01  5.45186341e-01  2.28842258e+00  1.10055888e+00\n",
      " -1.21770799e+00  1.58846831e+00 -3.03212106e-01  7.99996734e-01\n",
      " -4.52241808e-01 -1.28248775e+00 -1.17803335e+00  4.28189576e-01\n",
      "  1.09969676e+00  2.49302536e-01  1.73024023e+00 -1.14630237e-01\n",
      " -1.54688299e+00 -1.38048494e+00 -9.77930427e-01  1.42739356e+00\n",
      " -9.21156049e-01  2.62998372e-01 -2.83826470e+00 -2.86679476e-01\n",
      " -2.76607424e-01  1.51907527e+00 -1.24852633e+00 -8.61297667e-01\n",
      " -6.25245810e-01  8.96807969e-01  1.66234255e+00 -8.22341681e-01\n",
      " -4.98737060e-02  1.06098449e+00 -4.88106823e+00 -8.25428367e-01\n",
      " -3.49978745e-01 -3.36685944e+00 -1.69037235e+00  1.25143504e+00\n",
      " -1.91567111e+00  3.39998811e-01  8.65035474e-01 -2.37771130e+00\n",
      " -2.89905596e+00 -1.33891523e+00 -1.45872343e+00  5.21614373e-01\n",
      " -9.64360833e-01  1.11378539e+00  7.55346060e-01  1.11073756e+00\n",
      "  1.98872340e+00  1.71223533e+00  2.08705711e+00 -2.37474632e+00\n",
      " -8.45744669e-01  1.99626178e-01 -1.73197126e+00 -1.06735551e+00\n",
      " -1.57567477e+00 -2.44537238e-02 -1.18522435e-01 -9.59143266e-02\n",
      " -1.55723131e+00 -2.71930432e+00 -2.18980461e-01 -1.19574094e+00\n",
      " -1.96211708e+00 -1.53374755e+00  2.27849793e+00 -2.22093999e-01\n",
      "  2.51613464e-03 -2.24987841e+00 -1.23844218e+00  7.14979053e-01\n",
      " -3.11033785e-01  1.89631927e+00 -1.79040277e+00  2.16995195e-01\n",
      "  7.58312583e-01  1.25720870e+00 -8.78278494e-01  6.77652806e-02\n",
      " -1.83494878e+00  4.04140204e-01  2.08009362e+00 -1.09776592e+00\n",
      " -2.68308258e+00  1.75426626e+00 -1.03961051e+00  4.69103068e-01\n",
      " -9.44784164e-01  1.73862588e+00 -3.29097956e-01 -1.51450396e-01\n",
      " -2.47264099e+00  2.45633125e-01  3.19897950e-01  1.70953858e+00\n",
      " -1.21664572e+00  1.49305630e+00 -4.20588911e-01  1.68011451e+00\n",
      "  8.88512790e-01 -1.38659906e+00 -6.36100471e-01  4.42219645e-01\n",
      " -2.30787778e+00 -6.05001152e-01 -8.53071332e-01  2.08331183e-01\n",
      "  5.21125615e-01  2.05599356e+00 -9.45527852e-01 -4.61477488e-01\n",
      " -1.28926420e+00 -1.36757016e+00  6.55399561e-01 -2.06215620e+00\n",
      "  1.31785882e+00 -1.66240656e+00  2.46189666e+00  1.54051781e+00\n",
      " -2.00598025e+00 -8.55701208e-01 -2.17405987e+00 -1.24288476e+00\n",
      "  8.67240191e-01 -8.51606309e-01 -1.62960398e+00  3.56850386e-01\n",
      "  2.40478009e-01  1.46449655e-01  2.11803532e+00  1.45821884e-01\n",
      " -5.24923652e-02 -1.21046686e+00  3.27427715e-01  3.59057426e-01\n",
      " -1.03055779e-02  2.93847471e-01  3.89725268e-01 -1.21756673e+00\n",
      "  1.29423845e+00  4.16875213e-01  1.73145354e+00 -3.96493375e-01\n",
      "  4.17616844e+00  4.93993253e-01  1.48908591e+00  7.82262802e-01\n",
      " -1.48052096e+00  6.43525720e-01 -1.64908051e+00 -4.74225312e-01\n",
      " -2.19713235e+00 -3.42112601e-01 -1.13222456e+00  1.13874602e+00\n",
      " -1.44101441e+00 -3.28424394e-01  1.10858929e+00  9.18692827e-01\n",
      " -1.36844814e+00  2.42079878e+00 -3.21596771e-01  1.34047377e+00\n",
      "  1.48047400e+00 -1.25802845e-01 -3.09897399e+00 -1.27499223e+00\n",
      " -1.70864069e+00  1.02844250e+00  6.22190893e-01  1.11571050e+00\n",
      " -4.43287283e-01  7.39393592e-01 -1.98788822e+00 -1.56057334e+00\n",
      "  4.01333141e+00  9.34187829e-01  2.68849778e+00  7.38678873e-01\n",
      " -7.26633966e-01  4.62142408e-01 -1.83354497e+00  1.26727748e+00\n",
      "  3.08644795e+00  9.18307781e-01  1.57835507e+00 -1.96509564e+00\n",
      " -1.68474841e+00  5.29833853e-01  2.37935042e+00  9.67925310e-01\n",
      " -1.86240339e+00 -6.53316081e-01 -1.69650781e+00 -6.94140196e-01\n",
      " -4.17289829e+00 -1.19548690e+00  1.23235595e+00  2.42930099e-01\n",
      " -3.04378605e+00  8.63040984e-02  6.91582382e-01 -3.97786164e+00\n",
      " -1.92505133e+00  1.60077035e+00 -2.57731169e-01  1.56854808e+00\n",
      " -5.66345870e-01 -2.57563084e-01 -1.26197946e+00 -1.19706881e+00\n",
      "  1.59759715e-01 -1.50585186e+00  1.09347619e-01 -3.08842182e+00\n",
      " -1.11987090e+00  1.04275417e+00 -9.33679819e-01  1.37866616e+00\n",
      "  1.46604374e-01 -2.24893808e+00 -1.54372191e+00  2.46810031e+00]\n",
      "[0.7421367  1.1255333  0.98834604 0.96203595 1.0866479  1.1881754\n",
      " 0.9125677  0.780915   0.5269159  0.91297984 1.0067546  0.79465234\n",
      " 0.63916457 0.69147646 0.7222008  0.76413405 0.5577408  0.82648116\n",
      " 0.94948703 0.736134   0.7772557  1.1386172  0.8177893  0.7267039\n",
      " 0.94212514 1.1123099  0.8318209  0.6631771  0.7638617  0.43714067\n",
      " 0.88258445 0.6964867  0.83409935 0.2969088  0.9883035  0.8024597\n",
      " 0.9197969  0.5696684  0.66812605 0.7473947  0.98717934 0.884351\n",
      " 0.585072   0.8511386  0.60914737 0.7561752  1.0869797  0.7550654\n",
      " 0.45426393 0.49211293 1.0870364  0.952744   1.1507498  0.72473514\n",
      " 0.86422753 0.66649973 1.1096457  0.78609246 0.8118466  0.36053044\n",
      " 0.77157825 0.5124725  0.57568264 0.57506293 0.6097743  0.61642253\n",
      " 0.6510648  0.70143235 0.9510313  0.8705907  1.2011273  1.047194\n",
      " 0.9990209  1.2709297  0.859378   0.9570671  1.1805516  0.967436\n",
      " 0.6799596  0.6075125  0.72344345 0.86766726 1.0314522  0.99181664\n",
      " 0.659923   0.42196628 1.0739827  0.72287375 0.4003051  0.7161209\n",
      " 0.42654893 0.6460603  0.8766745  0.46552446 0.8483135  0.91367084\n",
      " 0.56608474 0.5024765  0.59319353 0.37930125 0.7790219  0.9194529\n",
      " 0.5548114  0.74454075 0.28950936 0.6886033  0.63992304 1.1680728\n",
      " 0.65999514 0.5770174  0.8174814  0.8256994  0.92920643 0.6931731\n",
      " 0.67323434 1.0838565  0.96185726 0.841799   0.77517605 0.88662285\n",
      " 0.5581676  0.9778534  0.7616183  0.51817715 0.6483938  0.95331806\n",
      " 1.1175462  0.7730744  0.7271623  0.62805724 1.501131   0.70792615\n",
      " 0.8468978  0.8686612  0.835713   0.6676682  0.7408976  0.9592205\n",
      " 0.95095235 0.8791546  0.5178058  0.6831356  0.82725024 1.029181\n",
      " 0.75928575 0.67943215 0.67091644 1.1608697  0.9876549  0.8096939\n",
      " 0.60261214 0.6746874  0.74361587 1.0432079  0.6064913  0.7377347\n",
      " 0.86056286 0.87306505 0.6627474  1.0210761  0.5253419  0.6517113\n",
      " 0.6983711  0.9179285  0.81387216 0.9900704  0.5540203  0.6982557\n",
      " 0.8118454  0.5669258  0.77554274 0.65493983 0.87054324 1.1633872\n",
      " 0.35953563 1.009268   0.831558   0.33844835 1.2344667  0.8042775\n",
      " 0.7566162  1.1300431  0.60751355 0.69348115 1.0916492  0.6787997\n",
      " 0.5577866  0.87305903 0.5117814  0.7949092  0.76090825 1.0185359\n",
      " 0.5318482  0.5006385  0.7169009  0.88479364 0.75118357 0.8280424\n",
      " 0.95476204 0.6345675  0.6359335  0.9821364  0.7704616  0.48806357\n",
      " 0.5362293  0.92606604 0.9550787  0.7284843  0.7147538  0.915536\n",
      " 0.55579317 0.91899157 1.1112417  0.64812785 0.66648054 0.7938254\n",
      " 1.0096424  0.8421065  1.3106709  1.0034145  0.62407416 0.9476812\n",
      " 0.51813245 0.86045337 0.7595124  0.83994925 1.4972781  1.4637196\n",
      " 0.985805   1.0712756  0.5007516  0.67647696 0.5641811  0.5377079\n",
      " 0.7883878  0.8020983  0.40752754 0.57281446 0.6097175  1.0057437\n",
      " 1.1432426  0.30559272 0.8301292  1.0060073  0.7003521  0.7004823\n",
      " 0.93066424 1.3363343  0.7776102  0.79409003 0.2219313  0.7197655\n",
      " 0.8224447  0.63283265 0.8767927  0.1921768  0.89569885 0.93137383\n",
      " 0.48947263 1.0695766  0.9013691  0.9292499  0.9180692  0.69468707\n",
      " 0.9865361  0.6320977  0.6407738  0.6956065  0.65830165 0.6136261\n",
      " 0.6302532  0.58323973 0.7310302  0.9270376  0.63168776 0.79145753\n",
      " 0.99352986 1.0359477  1.2930615  0.5583661  0.9791049  0.8449752\n",
      " 1.4890761  0.73549205 0.4403545  0.7304537  0.6345696  0.6890666\n",
      " 0.563946   0.8109904  0.78960264 0.8570002  0.59210896 0.59712803\n",
      " 0.5687773  0.93549466 0.794265   0.7016385  0.70702964 0.37981603\n",
      " 0.935003   0.82148015 1.1056582  1.0718265  0.44365045 0.5720863\n",
      " 0.7072554  0.59254056 0.869869   0.5072395  0.5951906  0.5956664\n",
      " 0.9144993  0.84541523 0.9204101  0.90768534 0.45864493 0.8369355\n",
      " 0.82965153 0.7128235  0.84284675 0.47207484 0.6867116  0.46007127\n",
      " 0.7105971  0.77254224 0.50268173 0.8536403  0.76634634 0.25776187\n",
      " 0.88475025 0.4843942  0.89220476 0.5044504  0.85686153 0.7044058\n",
      " 0.63670564 0.6895959  0.49262384 1.0376167  0.75594646 0.8432647\n",
      " 0.59244126 0.5869515  0.9461287  0.64300084 0.68082345 0.360899\n",
      " 0.5248476  0.8691228  0.71830237 0.6331263  0.5954339  0.44891512\n",
      " 0.8494346  1.0095443  0.8009782  0.75906867 0.5918272  0.7067603\n",
      " 0.5723916  0.84585845 0.8792482  0.481058   0.7708105  1.018906\n",
      " 0.71905386 0.3052915  0.900234   1.1344203  0.6566737  0.95111424\n",
      " 0.71574086 0.8089575  0.56821436 0.90830994 0.8643483  0.50401753\n",
      " 0.9290299  0.6074609  1.2447742  1.3867803  1.1890541  0.55006176\n",
      " 0.8379825  0.93863344 0.8765594  0.64634514 1.0234479  0.8548148\n",
      " 0.772079   0.468733   0.6898203  0.61787325 0.96769464 0.8325795\n",
      " 0.9079022  0.8992789  1.2457365  0.85379523 0.9364293  0.66675913\n",
      " 0.67512447 0.6545643  0.5204647  0.4022195  0.7364509  0.7233785\n",
      " 0.8031588  1.2050502  0.5836383  0.82404107 0.75039905 0.80379146\n",
      " 1.011718   0.4508554  0.6389686  0.7789884  0.63701665 0.39002815\n",
      " 0.6368863  0.7769013  0.7149525  0.5555195  0.5333825  0.78852236\n",
      " 0.57060534 0.9125024  1.0961905  0.69649225 0.5360173  1.0468711\n",
      " 0.6674596  1.2238305  0.800115   0.29422444 0.8656873  0.7914056\n",
      " 0.5415017  1.1480314  0.6883311  0.78821886 0.88174915 0.75089145\n",
      " 0.9880617  1.0250024  0.78858626 0.52023673 0.58213824 0.7667227\n",
      " 0.7907844  1.0513821  0.89392287 1.0120527  0.4955884  0.8680795\n",
      " 1.1126541  0.7122686  0.7757338  1.5078794  0.9314861  1.3232769\n",
      " 0.54050535 0.7472189  0.95555544 0.7573855  0.71152157 0.76466274\n",
      " 0.72227126 0.8039174  0.8272387  0.61658376 0.77866155 0.8301407\n",
      " 0.92530656 0.76211727 0.62572396 0.6757613  1.1014311  0.7636412\n",
      " 0.7779386  0.727094   0.97361803 0.8332705  0.6016146  1.0274957\n",
      " 0.82613814 0.9725624  1.7311999  0.35154268 0.8222139  0.6652459\n",
      " 0.8903699  1.0256785  0.52318233 0.66374475 0.54282546 0.6423036\n",
      " 0.7177396  0.6185398  1.1829137  0.71571726 1.0774531  0.43299532\n",
      " 0.7304906  0.6291774  0.73620784 0.8762817  0.30866158 0.6230077\n",
      " 0.7393923  0.71734804]\n"
     ]
    }
   ],
   "source": [
    "import math as m\n",
    "layer72 = model.layers[72]\n",
    "W = np.array(layer72.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "batchNorm = model.layers[72].get_weights()\n",
    "\n",
    "fMean = open(\"data/TwentyThreeLayer/TwentyThree_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/TwentyThreeLayer/TwentyThree_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/TwentyThreeLayer/TwentyThree_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/TwentyThreeLayer/TwentyThree_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_TwentyThreeLayer():\n",
    "    fExp = open('data/TwentyThreeLayer/TwentyThree_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/TwentyThreeLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            if(counter < 30):\n",
    "                print(str(cAct[i].strip()) + \"--->\" + str(cExp[i].strip()))\n",
    "            \n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500109--->0.49985716\n",
      "1.500109--->1.4999025\n",
      "1.500152--->1.4993539\n",
      "1.500159--->1.4999914\n",
      "1.499943--->1.5001465\n",
      "1.500200--->1.4999202\n",
      "2.500035--->2.499538\n",
      "0.499844--->0.50001276\n",
      "Number of mismatch - 8\n"
     ]
    }
   ],
   "source": [
    "checkFile_TwentyThreeLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
