{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikhil/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import Model\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import Conv3D\n",
    "\n",
    "fileName = \"Trump.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "# Global MobileNets model\n",
    "mobile = keras.applications.mobilenet.MobileNet(weights=\"imagenet\")\n",
    "model = Model(mobile.input, mobile.layers[67].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7ff7702a0ba8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7ff6e129a550>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6e110b080>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6e08d20b8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6e08d2eb8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6e08eac50>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6e0060f28>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d87f7630>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6d8797470>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d8709400>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d87709e8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7ff6d86f3c50>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6d8691f28>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d826b6a0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d826b8d0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6d82079b0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d8186f28>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d81b4da0>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6d8167a58>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d8127128>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d808af98>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6d8049c50>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d077ae10>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d07a4ac8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7ff6d0761cf8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6d071dd68>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d069df60>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d069deb8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6d0655208>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d0614320>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d05ff908>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6d0580b70>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d05d1898>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d05317f0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6d04df780>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d044c5c0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d04b7ba8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7ff6d03bce10>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6d03f15f8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6e1318208>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6e1318e48>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6d02cf978>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d028cb70>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d01fc0f0>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6d022db00>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d01e91d0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d0150198>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6d00fadd8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d00c8e10>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d00acd30>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6d00452e8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6c87e85f8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6c8748588>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6c8766828>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6c86dc4a8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6c86c6908>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6c8647c18>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6c869f9e8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6c85799e8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6c85a7908>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6c8515908>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6c8496d30>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6c8439860>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6c8474908>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6c83e3d68>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6c8398b38>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6c8352d30>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6c82bdfd0>\n",
      "\n",
      "\n",
      " Weight Size\n",
      "(1, 1, 1, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer65 = model.layers[65]\n",
    "W = np.array(layer65.get_weights())\n",
    "\n",
    "print(\"\\n\\n Weight Size\")\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file_weights_layer_TwentyOne(fileName, W):\n",
    "    fTemp = open(fileName, \"w\")\n",
    "    for i in range(1):\n",
    "        for j in range(1):\n",
    "            for k in range(512):\n",
    "                for l in range(512):\n",
    "                    fTemp.write(str(W[i][j][l][k]) + \"\\n\")\n",
    "    fTemp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7ff7702a0ba8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7ff6e129a550>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6e110b080>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6e08d20b8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6e08d2eb8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6e08eac50>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6e0060f28>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d87f7630>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6d8797470>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d8709400>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d87709e8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7ff6d86f3c50>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6d8691f28>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d826b6a0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d826b8d0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6d82079b0>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d8186f28>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d81b4da0>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6d8167a58>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d8127128>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d808af98>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6d8049c50>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d077ae10>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d07a4ac8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7ff6d0761cf8>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6d071dd68>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d069df60>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d069deb8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6d0655208>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d0614320>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d05ff908>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6d0580b70>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d05d1898>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d05317f0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6d04df780>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d044c5c0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d04b7ba8>\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x7ff6d03bce10>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6d03f15f8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6e1318208>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6e1318e48>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6d02cf978>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d028cb70>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d01fc0f0>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6d022db00>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d01e91d0>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d0150198>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6d00fadd8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6d00c8e10>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6d00acd30>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6d00452e8>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6c87e85f8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6c8748588>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6c8766828>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6c86dc4a8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6c86c6908>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6c8647c18>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6c869f9e8>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6c85799e8>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6c85a7908>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6c8515908>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6c8496d30>\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x7ff6c8439860>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6c8474908>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6c83e3d68>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7ff6c8398b38>\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7ff6c8352d30>\n",
      "<keras.layers.advanced_activations.ReLU object at 0x7ff6c82bdfd0>\n",
      "(1, 1, 1, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n",
    "layer65 = model.layers[65]\n",
    "W = np.array(layer65.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "W = layer65.get_weights()[0]\n",
    "write_to_file_weights_layer_TwentyOne(\"data/TwentyOneLayer/weightsNorm.txt\", W)\n",
    "\n",
    "W[:,:,:,:] = 1\n",
    "write_to_file_weights_layer_TwentyOne(\"data/TwentyOneLayer/weightsSet1.txt\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 512)\n",
      "[0.44393718 0.78796834 0.5250336  1.1094227  1.5309553  0.62105995\n",
      " 1.0955008  0.83503187 1.137284   1.4346354  1.3295168  1.4382361\n",
      " 1.0158572  1.5317822  1.2893071  0.8144526  1.2738312  1.0216155\n",
      " 1.5581996  1.3446501  1.3087415  0.9103474  1.1063225  1.195752\n",
      " 1.2046727  1.112719   1.6837567  1.4431183  1.1480286  1.3332343\n",
      " 1.0322361  1.6569871  0.9232818  0.6213289  1.5123761  1.4036902\n",
      " 0.75415725 1.1208721  0.7343528  1.3321085  1.4080738  1.2815874\n",
      " 1.4119872  1.0473968  1.0956693  0.9299593  1.0376112  1.2574801\n",
      " 1.2325242  1.2613951  1.2873296  1.09961    1.1661265  1.2566265\n",
      " 1.2393887  1.2977393  0.838341   1.4669948  1.1493318  0.94561327\n",
      " 1.4221705  1.447366   1.1751813  0.7762716  1.1934288  0.8263137\n",
      " 1.0870245  1.1947337  1.3687906  1.4258817  1.0656008  1.1494904\n",
      " 1.0544597  1.2525377  1.2499299  1.5204433  1.7318183  1.7828399\n",
      " 0.6827705  1.299936   0.7502316  0.41196907 1.4048469  1.7008547\n",
      " 1.4851265  0.8375886  0.8457411  1.1115751  1.0860707  0.85788596\n",
      " 0.8806399  0.4955555  1.5564824  1.1480359  1.0358036  1.168145\n",
      " 1.4716555  1.2375362  1.6353216  1.2831066  0.64166826 1.1521267\n",
      " 1.2365079  1.6454346  0.5308201  1.2477897  1.2938203  0.45967007\n",
      " 1.3035477  0.9791628  0.970793   0.9381586  0.53045    1.4106857\n",
      " 1.4564582  1.4035757  1.4893408  1.3240672  0.7870406  1.0461389\n",
      " 1.3141547  1.1845901  1.0894681  1.5828896  1.3369979  0.8678667\n",
      " 1.3163506  1.2857497  0.464527   1.0024223  1.0377362  1.0973707\n",
      " 0.8471224  0.7185429  1.0260446  0.7833596  1.584686   1.2686433\n",
      " 1.1578711  1.1045933  0.8131014  1.1397235  0.96899927 1.4659381\n",
      " 1.4684334  1.4619023  1.0728703  1.4047488  1.2846475  1.2020401\n",
      " 1.272729   1.2524762  1.402258   1.0980086  1.4658569  1.2898858\n",
      " 0.9744541  1.0590552  1.4521872  1.4137313  1.5462805  1.6973644\n",
      " 0.7649971  1.1943959  1.024729   1.4366919  1.6463048  0.8818177\n",
      " 3.19035    0.7624908  0.8074425  1.1418022  1.2722659  1.2193558\n",
      " 1.9906808  0.8372958  1.059856   1.3135346  1.2915436  1.196499\n",
      " 1.4398458  1.5698742  1.0293925  1.1603748  1.8132348  0.91571015\n",
      " 1.129071   0.8535193  0.74644226 1.5392205  1.3790946  0.821037\n",
      " 1.6847824  1.5027083  1.3544875  1.2502897  1.4659854  1.6309135\n",
      " 1.1987442  1.3407927  1.2724968  1.432988   1.2001941  0.9891392\n",
      " 0.6482072  1.3950294  1.1036763  1.1355251  1.3021789  1.5467814\n",
      " 1.3690461  1.0282681  1.3252524  1.4813288  1.2042817  1.4228112\n",
      " 0.9451172  1.1222609  1.5839243  2.186442   1.2688135  1.0947205\n",
      " 0.8798697  1.1033707  1.2454749  1.2880315  0.983637   0.7241756\n",
      " 1.1481558  1.3837757  0.7217988  1.07684    1.3980145  1.3610427\n",
      " 1.5866965  0.9732284  1.3825277  0.74880177 1.3655205  0.72873175\n",
      " 1.3076565  0.66230553 0.9792122  1.2767563  1.332461   1.2098136\n",
      " 1.6372153  1.2296847  0.7674523  1.326963   1.4108441  1.0195853\n",
      " 0.977814   1.1966054  0.8909529  1.2979164  1.3347263  1.0416722\n",
      " 1.1914957  1.0733663  1.3542874  1.1360211  1.2440771  0.91487575\n",
      " 1.4809606  0.9423242  1.0167214  1.0582566  2.7739134  0.90112823\n",
      " 0.82133585 1.3275914  1.1295567  1.0333757  1.6087697  1.4775739\n",
      " 1.1505055  1.3304855  1.0366739  0.72823155 1.2793376  1.0767881\n",
      " 1.4047289  1.0973109  1.389728   1.3003091  1.2143484  1.1218214\n",
      " 1.0402273  1.3058292  1.2259574  1.4178756  1.3449502  1.1250098\n",
      " 1.4362823  1.3599185  1.6103891  1.3215296  1.2636294  1.5058162\n",
      " 0.9010563  0.85750335 1.1922927  1.226977   0.7609853  1.2892452\n",
      " 0.9849312  0.975194   1.1921484  1.3204812  1.3217411  1.6764889\n",
      " 1.419324   0.4186932  1.3482298  1.1114775  1.362233   1.3387126\n",
      " 1.5344437  1.277507   1.5045149  1.7867938  1.3544365  1.3894376\n",
      " 1.2897654  0.58593065 1.3098215  0.8758032  1.3771497  1.3748008\n",
      " 1.1529609  0.7294385  1.3437916  0.9723684  0.55484986 1.3113223\n",
      " 1.0516316  1.4485351  1.4640716  1.1419619  1.1986495  1.1144553\n",
      " 1.5029858  0.9982324  1.1701499  0.5364945  0.95902467 1.46245\n",
      " 1.2625033  1.2661382  1.2333704  1.26182    1.0352023  1.2958791\n",
      " 1.1980983  1.6665593  1.4220417  1.0404276  1.1553397  1.1488614\n",
      " 1.0487844  1.0106199  0.7213427  1.2776316  1.3877468  1.3197621\n",
      " 1.1669313  1.5177547  1.1484743  1.0034546  1.243989   1.2189221\n",
      " 0.81028247 1.5561786  1.2104425  1.5988344  1.1882968  1.1057787\n",
      " 1.2464179  1.3153334  1.165648   1.4882307  1.0253661  1.3345616\n",
      " 0.8680516  1.0658917  1.2660502  1.0488607  0.98907995 0.81056696\n",
      " 1.5347378  1.3757721  1.0694062  1.3975128  0.9701413  1.3294021\n",
      " 1.0426931  1.3178898  1.3517692  1.159966   1.2358441  1.0387863\n",
      " 0.58913296 1.169905   0.4918084  1.3116306  1.4491987  1.6386179\n",
      " 1.1633918  1.2264235  1.3058668  1.4262985  1.1779014  1.3353784\n",
      " 1.3698362  0.9635982  1.257281   1.3481883  1.2661656  1.187355\n",
      " 1.1655461  1.4611671  1.2988781  1.1349263  1.2023405  1.4487435\n",
      " 1.6343751  1.1667578  1.0955635  1.299533   1.0370713  1.6490225\n",
      " 1.1092607  1.4554743  1.2328283  1.4473217  1.2176064  1.0137863\n",
      " 1.4625386  1.2166401  1.1568574  1.0007546  2.4340804  1.5544652\n",
      " 1.4612024  1.0640315  1.2601844  1.1657181  1.2919252  0.8972789\n",
      " 1.2396588  1.5322348  0.88880557 1.3425679  1.1666982  1.0000833\n",
      " 1.4844508  1.0787989  1.2127092  1.2564682  1.4794959  1.1960819\n",
      " 2.0760438  1.1971287  1.4104518  1.2111263  1.5430793  1.2294581\n",
      " 1.4624008  1.2891829  1.0853487  1.1344477  1.2300832  1.232768\n",
      " 1.1931162  2.5409565  1.4840591  1.2894112  1.3244481  1.1185875\n",
      " 1.1687801  1.6820998  1.2092509  1.2338247  1.4745557  1.3731934\n",
      " 1.2884552  1.1666856  1.1879753  1.2297193  0.83715624 1.4436021\n",
      " 1.2263142  1.1515261  1.3117647  1.1157472  1.1981019  1.236996\n",
      " 1.4219013  1.1957163  1.1381749  1.1870978  0.9241621  0.7920888\n",
      " 1.2411063  1.2627186  1.1959924  0.6289218  1.2722688  1.2279204\n",
      " 0.6528485  1.384706  ]\n",
      "[ 2.0148287   0.9220042   1.8676815  -0.53670037 -0.43874496  1.567101\n",
      "  0.9725855  -0.2275275  -0.36849687 -0.52258754 -0.15678294 -0.11044765\n",
      " -0.8881558  -0.73087835 -0.8952773   1.0785457  -0.3422484   1.1688828\n",
      " -0.4717499  -0.27550906  0.79939866 -0.6388771  -0.6642003   0.32089072\n",
      " -0.8094728  -0.3507453  -0.5158286  -0.8723962   0.8147464  -0.53073555\n",
      " -0.44603083 -0.16845062  0.63323784  1.223146   -0.7347756   0.02090184\n",
      "  0.8083802  -0.55900455  1.0021406  -0.24460346 -0.32307205 -0.47734827\n",
      " -0.7314806  -0.8347515  -0.6696074   0.3474449   1.2327476  -0.21374112\n",
      "  0.33813    -0.71603733 -0.37180275 -0.28221425 -0.4869784  -0.24438591\n",
      " -0.8005486   0.56212837  1.4802094  -0.59666526  1.7279253   0.02322294\n",
      " -0.6509968   0.46459422 -0.57616514  1.6403023  -0.18783666  0.7392069\n",
      " -0.4283514   0.2565146  -0.30166632  0.0642058  -0.69335496  1.4775457\n",
      "  1.0870817  -0.86755335 -0.88553786 -0.47648704  0.0560079  -1.2263656\n",
      "  1.8887708  -0.507382    1.0579662   1.6589508  -0.8730431   1.2904023\n",
      " -0.63105315  1.5155665   0.37674573  0.743206   -0.20489864 -0.34983593\n",
      "  0.40113282  1.4013733   0.11931365  0.20913407 -0.98045236 -0.25488684\n",
      " -0.378524   -0.15596907 -0.42405364 -0.9050888   1.7519505  -0.5088968\n",
      " -0.26445827  0.06051509  1.4736881   1.037296   -0.33803877  1.5168035\n",
      " -0.56314915  0.7504021  -0.33578613 -0.77423424  1.467076   -0.111628\n",
      "  0.37276495 -0.06845224 -0.55149007  0.91290265  1.6457572  -0.1073612\n",
      " -0.6752461  -0.03300888 -0.02260032 -0.3388261  -0.5076143   1.1804161\n",
      "  0.8028284  -0.45475334  1.6381932   0.89625025 -1.1111368  -1.1463491\n",
      "  1.4277046   1.2820737  -0.33897653 -1.1218224   0.6766982  -1.1521282\n",
      "  0.861813   -0.9060296   1.4017462  -0.95990807  1.2247269  -0.38622487\n",
      " -0.4037362  -1.0349383  -0.37185854 -0.48086673 -0.6552259  -0.75863224\n",
      "  0.3855743  -0.6923028   2.2753115  -0.31321058 -0.45227674 -0.59394175\n",
      "  1.1812874  -0.6865486  -0.5831725   0.2120372  -0.03222663 -0.4128561\n",
      "  0.76360965  0.6846557   0.9493905  -1.3753734  -0.9474789  -0.7131466\n",
      " -0.20288195  2.0960705   2.0487564  -0.18516697 -0.2968717  -0.9562784\n",
      "  0.47473282  1.2547724   0.46459252 -0.5735779  -0.20361573 -1.1502075\n",
      " -0.36837295  0.01832613 -0.58357817 -0.5568962   0.6390787  -0.14110729\n",
      " -0.34545368  0.19789062  1.6956067  -0.403545    0.29080793  0.15772255\n",
      " -0.15268843 -0.05549365 -0.4588645  -0.9355625   0.3055046   0.5718588\n",
      "  0.58548087  0.46982613 -0.8551094  -0.10124909 -0.5747172  -0.15245329\n",
      "  1.3822398  -0.7736889  -0.54129815 -0.5544055   0.05289495  0.23239096\n",
      " -0.8878663  -0.0623333  -0.3729036   0.19504435 -0.439308   -0.6941412\n",
      " -0.00989    -0.05588314  0.30465975  0.11977723 -1.1563755  -0.27517408\n",
      "  1.8984482  -0.67889965 -0.24626897 -0.75341547 -0.9187953   1.6226281\n",
      "  0.02305156  0.43369883  1.6788075  -0.9662975   0.46720502 -0.7541389\n",
      "  0.9380733  -0.24044296 -0.9312251   1.5206078   0.9299411   1.6427422\n",
      " -0.6331432   1.7745063  -0.057046   -0.701342   -0.4050813  -0.15646891\n",
      "  1.7480367  -0.38559666  1.2872769   0.692012    0.85322845 -0.26160526\n",
      " -0.6199229  -0.4765597  -0.270867   -1.5569776  -0.271197    1.1228223\n",
      "  0.77607936 -0.6316813  -0.5371695  -0.29246846 -1.1232721  -0.01230337\n",
      " -0.8421591   1.6210172  -0.3333055  -0.1760722   1.144692    1.3639998\n",
      "  1.3923408  -0.41531697  0.28331235 -0.4357111  -0.28130254 -0.6992127\n",
      " -0.15916103 -0.26473656  0.31366667  1.388557   -1.1312382  -0.37555027\n",
      " -0.24553968 -0.4082847  -0.18077266  2.1685202   0.6530368  -0.2872055\n",
      "  0.55935085 -1.0046246  -1.0373043  -0.44681692 -1.0469644  -0.600748\n",
      "  0.00460728 -0.6572062   0.16200113 -1.037605   -0.772396   -0.62134457\n",
      " -0.99080044  1.2118076  -0.13166393 -0.39967588  1.4272747  -0.5238797\n",
      "  0.8005636   0.8283663   0.36154428 -0.18676175  0.40653244 -0.08037408\n",
      " -0.05879773  1.8178738  -1.060446    1.1290886  -0.3216469  -0.798486\n",
      " -0.391327   -0.80747604  0.5439743  -0.79591084  0.10431448 -0.27312568\n",
      " -1.1107987   1.550842   -1.2363746   1.037104   -0.48448583 -0.7400666\n",
      " -0.818256    1.5432312  -0.82042664 -0.15400104  1.8962394  -0.56345737\n",
      "  0.8093128  -0.7846874  -0.00979334 -0.94612575 -0.67926675 -0.02681331\n",
      " -0.10864566 -0.27940503 -0.5024573   1.1520286   1.3706906   1.3412921\n",
      " -0.5223119  -0.56707156  0.21773145 -0.18808551 -0.2618307  -0.3096864\n",
      " -0.8415378  -0.64702785 -1.4628136  -0.38814998 -1.0074826  -0.08215825\n",
      " -0.52373046 -0.12180779 -0.33394268 -0.5570244  -1.2028501   0.9084791\n",
      " -0.34488702 -1.1983708  -0.32555613 -0.29399475  0.05734641 -0.7680112\n",
      "  1.1280618   0.20677581 -0.8070623  -0.3459286  -0.80353796 -0.54645085\n",
      "  0.05381696 -0.2665219  -1.1427243   0.5741042  -0.749822    0.4849016\n",
      " -0.29564536 -1.1397011  -0.6839853  -0.7362032  -0.04473972  1.7479378\n",
      " -0.6519049  -0.21586981 -0.77190775 -0.5821158   0.03620329  0.20487534\n",
      " -0.9679852  -0.35581407 -0.3051508  -0.45407027  1.1124985   1.3326085\n",
      "  1.5246786  -0.44159698  1.6877377   0.12541486 -1.2041335  -0.5990835\n",
      " -1.3231735  -0.33862266 -0.71060824 -1.228681   -0.01700371  0.15975209\n",
      "  0.3944269   1.2211637  -0.6012272   0.20961781 -0.4024479  -0.7602151\n",
      " -0.17805226  0.33369565  0.17030092 -0.3570653  -0.41836062 -0.9203335\n",
      " -0.4644799  -1.5027875  -1.2276324  -1.0816363   0.39150846 -0.63153225\n",
      "  1.3306817  -0.90728426 -1.0585514   0.49008146 -0.41829816 -0.26954427\n",
      "  1.152203   -0.5366428  -0.27384797 -0.41904724  0.11713984 -0.3001422\n",
      " -0.54092497 -0.6197268  -0.40458655 -0.5458288  -0.860998    0.89671534\n",
      " -0.31015527 -0.7525796   0.16586784 -0.542354   -0.0855904  -0.5003579\n",
      "  1.5268178  -0.95617115 -0.5154948  -1.1054065   0.7963386  -1.2355247\n",
      "  0.87229615 -0.5607372  -0.42295614 -1.0534711   0.6214174  -0.33853817\n",
      " -1.0597224  -0.8871211   1.0557901  -0.7695815   0.9097303  -1.2158381\n",
      "  0.6137195   0.8081748   0.03265501  0.6253804  -0.44406128  0.06802559\n",
      "  0.53934455 -0.17170793  1.28595     0.9063075  -0.51924086 -0.57798386\n",
      " -0.13780117  1.4566895  -0.31696832 -0.83892345  0.63812226 -0.15447046\n",
      " -0.27402306  1.332276   -0.7221574   0.9496167   0.00848651 -0.4794347\n",
      " -0.7118167  -0.7294964  -0.38197982  1.626433    1.340477    1.3046224\n",
      " -0.88081104 -0.2245203   0.7537273   1.6806263   0.9414675  -0.06856167\n",
      "  1.269417   -0.4770991 ]\n",
      "[-1.11931527e+00  1.34389567e+00 -1.85127330e+00 -1.59270418e+00\n",
      "  3.05848622e+00 -4.56373952e-02  5.41231513e-01 -1.52432966e+00\n",
      " -1.15544629e+00  1.74456906e+00  1.08494771e+00  3.23833275e+00\n",
      "  6.99967802e-01  2.65045427e-02 -2.28603616e-01  8.19634199e-01\n",
      " -9.16926444e-01  6.32944643e-01 -1.54014003e+00 -7.77675688e-01\n",
      "  1.91732872e+00  2.62483740e+00  1.58716881e+00 -1.02665222e+00\n",
      " -8.55858266e-01 -2.03556824e+00  1.10423446e+00  4.41350102e-01\n",
      "  3.20153737e+00 -1.05816090e+00  3.31337392e-01 -2.81699598e-01\n",
      "  2.14842391e+00 -9.42898393e-01  1.66557109e+00 -1.12897277e+00\n",
      " -9.53285396e-01  1.66963232e+00 -2.00371885e+00 -1.07775591e-01\n",
      " -1.10535181e+00 -3.73451233e-01  1.01822877e+00 -1.72913027e+00\n",
      " -4.74755317e-02  2.29724288e+00 -3.53149056e+00  1.83423758e+00\n",
      " -3.09409685e-02  4.15803480e+00  1.44639826e+00  3.42691660e-01\n",
      "  1.32094312e+00 -1.06353603e-01 -4.37563390e-01 -1.79223567e-02\n",
      " -1.33306193e+00  5.53120971e-01  1.38012242e+00  1.12475539e-02\n",
      " -1.62495089e+00  9.99395490e-01  3.03397477e-02  4.48311090e+00\n",
      "  1.32598686e+00  1.03774035e+00  1.10741651e+00 -4.64533359e-01\n",
      "  1.71738878e-01  4.11973858e+00  1.92115664e+00  1.05592823e+00\n",
      "  6.98924363e-01  7.53719985e-01 -5.16646385e-01  2.75194556e-01\n",
      " -1.84783805e-02 -1.97522628e+00  1.70025921e+00  5.06481946e-01\n",
      "  2.23366332e+00 -2.15316296e+00 -1.76412106e-01 -4.53263223e-01\n",
      " -1.08068120e+00 -2.93579936e-01  9.37529743e-01  2.48984241e+00\n",
      "  7.03056693e-01 -1.42053813e-01 -1.01331031e+00  6.57421887e-01\n",
      "  1.63678765e+00  2.09042978e+00  1.21884358e+00  9.61848736e-01\n",
      " -5.21929085e-01  3.04486632e-01  3.33131254e-01  3.84365112e-01\n",
      " -1.33871585e-01  9.16372716e-01  1.73047233e+00  8.99039984e-01\n",
      " -1.94542420e+00  3.73115018e-02  1.35572720e-02 -3.27007115e-01\n",
      "  2.68029189e+00 -4.54544783e-01  1.82703018e+00  2.29835677e+00\n",
      " -1.18781412e+00  1.84885812e+00  1.17469800e+00 -3.35489064e-01\n",
      "  6.99643433e-01 -9.88006651e-01  1.62222946e+00  7.31895864e-01\n",
      "  9.41764653e-01 -1.56578672e+00  8.84672284e-01  1.70340323e+00\n",
      " -2.41290167e-01 -3.08468628e+00 -1.48310757e+00  4.52539384e-01\n",
      " -4.82483178e-01  1.58355856e+00 -1.13513991e-01  3.67928386e+00\n",
      "  1.95236397e+00  2.88292718e+00 -5.89966893e-01 -1.84087062e+00\n",
      "  3.65286613e+00  9.01022732e-01  7.04199851e-01  2.41727248e-01\n",
      " -5.98636605e-02  2.20947206e-01  8.51174355e-01 -1.17372692e+00\n",
      "  1.74395061e+00 -2.19951105e+00  8.90316963e-01  2.07269001e+00\n",
      " -2.50605226e-01  2.18419099e+00  1.58550680e-01  2.51291728e+00\n",
      " -1.16037977e+00 -5.95056593e-01 -5.80747366e-01  9.62155223e-01\n",
      " -1.92274302e-01 -1.26955402e+00  1.86641264e+00  1.29830766e+00\n",
      " -1.71156836e+00 -2.50541624e-02 -3.97002667e-01 -5.75483918e-01\n",
      "  2.84417808e-01 -1.62796652e+00 -1.68147278e+00  7.76893079e-01\n",
      "  9.18253481e-01  3.19289970e+00  3.63462120e-01 -2.16467357e+00\n",
      "  2.91482091e+00 -3.02833962e+00  1.30459750e+00 -9.58283007e-01\n",
      " -3.22454244e-01  1.35622513e+00  2.03343570e-01 -1.80203462e+00\n",
      "  2.11490154e+00  3.15139151e+00  1.20282996e+00 -3.21626574e-01\n",
      "  1.01033473e+00  1.20484281e+00 -9.12796184e-02 -1.44995078e-01\n",
      "  9.28499877e-01  4.38544929e-01  6.99734330e-01  8.67499948e-01\n",
      " -1.51949334e+00  1.44336200e+00  4.80075508e-01  9.36073005e-01\n",
      " -2.51402378e+00 -3.94787878e-01 -3.55650759e+00  1.60222578e+00\n",
      " -3.25658351e-01 -1.16787009e-01  1.88124120e+00 -1.48285484e+00\n",
      " -5.30294836e-01 -2.72853899e+00  2.98794913e+00  1.34634829e+00\n",
      " -1.35729504e+00  1.16044009e+00  1.63079184e-02 -1.38166916e+00\n",
      " -1.00321460e+00 -3.97322953e-01  5.80431819e-01  1.05246007e+00\n",
      "  1.79997921e+00  2.10818386e+00  3.45662212e+00 -3.79185408e-01\n",
      "  1.69848502e+00  2.15508032e+00  2.20056027e-01 -5.02262115e-01\n",
      " -3.54108512e-01  1.70047152e+00 -8.51743221e-01  6.56019568e-01\n",
      "  1.14580631e+00 -1.08170640e+00 -6.34362459e-01  7.05968678e-01\n",
      "  3.84138137e-01 -5.05132484e+00  1.56166828e+00 -3.79335046e-01\n",
      "  6.01154985e-03 -3.34151840e+00  2.60734868e+00 -1.04918957e+00\n",
      "  1.19464815e+00  2.12616420e+00 -2.08669126e-01 -1.74188510e-01\n",
      " -1.81670511e+00  4.00488466e-01  3.34488600e-01 -1.66123414e+00\n",
      " -3.04337531e-01 -9.81029093e-01 -4.53888020e-03  9.81745720e-01\n",
      "  6.97339892e-01  1.05527389e+00  1.48025835e+00 -1.28305328e+00\n",
      "  3.89653087e-01  1.09078443e+00 -9.85057890e-01  2.33228827e+00\n",
      " -1.28434610e+00 -1.36680789e-02 -1.20765686e+00  2.53860402e+00\n",
      " -9.10451770e-01  2.42994571e+00  3.27880681e-01  6.55090988e-01\n",
      " -2.09549487e-01  1.70738339e-01  7.80745029e-01 -1.15965378e+00\n",
      "  1.46367025e+00 -9.09785628e-01  3.34083891e+00 -6.81827843e-01\n",
      " -5.44845343e-01 -7.36514553e-02 -2.75353289e+00 -1.96265001e-02\n",
      "  2.50030112e+00 -2.90156722e-01 -1.79518723e+00  7.47041032e-02\n",
      " -2.80729592e-01  1.56047270e-01 -3.52858156e-01  1.54681587e+00\n",
      " -1.17417085e+00  1.80886507e+00  1.07329935e-01  1.46749818e+00\n",
      " -3.90417123e+00 -2.36306691e+00  8.65946174e-01 -6.46495938e-01\n",
      "  2.85455847e+00 -1.93377644e-01  3.73156166e+00  1.80632472e+00\n",
      " -1.11347580e+00 -9.40227389e-01 -1.53962755e+00  3.29734743e-01\n",
      "  1.86242080e+00 -6.93422973e-01 -2.59053254e+00 -1.97687137e+00\n",
      " -3.28075552e+00  9.17790771e-01 -1.20264697e+00  2.40792966e+00\n",
      " -1.99846104e-01  1.41284490e+00 -4.35279816e-01  1.15465797e-01\n",
      "  2.03084528e-01 -8.83233011e-01 -4.65200782e-01 -7.71711648e-01\n",
      " -2.17645812e+00 -1.13392234e+00  6.38247848e-01 -8.04210126e-01\n",
      "  9.69197869e-01 -7.76907623e-01 -1.00121248e+00  2.96793652e+00\n",
      " -5.79794236e-02 -1.49806499e-01  3.41904473e+00  2.45696697e-02\n",
      " -1.89120662e+00  8.23292613e-01  5.88854969e-01 -8.95560026e-01\n",
      "  4.79701757e-01  1.04421206e-01  4.24593806e-01 -1.80771542e+00\n",
      "  2.76392078e+00  2.27115011e+00 -5.21781445e-02  1.24846172e+00\n",
      "  2.98003882e-01  7.81600833e-01  1.23074615e+00 -4.04842675e-01\n",
      "  8.11076820e-01 -1.36105680e+00 -1.19116342e+00  2.21793914e+00\n",
      "  3.16200219e-02  6.40024185e-01  1.39037848e+00 -2.20847830e-01\n",
      " -2.08738565e+00  2.54970074e+00  1.75148427e+00  2.20974159e+00\n",
      "  1.11730206e+00  2.15218210e+00 -3.67381364e-01 -8.15757275e-01\n",
      " -6.71679080e-01  9.08332825e-01 -9.31170762e-01 -9.59907353e-01\n",
      " -2.94916105e+00  1.65929592e+00  1.48406744e+00  9.13407326e-01\n",
      "  2.79969096e-01  2.45564491e-01  1.66179514e+00  1.11585009e+00\n",
      "  1.28062916e+00  3.04910469e+00 -3.57929444e+00  2.13222235e-01\n",
      " -9.74329412e-01  2.02785432e-01 -4.91569713e-02  2.85195261e-01\n",
      "  1.35904267e-01  1.19178617e+00  5.66426992e-01  6.35965645e-01\n",
      " -2.41801366e-01  3.63538951e-01 -3.06298208e+00  2.52778679e-01\n",
      " -5.48922598e-01  2.73476410e+00  1.81120718e+00  8.15782309e-01\n",
      "  7.24230528e-01  8.26773167e-01  2.78414297e+00 -2.25181133e-01\n",
      "  7.78769314e-01  1.77864683e+00 -7.64234781e-01  2.45463490e+00\n",
      " -8.51857245e-01  3.32198203e-01  1.79786813e+00  2.15290621e-01\n",
      "  2.92910290e+00  1.89131165e+00  2.32817888e+00 -2.99732828e+00\n",
      " -1.72338104e+00 -4.77126211e-01  9.05464113e-01 -4.65012848e-01\n",
      "  1.62952709e+00  2.46325278e+00 -5.85272253e-01  1.44184500e-01\n",
      "  1.24048722e+00 -1.43561542e-01  8.62811685e-01 -5.05939960e-01\n",
      "  4.46696460e-01  2.02269524e-01  9.22217607e-01 -8.10019672e-01\n",
      "  6.37337491e-02  1.81557906e+00 -8.32960010e-01 -1.19659340e+00\n",
      "  4.07892138e-01  1.42822337e+00 -1.65243313e-01  1.73241007e+00\n",
      "  7.93764591e-01  2.33860636e+00  3.98402184e-01 -3.54540437e-01\n",
      " -3.13693953e+00  1.49828243e+00  1.69816148e+00 -1.27498388e+00\n",
      "  2.47855082e-01  9.58290577e-01 -8.68636608e-01  1.23540413e+00\n",
      "  3.33317852e+00  6.19165361e-01 -1.89598024e-01 -1.11171901e+00\n",
      "  2.43160152e+00  1.41260996e-01  3.19788480e+00  1.64069831e+00\n",
      "  2.87618816e-01 -2.26889586e+00  2.18413186e+00  1.99049830e-01\n",
      " -7.26248264e-01  1.71018049e-01 -1.14800417e+00 -2.48109981e-01\n",
      "  9.89076734e-01  1.48916268e+00  2.40319753e+00 -1.77056742e+00\n",
      "  1.08102036e+00 -4.95453119e-01 -3.62098962e-01 -2.72462273e+00\n",
      "  5.25779307e-01 -9.17616189e-01  1.46552098e+00  2.87415564e-01\n",
      "  9.06275868e-01 -1.02385759e+00 -2.15853930e+00  1.30801558e+00\n",
      " -2.99929333e+00 -1.26488119e-01  1.11561561e+00  2.64237911e-01\n",
      " -1.30764139e+00  1.20313859e+00  6.07787192e-01 -6.18155777e-01\n",
      "  1.49712956e+00  3.86256367e-01  1.32063246e+00 -5.35442412e-01\n",
      "  4.86149698e-01 -3.80664498e-01  1.95001352e+00  2.07544827e+00\n",
      "  1.96779275e+00  2.89624572e+00  5.97510457e-01  2.23719764e+00\n",
      " -1.42105326e-01  5.24082422e-01 -3.92869622e-01 -1.09987879e+00\n",
      "  1.57072437e+00  3.93520653e-01  1.35020995e+00 -1.41424668e+00\n",
      " -1.12366192e-02  1.53399989e-01  5.06427288e-01 -1.42787826e+00]\n",
      "[0.73080087 0.374237   0.7718887  0.58898085 0.91138715 0.4384126\n",
      " 0.5865685  0.72083837 0.6307158  0.78629875 0.75154644 0.7544553\n",
      " 0.6220273  0.7891053  0.53263646 0.6515422  0.56248504 0.43448064\n",
      " 1.0826188  0.3471303  0.96416944 0.5353524  0.62817025 0.23543195\n",
      " 0.7764244  1.180388   0.5302118  0.6921698  0.7235878  1.1292176\n",
      " 0.53266126 0.7626526  0.61948043 0.6472387  0.96840477 0.70604146\n",
      " 0.42254904 0.57412827 0.7951948  0.7444554  0.5240981  0.6628414\n",
      " 0.9433707  0.582472   0.4202087  1.1548588  0.9077083  1.0126007\n",
      " 0.544353   0.7881127  0.81902486 0.5347435  0.7329513  0.31872198\n",
      " 0.54944175 0.8412688  0.557012   0.7880647  0.84418255 0.7182912\n",
      " 0.6751443  0.64732605 0.814788   0.5533676  1.0939138  0.96503794\n",
      " 0.6592329  0.6115932  0.8258266  0.8217779  0.7503271  0.4636166\n",
      " 0.52885824 0.7186797  0.59975207 0.64503634 0.63825965 0.51376677\n",
      " 0.5843802  0.80453914 0.6364276  0.94267637 0.5210192  0.5927081\n",
      " 0.9309383  0.5390622  0.34219643 0.42133    1.2791222  0.4986144\n",
      " 0.45128572 0.590016   0.8269412  0.5416884  0.5483108  0.91652983\n",
      " 0.79345393 0.45491466 0.6693765  0.7874109  0.75579506 0.54784155\n",
      " 0.95174015 0.67118835 0.5001297  0.91530895 0.6859159  0.931389\n",
      " 0.766842   1.3650519  0.88483334 0.5101828  0.5238408  0.75030094\n",
      " 0.81844753 0.6861495  0.9563079  0.7925553  0.46325985 0.5706504\n",
      " 0.49747702 0.6879371  0.46010607 0.92940277 0.6358942  0.9019348\n",
      " 0.80858344 0.6728341  0.769527   0.5965343  0.6472153  0.71313137\n",
      " 0.5426261  0.5732101  0.661133   0.40569457 0.66963196 0.73899144\n",
      " 0.6596056  0.5431624  0.3875518  0.7345175  0.3910704  0.52992195\n",
      " 0.827675   0.6640252  0.77694696 0.6888274  0.67413646 0.64942396\n",
      " 0.58860207 0.79044175 0.71656764 0.63948107 1.1315798  0.75393134\n",
      " 0.4597425  0.74647325 0.7991623  0.85633785 0.86494094 0.2997641\n",
      " 0.4762657  0.64432335 1.1747899  0.63916093 0.6116312  0.56229955\n",
      " 0.48239982 0.44704846 0.48349547 0.5280167  0.715362   0.66937524\n",
      " 1.0203102  0.47385094 1.00161    0.39147514 0.5465173  0.750027\n",
      " 0.87405616 1.2034353  0.7079577  0.48365864 0.40103522 0.7376149\n",
      " 0.3010521  0.39323223 0.41850027 0.8227999  0.8007312  0.7198942\n",
      " 0.7472904  0.8067609  0.39863586 0.5229512  0.6161445  0.8318226\n",
      " 1.041042   1.0186847  0.71173334 0.9013249  0.55244535 0.8640839\n",
      " 0.46683553 0.75695086 0.75225896 0.50091887 0.6992284  0.70859224\n",
      " 0.70820975 0.60170126 0.6101038  0.89071965 0.67109585 0.5853161\n",
      " 0.69416004 0.93097365 1.037807   0.87634754 0.96045345 0.6088968\n",
      " 0.44382176 0.80798584 0.684067   0.66766846 0.6626624  0.81324434\n",
      " 0.60690963 0.82922375 0.41405028 0.6461081  0.6767866  0.9330518\n",
      " 0.73291034 0.65534985 0.7408449  0.39501464 0.668674   0.49530193\n",
      " 0.71386176 0.9353661  0.7112063  0.5723307  0.8460491  0.7010146\n",
      " 0.43083966 0.7745612  0.521328   0.74324083 0.84935033 0.3929031\n",
      " 0.51546174 0.7094724  1.1196762  0.54634917 0.62560904 0.59188\n",
      " 0.7234475  0.8220789  0.99186015 0.5982804  0.45026544 0.6401861\n",
      " 0.5338142  0.5562917  0.6382199  0.6232559  0.6109312  0.6349907\n",
      " 0.4500732  0.72807604 0.57509154 0.5814188  1.0188364  0.6841914\n",
      " 0.47852406 0.39560804 0.56037325 0.5824586  0.6477305  0.69665873\n",
      " 0.8920615  0.8143314  0.36659864 0.94498813 0.8180675  0.86195475\n",
      " 0.5281328  0.63194865 0.7338223  0.5858342  0.49201    0.5876702\n",
      " 0.63203496 0.5430892  0.949366   0.63700444 0.7362175  0.80463654\n",
      " 0.2807905  0.49165592 0.7101589  0.7946623  0.47758314 0.6381191\n",
      " 0.5163353  0.47906855 0.6840693  0.841446   0.86376834 1.4319165\n",
      " 0.8653447  0.27935335 0.72125953 0.98602587 0.5972979  0.8887274\n",
      " 0.60718745 0.6620565  0.7022343  0.7095557  0.4436316  1.0691215\n",
      " 0.5270858  0.20431778 0.7549054  0.46769184 0.638926   0.539354\n",
      " 0.41339135 0.25770202 0.52176327 0.8361561  0.52369905 0.76695895\n",
      " 0.83766305 0.3787697  0.7129231  0.8423584  0.7133245  0.9474046\n",
      " 0.69017905 0.95662814 0.679421   0.63953996 0.5908923  0.95693314\n",
      " 0.6633294  0.71075517 1.0819786  0.85069734 0.7750041  0.70707417\n",
      " 1.0517387  0.76713127 0.4362404  0.75764865 0.653054   0.58548135\n",
      " 0.65217966 0.5146287  0.7868247  0.8715129  0.41549274 0.6265622\n",
      " 0.57033974 0.5678598  0.7413656  0.75584894 0.9954755  0.65169525\n",
      " 0.44504315 0.32311958 0.5572527  0.93105835 0.7199317  0.647983\n",
      " 0.8142043  0.7563989  0.6505705  1.1724648  0.6180568  0.6236394\n",
      " 0.7002072  0.53983325 0.69130284 0.4909015  0.9990529  0.69631916\n",
      " 0.5913648  0.755255   0.5303079  0.7463448  0.71982855 0.70299834\n",
      " 0.5866559  0.4324594  0.53865737 0.7879699  0.5960443  0.61945635\n",
      " 0.70002794 0.70848423 0.75569    0.7887747  0.6208086  0.6493792\n",
      " 0.348529   0.59938717 0.8891341  0.9184596  0.7145556  0.9032396\n",
      " 0.6982351  0.51417875 0.6884095  0.71283746 0.60601133 0.54465294\n",
      " 0.9462844  0.75612694 0.72429067 0.69277656 0.6080563  0.5441506\n",
      " 0.78859556 0.4599473  0.3291339  0.912833   0.6462927  0.90988237\n",
      " 0.64174825 0.68422115 0.6254001  0.9537439  0.7220004  0.759181\n",
      " 1.0423607  0.7342881  0.60440683 0.62706995 0.4717974  0.7586717\n",
      " 0.87473065 0.5849612  0.6933301  0.6900844  0.7014578  0.5755483\n",
      " 0.44033784 0.4969443  0.71603    0.8233496  0.6239587  0.38064462\n",
      " 0.59594285 0.45595828 0.6088718  0.5735871  0.9880985  0.5322736\n",
      " 0.6168626  0.6134537  0.91962606 0.60594994 0.74589837 0.5039182\n",
      " 0.9677143  0.9409999  0.7642148  0.555249   0.54026055 0.70434\n",
      " 0.9059594  0.51686877 1.1823134  0.77572227 0.84544754 0.76162213\n",
      " 0.61894226 0.30570075 0.6333867  0.74310523 1.114122   0.6861904\n",
      " 0.8355943  0.34819132 0.790365   0.558026   0.4127928  0.2978435\n",
      " 0.789119   0.5702223  0.5960207  0.4388702  0.64019984 0.8565906\n",
      " 0.5428556  0.6746945  0.73296386 0.63067615 0.5633188  0.70721817\n",
      " 0.89876926 0.72570056 0.55351806 0.39209437 0.51069427 0.4168766\n",
      " 1.1264313  0.942138  ]\n"
     ]
    }
   ],
   "source": [
    "import math as m\n",
    "layer66 = model.layers[66]\n",
    "W = np.array(layer66.get_weights())\n",
    "print(W.shape)\n",
    "\n",
    "batchNorm = model.layers[66].get_weights()\n",
    "\n",
    "fMean = open(\"data/TwentyOneLayer/TwentyOne_Layer_Mean.txt\", \"w\")\n",
    "fSD = open(\"data/TwentyOneLayer/TwentyOne_Layer_StanDev.txt\", \"w\")\n",
    "fGamma = open(\"data/TwentyOneLayer/TwentyOne_Layer_Gamma.txt\", \"w\")\n",
    "fBeta = open(\"data/TwentyOneLayer/TwentyOne_Layer_Beta.txt\", \"w\")\n",
    "\n",
    "\n",
    "for i in range(len(batchNorm[0])):\n",
    "    fGamma.write(str(float(batchNorm[0][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[1])):\n",
    "    fBeta.write(str(float(batchNorm[1][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[2])):\n",
    "    fMean.write(str(float(batchNorm[2][i])) + \"\\n\")\n",
    "\n",
    "for i in range(len(batchNorm[3])):\n",
    "    # The Value for Epsilon is assumed to be 0.001 in this implementation\n",
    "    fSD.write(str(m.sqrt(float(batchNorm[3][i]) + 0.001)) + \"\\n\")\n",
    "\n",
    "\n",
    "print(batchNorm[0])\n",
    "print(batchNorm[1])\n",
    "print(batchNorm[2])\n",
    "print(batchNorm[3])\n",
    "\n",
    "fMean.close()\n",
    "fSD.close()\n",
    "fGamma.close()\n",
    "fBeta.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFile_TwentyOneLayer():\n",
    "    fExp = open('data/TwentyOneLayer/TwentyOne_Layer_Output.txt', 'r')\n",
    "    fAct = open('data/TwentyOneLayer/output.txt', 'r')\n",
    "    \n",
    "    cExp = fExp.readlines()\n",
    "    cAct = fAct.readlines()\n",
    "    counter = 0\n",
    "    for i in range(len(cExp)):\n",
    "         if int(round(float(cAct[i].strip()))) != int(round(float(cExp[i].strip()))):\n",
    "            counter += 1\n",
    "            if(counter < 30):\n",
    "                print(str(cAct[i].strip()) + \"--->\" + str(cExp[i].strip()))\n",
    "            \n",
    "        \n",
    "    print(\"Number of mismatch - \" + str(counter))\n",
    "    \n",
    "    fExp.close()\n",
    "    fAct.close()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.500061--->1.499938\n",
      "0.500120--->0.49999323\n",
      "1.499907--->1.5000167\n",
      "0.500134--->0.49986032\n",
      "2.500002--->2.4996572\n",
      "0.500088--->0.49989048\n",
      "0.499902--->0.5003196\n",
      "0.499832--->0.5001062\n",
      "3.500182--->3.4999926\n",
      "0.500177--->0.49964494\n",
      "0.499923--->0.50004125\n",
      "Number of mismatch - 11\n"
     ]
    }
   ],
   "source": [
    "checkFile_TwentyOneLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
